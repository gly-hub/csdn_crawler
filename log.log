2019-10-29 09:22:41 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:22:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:22:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:22:42 [scrapy.extensions.telnet] INFO: Telnet Password: d72433fee595d52d
2019-10-29 09:22:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:22:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:22:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:22:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:22:44 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:22:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:22:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:22:48 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:22:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 42105,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 183973,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 22, 48, 813654),
 'item_scraped_count': 25,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 10, 29, 1, 22, 44, 172584)}
2019-10-29 09:22:48 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:25:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:25:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:25:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:25:47 [scrapy.extensions.telnet] INFO: Telnet Password: fc695c8a863ba5d7
2019-10-29 09:25:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:25:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:25:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:25:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:25:48 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:25:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:25:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:25:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:25:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 45561,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 183824,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 25, 55, 507172),
 'item_scraped_count': 25,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 10, 29, 1, 25, 48, 228150)}
2019-10-29 09:25:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:29:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:29:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:29:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:29:47 [scrapy.extensions.telnet] INFO: Telnet Password: e1deb558802a0063
2019-10-29 09:29:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:29:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:29:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:29:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:29:48 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:29:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:29:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:29:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:29:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 45561,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 183829,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 29, 50, 434417),
 'item_scraped_count': 25,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 10, 29, 1, 29, 48, 442769)}
2019-10-29 09:29:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:32:34 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:32:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:32:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:32:34 [scrapy.extensions.telnet] INFO: Telnet Password: e77e504527c703f5
2019-10-29 09:32:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:32:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:32:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:32:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:32:34 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:32:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:32:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:32:37 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:32:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 45561,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 183831,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 32, 37, 237837),
 'item_scraped_count': 25,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 10, 29, 1, 32, 35, 2860)}
2019-10-29 09:32:37 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:34:58 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:34:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:34:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:34:58 [scrapy.extensions.telnet] INFO: Telnet Password: 0438bce2184c4312
2019-10-29 09:34:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:34:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:34:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:34:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:34:59 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:34:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:34:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:35:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:35:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 45561,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 183847,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 35, 1, 628246),
 'item_scraped_count': 25,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 10, 29, 1, 34, 59, 446601)}
2019-10-29 09:35:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:37:28 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:37:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:37:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:37:28 [scrapy.extensions.telnet] INFO: Telnet Password: 8f905267a99d8566
2019-10-29 09:37:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:37:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:37:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:37:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:37:28 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:37:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:37:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:37:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:37:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20240,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 86016,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 37, 30, 411365),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 37, 28, 883311)}
2019-10-29 09:37:30 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:38:42 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:38:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:38:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:38:42 [scrapy.extensions.telnet] INFO: Telnet Password: f6b584ca8aca2507
2019-10-29 09:38:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:38:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:38:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:38:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:38:43 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:38:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:38:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:38:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:38:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6561,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 87569,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 38, 44, 783539),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 38, 43, 271362)}
2019-10-29 09:38:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:38:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:38:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:38:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:38:57 [scrapy.extensions.telnet] INFO: Telnet Password: a66bad84f0573061
2019-10-29 09:38:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:38:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:38:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:38:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:38:58 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:38:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:38:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:39:08 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:39:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6561,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 87568,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 39, 8, 445709),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 38, 58, 153675)}
2019-10-29 09:39:08 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:44:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:44:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:44:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:44:35 [scrapy.extensions.telnet] INFO: Telnet Password: ae0ffe6dc1ad4c10
2019-10-29 09:44:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:44:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:44:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:44:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:44:35 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:44:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:44:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:44:37 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:44:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5516,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 87602,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 44, 37, 476706),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 44, 35, 941091)}
2019-10-29 09:44:37 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:48:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:48:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:48:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:48:53 [scrapy.extensions.telnet] INFO: Telnet Password: effbe9fb67078b95
2019-10-29 09:48:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:48:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:48:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:48:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:48:53 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:48:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:48:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:48:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:48:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20240,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 85983,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 48, 55, 748400),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 48, 54, 8964)}
2019-10-29 09:48:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:52:48 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:52:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:52:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:52:48 [scrapy.extensions.telnet] INFO: Telnet Password: 8e19ec3964d66b03
2019-10-29 09:52:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:52:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:52:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:52:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:52:49 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:52:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:52:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:52:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:52:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1624,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 18799,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 52, 50, 443928),
 'log_count/INFO': 9,
 'offsite/domains': 1,
 'offsite/filtered': 11,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 10, 29, 1, 52, 49, 638502)}
2019-10-29 09:52:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:53:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:53:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:53:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:53:18 [scrapy.extensions.telnet] INFO: Telnet Password: b19bf70c69efe662
2019-10-29 09:53:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:53:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:53:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:53:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:53:19 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:53:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:53:20 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:53:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1624,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 53, 20, 294929),
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 10, 29, 1, 53, 19, 657989)}
2019-10-29 09:53:20 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:53:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:53:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:53:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:53:35 [scrapy.extensions.telnet] INFO: Telnet Password: 06ea354fd0d11dab
2019-10-29 09:53:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:53:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:53:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:53:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:53:35 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:53:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:53:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:53:37 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:53:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20240,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 85529,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 53, 37, 435041),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 53, 35, 827213)}
2019-10-29 09:53:37 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:54:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:54:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:54:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:54:16 [scrapy.extensions.telnet] INFO: Telnet Password: 8674438f148a364e
2019-10-29 09:54:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:54:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:54:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:54:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:54:17 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:54:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:54:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:54:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:54:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19928,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 85536,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 54, 18, 711149),
 'item_scraped_count': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 29, 1, 54, 17, 95727)}
2019-10-29 09:54:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:56:19 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:56:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:56:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:56:19 [scrapy.extensions.telnet] INFO: Telnet Password: 21546690d376478d
2019-10-29 09:56:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:56:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:56:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:56:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:56:20 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:56:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:56:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:56:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:56:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3260,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25325,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 56, 21, 639927),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 29, 1, 56, 20, 323123)}
2019-10-29 09:56:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-29 09:56:41 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-29 09:56:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-29 09:56:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-29 09:56:41 [scrapy.extensions.telnet] INFO: Telnet Password: 25486b9b23ff3132
2019-10-29 09:56:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-29 09:56:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-29 09:56:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-29 09:56:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-29 09:56:42 [scrapy.core.engine] INFO: Spider opened
2019-10-29 09:56:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-29 09:56:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-29 09:56:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-29 09:56:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3260,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25323,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 29, 1, 56, 43, 618560),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 29, 1, 56, 42, 510479)}
2019-10-29 09:56:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 09:29:25 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 09:29:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 09:29:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 09:29:25 [scrapy.extensions.telnet] INFO: Telnet Password: f25885ff62056e4a
2019-10-30 09:29:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 09:29:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 09:29:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 09:29:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 09:29:27 [scrapy.core.engine] INFO: Spider opened
2019-10-30 09:29:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 09:29:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 09:29:28 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 09:29:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3260,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25409,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 1, 29, 28, 429794),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 1, 29, 27, 184736)}
2019-10-30 09:29:28 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 09:33:20 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 09:33:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 09:33:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 09:33:20 [scrapy.extensions.telnet] INFO: Telnet Password: 3034e58fae5009e3
2019-10-30 09:33:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 09:33:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 09:33:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 09:33:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 09:33:21 [scrapy.core.engine] INFO: Spider opened
2019-10-30 09:33:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 09:33:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 09:33:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 09:33:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6428,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 26105,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 1, 33, 23, 13464),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 4,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 1, 33, 21, 556379)}
2019-10-30 09:33:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 09:33:40 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 09:33:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 09:33:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 09:33:40 [scrapy.extensions.telnet] INFO: Telnet Password: f36f2012d71356ac
2019-10-30 09:33:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 09:33:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 09:33:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 09:33:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 09:33:41 [scrapy.core.engine] INFO: Spider opened
2019-10-30 09:33:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 09:33:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 09:33:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 09:33:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3260,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25411,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 1, 33, 43, 164285),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 1, 33, 41, 969214)}
2019-10-30 09:33:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 09:55:55 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 09:55:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 09:55:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 09:55:55 [scrapy.extensions.telnet] INFO: Telnet Password: f4306cdcc3d4a66f
2019-10-30 09:55:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 09:55:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 09:55:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 09:55:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 09:55:56 [scrapy.core.engine] INFO: Spider opened
2019-10-30 09:55:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 09:55:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 09:55:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 09:55:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4128,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25410,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 1, 55, 57, 684560),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 1, 55, 56, 496128)}
2019-10-30 09:55:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 09:56:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 09:56:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 09:56:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 09:56:06 [scrapy.extensions.telnet] INFO: Telnet Password: 30b452c7ba079065
2019-10-30 09:56:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 09:56:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 09:56:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 09:56:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 09:56:07 [scrapy.core.engine] INFO: Spider opened
2019-10-30 09:56:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 09:56:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 09:56:08 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 09:56:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4128,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 25411,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 1, 56, 8, 651978),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 1, 56, 7, 465465)}
2019-10-30 09:56:08 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 10:56:43 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 10:56:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 10:56:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 10:56:43 [scrapy.extensions.telnet] INFO: Telnet Password: 4cf2be9470b90e7d
2019-10-30 10:56:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 10:56:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 10:56:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 10:56:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 10:56:44 [scrapy.core.engine] INFO: Spider opened
2019-10-30 10:56:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 10:56:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 10:57:04 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 10:57:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6235,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36583,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 2, 57, 4, 700603),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 2, 56, 44, 837918)}
2019-10-30 10:57:04 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 10:57:50 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 10:57:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 10:57:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 10:57:50 [scrapy.extensions.telnet] INFO: Telnet Password: a0f6a3a2334aa1f9
2019-10-30 10:57:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 10:57:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 10:57:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 10:57:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 10:57:50 [scrapy.core.engine] INFO: Spider opened
2019-10-30 10:57:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 10:57:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 10:57:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://blog.csdn.net/ytusdc/article/details/78878995 via http://192.168.229.125:8050/render.html> (referer: None)
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy_splash\middleware.py", line 156, in process_spider_output
    for el in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\spiders\java_spider.py", line 28, in get_articleHtml
    print(response.content)
AttributeError: 'SplashTextResponse' object has no attribute 'content'
2019-10-30 10:57:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 10:57:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6235,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36583,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 2, 57, 56, 438516),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/AttributeError': 1,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 2, 57, 50, 340705)}
2019-10-30 10:57:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 10:58:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 10:58:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 10:58:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 10:58:46 [scrapy.extensions.telnet] INFO: Telnet Password: da44da6cd75b7fad
2019-10-30 10:58:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 10:58:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 10:58:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 10:58:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 10:58:46 [scrapy.core.engine] INFO: Spider opened
2019-10-30 10:58:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 10:58:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 10:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://blog.csdn.net/ytusdc/article/details/78878995 via http://192.168.229.125:8050/render.html> (referer: None)
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy_splash\middleware.py", line 156, in process_spider_output
    for el in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\spiders\java_spider.py", line 28, in get_articleHtml
    print(response.content)
AttributeError: 'SplashTextResponse' object has no attribute 'content'
2019-10-30 10:58:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 10:58:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 832,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36826,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 2, 58, 49, 917119),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/AttributeError': 1,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 2, 58, 46, 824687)}
2019-10-30 10:58:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 10:59:14 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 10:59:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 10:59:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 10:59:14 [scrapy.extensions.telnet] INFO: Telnet Password: 444d75e5f28290a7
2019-10-30 10:59:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 10:59:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 10:59:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 10:59:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 10:59:14 [scrapy.core.engine] INFO: Spider opened
2019-10-30 10:59:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 10:59:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 10:59:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 10:59:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 832,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36826,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 2, 59, 17, 285815),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 2, 59, 14, 786294)}
2019-10-30 10:59:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:13:38 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:13:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:13:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:13:38 [scrapy.extensions.telnet] INFO: Telnet Password: 2cf82ff087a64931
2019-10-30 11:13:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:13:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:13:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:13:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:13:38 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:13:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:13:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:13:41 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:13:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 849,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36826,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 13, 41, 817576),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 13, 38, 736187)}
2019-10-30 11:13:41 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:21:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:21:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:21:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:21:52 [scrapy.extensions.telnet] INFO: Telnet Password: b0db86d6769e06d1
2019-10-30 11:21:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:21:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:21:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:21:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:21:52 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:21:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:21:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:21:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:21:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 849,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36361,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 21, 56, 30222),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 21, 52, 533071)}
2019-10-30 11:21:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:41:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:41:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:41:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:41:24 [scrapy.extensions.telnet] INFO: Telnet Password: 39fa6bce4c689639
2019-10-30 11:41:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:41:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:41:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:41:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:41:24 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:41:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:41:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://so.csdn.net/so/search/s.do?p=1&q=java> (referer: None)
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy_splash\middleware.py", line 156, in process_spider_output
    for el in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\spiders\java_spider.py", line 23, in parse
    yield SplashRequest(url = 'baidu.com', callback = self.get_articleHtml, args={'wait': 0.5})
  File "d:\programdata\anaconda3\lib\site-packages\scrapy_splash\request.py", line 76, in __init__
    **kwargs)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: baidu.com
2019-10-30 11:41:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:41:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 235,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19122,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 41, 26, 49188),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 41, 24, 267571)}
2019-10-30 11:41:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:42:09 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:42:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:42:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:42:09 [scrapy.extensions.telnet] INFO: Telnet Password: 223fee5983b1d20f
2019-10-30 11:42:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:42:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:42:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:42:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:42:10 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:42:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:42:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:42:13 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:42:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 849,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36829,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 42, 13, 264521),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 42, 10, 107763)}
2019-10-30 11:42:13 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:43:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:43:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:43:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:43:16 [scrapy.extensions.telnet] INFO: Telnet Password: a9a2c0a3349f00a1
2019-10-30 11:43:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:43:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:43:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:43:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:43:16 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:43:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:43:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:43:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:43:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 852,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36361,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 43, 19, 668403),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 43, 16, 523855)}
2019-10-30 11:43:19 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:44:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:44:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:44:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:44:23 [scrapy.extensions.telnet] INFO: Telnet Password: 449158ab6b036a2a
2019-10-30 11:44:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:44:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:44:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:44:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:44:23 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:44:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:44:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:44:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:44:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 841,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 36829,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 44, 27, 454109),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'splash/render.html/request_count': 1,
 'splash/render.html/response_count/200': 1,
 'start_time': datetime.datetime(2019, 10, 30, 3, 44, 23, 906807)}
2019-10-30 11:44:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 11:45:37 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 11:45:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 11:45:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 11:45:37 [scrapy.extensions.telnet] INFO: Telnet Password: 90176eadfa6d1b93
2019-10-30 11:45:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 11:45:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 11:45:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 11:45:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 11:45:37 [scrapy.core.engine] INFO: Spider opened
2019-10-30 11:45:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 11:45:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 11:45:47 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 11:45:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1134,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160911,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 3, 45, 47, 627712),
 'item_scraped_count': 1,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2019, 10, 30, 3, 45, 37, 326989)}
2019-10-30 11:45:47 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 14:17:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 14:17:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 14:17:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 14:17:23 [scrapy.extensions.telnet] INFO: Telnet Password: 5d35a5944cdb3fec
2019-10-30 14:17:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 14:17:24 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2019-10-30 14:17:24 [twisted] CRITICAL: Unhandled error in Deferred:
2019-10-30 14:17:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "d:\programdata\anaconda3\lib\subprocess.py", line 709, in __init__
    restore_signals, start_new_session)
  File "d:\programdata\anaconda3\lib\subprocess.py", line 997, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 140, in create_instance
    return objcls.from_crawler(crawler, *args, **kwargs)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 58, in from_crawler
    service_args=crawler.settings.get('PHANTOMJS_SERVICE_ARGS'))
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 22, in __init__
    self.browser = webdriver.PhantomJS(service_args=service_args)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py", line 56, in __init__
    self.service.start()
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'phantomjs' executable needs to be in PATH. 

2019-10-30 15:19:19 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:19:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:19:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:19:19 [scrapy.extensions.telnet] INFO: Telnet Password: 5562b25085f78eca
2019-10-30 15:19:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:19:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:19:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:19:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 15:19:20 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:19:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:19:20 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:19:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:19:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=1&q=java>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 72, in process_request
    chrome_options = Options()
NameError: name 'Options' is not defined
2019-10-30 15:19:20 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:19:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.NameError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 19, 20, 727754),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 10, 30, 7, 19, 20, 503728)}
2019-10-30 15:19:20 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:20:03 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:20:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:20:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:20:03 [scrapy.extensions.telnet] INFO: Telnet Password: 653cc62da89d0a99
2019-10-30 15:20:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:20:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:20:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:20:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 15:20:04 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:20:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:20:04 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:20:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:20:36 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:20:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1147225,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 20, 36, 183085),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 20, 4, 302475)}
2019-10-30 15:20:36 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:21:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:21:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:21:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:21:35 [scrapy.extensions.telnet] INFO: Telnet Password: 63c0bc98fb6b7f5d
2019-10-30 15:21:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:21:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:21:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:21:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 15:21:36 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:21:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:21:36 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:21:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:22:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:22:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1152952,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 22, 6, 420981),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 21, 36, 689827)}
2019-10-30 15:22:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:23:08 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:23:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:23:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:23:08 [scrapy.extensions.telnet] INFO: Telnet Password: 13391084d7dfcc0e
2019-10-30 15:23:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:23:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:23:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:23:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-10-30 15:23:09 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:23:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:23:09 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:23:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:23:39 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:23:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1152248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 23, 39, 168418),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 23, 9, 906971)}
2019-10-30 15:23:39 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:24:39 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:24:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:24:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:24:39 [scrapy.extensions.telnet] INFO: Telnet Password: 0183c098cb8e8e6d
2019-10-30 15:24:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:24:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:24:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:24:40 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:24:40 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:24:40 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:24:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:25:10 [scrapy.core.scraper] ERROR: Error processing {'content': ['<div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    downloader.download_Html(html, article['article_title'][0], path)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'article_title'
2019-10-30 15:25:10 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:25:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1122913,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 25, 10, 765391),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 24, 40, 285242)}
2019-10-30 15:25:10 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:30:22 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:30:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:30:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:30:22 [scrapy.extensions.telnet] INFO: Telnet Password: 1233e5d9433cd152
2019-10-30 15:30:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:30:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:30:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:30:23 [twisted] CRITICAL: Unhandled error in Deferred:
2019-10-30 15:30:23 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "d:\programdata\anaconda3\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 13
    print(article['title'][0])
        ^
SyntaxError: invalid syntax
2019-10-30 15:30:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:30:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:30:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:30:46 [scrapy.extensions.telnet] INFO: Telnet Password: 00c5eebe933ff334
2019-10-30 15:30:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:30:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:30:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:30:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:30:47 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:30:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:30:47 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:30:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:31:19 [scrapy.core.scraper] ERROR: Error processing {'content': ['<div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 17, in process_item
    downloader.download_Html(html, article['article_title'][0], path)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'article_title'
2019-10-30 15:31:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:31:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1104821,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 31, 19, 915081),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 30, 47, 409778)}
2019-10-30 15:31:19 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:32:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:32:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:32:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:32:46 [scrapy.extensions.telnet] INFO: Telnet Password: 4bcf5a0e2ddc9bf2
2019-10-30 15:32:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:32:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:32:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:32:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:32:47 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:32:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:32:47 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:32:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:33:21 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:33:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1117921,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 33, 21, 58658),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 32, 47, 502532)}
2019-10-30 15:33:21 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:37:48 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:37:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:37:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:37:48 [scrapy.extensions.telnet] INFO: Telnet Password: f8692c583adadfdf
2019-10-30 15:37:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:37:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:37:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:37:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:37:50 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:37:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:37:50 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:37:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:38:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:38:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1134040,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 38, 26, 503717),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 37, 50, 581111)}
2019-10-30 15:38:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:48:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:48:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:48:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:48:35 [scrapy.extensions.telnet] INFO: Telnet Password: c65a0a1ba47e5adf
2019-10-30 15:48:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:48:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:48:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:48:36 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:48:36 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:48:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:48:36 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:48:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:49:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:49:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1121884,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 49, 7, 407557),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 48, 36, 299952)}
2019-10-30 15:49:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 15:58:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 15:58:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 15:58:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 15:58:31 [scrapy.extensions.telnet] INFO: Telnet Password: c31f2b7841443048
2019-10-30 15:58:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 15:58:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 15:58:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 15:58:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 15:58:32 [scrapy.core.engine] INFO: Spider opened
2019-10-30 15:58:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 15:58:32 [java_spider] INFO: Spider opened: java_spider
2019-10-30 15:58:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 15:59:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 15:59:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1079059,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 7, 59, 12, 516754),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 7, 58, 32, 77549)}
2019-10-30 15:59:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:00:54 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:00:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:00:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:00:54 [scrapy.extensions.telnet] INFO: Telnet Password: 458ecb59f17ff181
2019-10-30 16:00:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:00:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:00:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:00:55 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:00:55 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:00:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:00:55 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:00:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:01:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:01:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1152072,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 1, 25, 151459),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 8, 0, 55, 585070)}
2019-10-30 16:01:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:21:24 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:21:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:21:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:21:24 [scrapy.extensions.telnet] INFO: Telnet Password: 1f2d89cc068497ca
2019-10-30 16:21:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:21:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:21:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:21:25 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:21:25 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:21:25 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:21:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:21:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:21:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1103076,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 21, 56, 187413),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 8, 21, 25, 673457)}
2019-10-30 16:21:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:24:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:24:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:24:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:24:56 [scrapy.extensions.telnet] INFO: Telnet Password: d8f903b1d125d07f
2019-10-30 16:24:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:24:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:24:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:24:57 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:24:57 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:24:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:24:57 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:24:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:26:41 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:28:06 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 6 items (at 6 items/min)
2019-10-30 16:28:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:28:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10524586,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 28, 7, 533381),
 'item_scraped_count': 11,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 30, 8, 24, 57, 676731)}
2019-10-30 16:28:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:31:14 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:31:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:31:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:31:14 [scrapy.extensions.telnet] INFO: Telnet Password: fd9fc3df2e5fdd4f
2019-10-30 16:31:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:31:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:31:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:31:15 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:31:15 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:31:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:31:15 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:31:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:31:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:31:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1076034,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 31, 44, 408056),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 30, 8, 31, 15, 663061)}
2019-10-30 16:31:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:32:24 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:32:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:32:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:32:24 [scrapy.extensions.telnet] INFO: Telnet Password: 33c6e204b3843dbe
2019-10-30 16:32:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:32:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:32:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:32:25 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:32:25 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:32:25 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:32:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:34:08 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:35:21 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 6 items (at 6 items/min)
2019-10-30 16:35:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:35:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10604209,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 35, 22, 584210),
 'item_scraped_count': 11,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 30, 8, 32, 25, 862540)}
2019-10-30 16:35:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:36:12 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:36:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:36:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:36:12 [scrapy.extensions.telnet] INFO: Telnet Password: 8751521e5104c432
2019-10-30 16:36:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:36:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:36:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:36:15 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:36:15 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:36:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:36:15 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:36:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:36:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000169929CD588>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:29 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992A87DD8>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:30 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC8828>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC1CC0>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC1A20>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:34 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC1780>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:36 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AB97B8>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:37 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AB93C8>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:38 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AB90F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:40 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AB0390>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AA1438>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:42 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AA1B38>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:44 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC80F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF2630>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:46 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF2710>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF2D30>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF2E80>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF2F60>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B25780>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B258D0>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:54 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AA1F60>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:56 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B257B8>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:57 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3C160>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:36:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3C240>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3C048>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:01 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B25B70>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:02 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3C518>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:04 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55208>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:05 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55358>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:06 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55438>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:08 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55240>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:09 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55B70>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:10 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55C50>: Failed to establish a new connection: [WinError 10061] ',)': /session/6cbf4fe516af174e795912a0315c51ad/url
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/java1995_com/article/details/5953933>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992AC8AC8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC8AC8>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/u010371710/article/details/53913272>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992AC1240>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AC1240>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/byg184244735/article/details/78897376>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992AB05C0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AB05C0>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/weixin_42529125/article/details/80785351>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992AA1400>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AA1400>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/high2011/article/details/50451216>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992AF28D0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992AF28D0>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/AivenZhong/article/details/78507309>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B25128>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B25128>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/LCF_lxf_ldy/article/details/79437679>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B25400>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B25400>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/xuemengrui12/article/details/81104953>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B3C400>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3C400>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/youanyyou/article/details/80078481>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B3CBE0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B3CBE0>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/Applying/article/details/80575616>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B555F8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B555F8>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/DATA8866/article/details/79954531>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000016992B55E10>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 86, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52548): Max retries exceeded with url: /session/6cbf4fe516af174e795912a0315c51ad/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016992B55E10>: Failed to establish a new connection: [WinError 10061] ',))
2019-10-30 16:37:11 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:37:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 11,
 'downloader/exception_type_count/urllib3.exceptions.MaxRetryError': 11,
 'downloader/response_bytes': 153779,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 37, 11, 884811),
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'log_count/WARNING': 33,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 30, 8, 36, 15, 902252)}
2019-10-30 16:37:11 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:37:43 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:37:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:37:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:37:43 [scrapy.extensions.telnet] INFO: Telnet Password: df3f099c5addebc2
2019-10-30 16:37:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:37:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:37:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:37:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:37:44 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:37:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:37:44 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:37:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:39:24 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:40:36 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 6 items (at 6 items/min)
2019-10-30 16:40:36 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:40:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10627449,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 40, 36, 990495),
 'item_scraped_count': 11,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 30, 8, 37, 44, 195021)}
2019-10-30 16:40:36 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:46:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:46:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:46:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:46:05 [scrapy.extensions.telnet] INFO: Telnet Password: 4aa114796dc3a957
2019-10-30 16:46:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:46:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:46:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:46:06 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:46:06 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:46:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:46:06 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:46:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:47:48 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:49:00 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 6 items (at 6 items/min)
2019-10-30 16:49:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 16:49:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10698723,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 8, 49, 0, 748921),
 'item_scraped_count': 11,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 12,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 10, 30, 8, 46, 6, 654292)}
2019-10-30 16:49:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 16:50:20 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:50:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:50:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:50:20 [scrapy.extensions.telnet] INFO: Telnet Password: b23ae95c34b750b5
2019-10-30 16:50:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:50:21 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:50:21 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:50:21 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:52:32 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:53:31 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-10-30 16:53:31 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, '', None, 10054, None))': /session/113a793f1903d3ff05570f4293f498a9/source
2019-10-30 16:53:32 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-10-30 16:53:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000252F186F550>: Failed to establish a new connection: [WinError 10061] ',)': /session/113a793f1903d3ff05570f4293f498a9/source
2019-10-30 16:53:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000252F186F828>: Failed to establish a new connection: [WinError 10061] ',)': /session/113a793f1903d3ff05570f4293f498a9/source
2019-10-30 16:53:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 16:53:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 16:53:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 16:53:52 [scrapy.extensions.telnet] INFO: Telnet Password: 248a7b7c547ff3b8
2019-10-30 16:53:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 16:53:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 16:53:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 16:53:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 16:53:53 [scrapy.core.engine] INFO: Spider opened
2019-10-30 16:53:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:53:53 [java_spider] INFO: Spider opened: java_spider
2019-10-30 16:53:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 16:56:06 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 16:57:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 5 pages/min), scraped 5 items (at 5 items/min)
2019-10-30 16:57:59 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 7 items (at 2 items/min)
2019-10-30 16:59:31 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 11 items (at 4 items/min)
2019-10-30 17:01:09 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-10-30 17:02:54 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 6 pages/min), scraped 23 items (at 6 items/min)
2019-10-30 17:04:27 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 6 pages/min), scraped 29 items (at 6 items/min)
2019-10-30 17:05:58 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 6 pages/min), scraped 35 items (at 6 items/min)
2019-10-30 17:07:10 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 5 pages/min), scraped 41 items (at 6 items/min)
2019-10-30 17:08:11 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 4 pages/min), scraped 46 items (at 5 items/min)
2019-10-30 17:08:11 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 17:08:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 47787537,
 'downloader/response_count': 54,
 'downloader/response_status_count/200': 54,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 9, 8, 11, 740254),
 'item_scraped_count': 50,
 'log_count/INFO': 20,
 'request_depth_max': 1,
 'response_received_count': 54,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'start_time': datetime.datetime(2019, 10, 30, 8, 53, 53, 741289)}
2019-10-30 17:08:11 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 17:21:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 17:21:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 17:21:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 17:21:53 [scrapy.extensions.telnet] INFO: Telnet Password: aca5307595079e27
2019-10-30 17:21:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 17:21:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 17:21:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 17:21:54 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 17:21:54 [scrapy.core.engine] INFO: Spider opened
2019-10-30 17:21:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 17:21:54 [java_spider] INFO: Spider opened: java_spider
2019-10-30 17:21:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 17:24:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 17:25:30 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 5 items (at 5 items/min)
2019-10-30 17:27:00 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 11 items (at 6 items/min)
2019-10-30 17:28:29 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-10-30 17:30:53 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 6 pages/min), scraped 23 items (at 6 items/min)
2019-10-30 17:30:54 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 28 items (at 5 items/min)
2019-10-30 17:32:32 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 6 pages/min), scraped 29 items (at 1 items/min)
2019-10-30 17:34:03 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 6 pages/min), scraped 35 items (at 6 items/min)
2019-10-30 17:35:35 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 6 pages/min), scraped 41 items (at 6 items/min)
2019-10-30 17:36:17 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 3 pages/min), scraped 47 items (at 6 items/min)
2019-10-30 17:36:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 17:36:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49010940,
 'downloader/response_count': 54,
 'downloader/response_status_count/200': 54,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 9, 36, 17, 541500),
 'item_scraped_count': 50,
 'log_count/INFO': 20,
 'request_depth_max': 1,
 'response_received_count': 54,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'start_time': datetime.datetime(2019, 10, 30, 9, 21, 54, 516766)}
2019-10-30 17:36:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-30 17:38:33 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-30 17:38:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-30 17:38:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-30 17:38:33 [scrapy.extensions.telnet] INFO: Telnet Password: c04d662c75e2c37d
2019-10-30 17:38:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-30 17:38:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-30 17:38:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-30 17:38:34 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline']
2019-10-30 17:38:34 [scrapy.core.engine] INFO: Spider opened
2019-10-30 17:38:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 17:38:34 [java_spider] INFO: Spider opened: java_spider
2019-10-30 17:38:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-30 17:40:31 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-10-30 17:40:46 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-10-30 17:42:12 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 5 items (at 4 items/min)
2019-10-30 17:43:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 11 items (at 6 items/min)
2019-10-30 17:45:51 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-10-30 17:47:48 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 6 pages/min), scraped 23 items (at 6 items/min)
2019-10-30 17:49:50 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 6 pages/min), scraped 29 items (at 6 items/min)
2019-10-30 17:49:51 [scrapy.core.scraper] ERROR: Error processing {'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/machitaoX/article/details/85054039">https://blog.csdn.net/machitaoX/article/details/85054039</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2><a '
             'name="t0"></a><a id="1_0"></a>1</h2>\n'
             '<p>python 3<br>\n'
             '&gt;&gt;&gt; print(hello python inter)</p>\n'
             '<h2><a name="t1"></a><a id="2python_4"></a>2python</h2>\n'
             '<p>1geanyrootapt-get install geany<br>\n'
             '2pythonpython commands : compilepython 3<br>\n'
             'execute python 3</p>\n'
             '<h2><a name="t2"></a><a id="3_8"></a>3</h2>\n'
             '<p>Linux python ***.py</p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python:    execute']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 14, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-10-30 17:51:29 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 6 pages/min), scraped 34 items (at 5 items/min)
2019-10-30 17:51:30 [scrapy.core.scraper] ERROR: Error processing {'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/Rozol/article/details/71081854">https://blog.csdn.net/Rozol/article/details/71081854</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="python3-pythonpickle-shelve"><a name="t0"></a>Python3 '
             'Python(pickle / shelve)</h1>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<p><strong> Luzhuo ,.</strong> <br>\n'
             '<strong>: '
             '<code>http://blog.csdn.net/rozol/article/details/71081854</code></strong>  '
             '</p>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<blockquote>\n'
             '  <p>Python3.6.1 <br>\n'
             '  Less is more!</p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="pickle"><a name="t1"></a>pickle</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#coding=utf-8</span>\n'
             '<span class="hljs-comment"># pickledemo.py Pickle</span>\n'
             '<span class="hljs-comment"># Python</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> pickle\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">demo</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>)\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    strs = <span class="hljs-string">""</span>\n'
             '    num = <span class="hljs-number">123</span>\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    pickle.dump(lists, f) <span class="hljs-comment"># '
             '</span>\n'
             '    pickle.dump(strs, f)\n'
             '    pickle.dump(num, f)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    f.close()\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"rb+"</span>)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    data = pickle.load(f) <span class="hljs-comment"># '
             '</span>\n'
             '    <span class="hljs-keyword">print</span> (data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '\n'
             '    f.close()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">pickle_funs</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>) <span '
             'class="hljs-comment"># (:wb+)</span>\n'
             '\n'
             '    num = pickle.HIGHEST_PROTOCOL <span class="hljs-comment"># '
             '(4)</span>\n'
             '    num = pickle.DEFAULT_PROTOCOL <span class="hljs-comment"># '
             '(3) {3:bytes; 4:}</span>\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># dump(obj, file, protocol=None, '
             '*, fix_imports=True) // obj</span>\n'
             '    pickle.dump(lists, f)\n'
             '    <span class="hljs-comment"># dumps(obj, protocol=None, *, '
             'fix_imports=True) // objbytes</span>\n'
             '    bytes = pickle.dumps(lists)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># load(file, *, fix_imports=True, '
             'encoding="ASCII", errors="strict") // fileobj</span>\n'
             '    lists = pickle.load(f)\n'
             '    <span class="hljs-comment"># loads(bytes_object, *, '
             'fix_imports=True, encoding="ASCII", errors="strict") // '
             'bytesobj</span>\n'
             '    lists = pickle.loads(bytes)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-keyword">try</span>:\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.PicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.UnpicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> pickle.PickleError: '
             '<span class="hljs-comment"># pickling</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    demo()\n'
             '    pickle_funs()\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.898451;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li '
             'style="color: rgb(153, 153, 153);">55</li><li style="color: '
             'rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, '
             '153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li '
             'style="color: rgb(153, 153, 153);">59</li><li style="color: '
             'rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, '
             '153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li '
             'style="color: rgb(153, 153, 153);">63</li><li style="color: '
             'rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, '
             '153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li '
             'style="color: rgb(153, 153, 153);">67</li><li style="color: '
             'rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, '
             '153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li '
             'style="color: rgb(153, 153, 153);">71</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="shelve"><a name="t2"></a>shelve</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#!/usr/bin/env python</span>\n'
             '<span class="hljs-comment"># coding=utf-8</span>\n'
             '__author__ = <span class="hljs-string">\'Luzhuo\'</span>\n'
             '__date__ = <span class="hljs-string">\'2017/5/26\'</span>\n'
             '<span class="hljs-comment"># shelve_demo.py '
             ':Python</span>\n'
             '<span class="hljs-comment"># , , '
             'picklePython</span>\n'
             '<span class="hljs-comment"># pickle, '
             '</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> shelve\n'
             '\n'
             '\n'
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">Person</span><span '
             'class="hljs-params">(object)</span>:</span>\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__init__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        self.name = <span class="hljs-string">"luzhuo"</span>\n'
             '        self.age = <span class="hljs-number">21</span>\n'
             '\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__str__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        <span class="hljs-keyword">return</span> <span '
             'class="hljs-string">"name: {}, age: {}"</span>.format(self.name, '
             'self.age)\n'
             '\n'
             'path = <span class="hljs-string">"file.txt"</span>\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_write</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> write: <span '
             'class="hljs-comment"># </span>\n'
             '        write[<span class="hljs-string">"nums"</span>] = [<span '
             'class="hljs-number">1</span>, <span '
             'class="hljs-number">2</span>, <span '
             'class="hljs-number">3</span>, <span '
             'class="hljs-number">4</span>, <span '
             'class="hljs-number">5</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        write[<span class="hljs-string">"obj"</span>] = '
             'Person()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_read</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> read:  <span '
             'class="hljs-comment"># </span>\n'
             '        nums = read.get(<span '
             'class="hljs-string">"nums"</span>)  <span class="hljs-comment"># '
             '</span>\n'
             '        print(nums)\n'
             '        clazz = read[<span class="hljs-string">"obj"</span>]\n'
             '        print(clazz)\n'
             '\n'
             '        <span class="hljs-keyword">del</span> read[<span '
             'class="hljs-string">"obj"</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        print(<span class="hljs-string">"obj"</span> <span '
             'class="hljs-keyword">in</span> read)\n'
             '\n'
             '        keys = list(read.keys())  <span class="hljs-comment"># '
             'key</span>\n'
             '        print(keys)\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_func</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># , filename:, '
             'writeback:(True,), Shelf</span>\n'
             '    <span class="hljs-comment"># shelve.open(filename, '
             "flag='c', protocol=None, writeback=False)</span>\n"
             '    d = shelve.open(path)\n'
             '\n'
             '    <span class="hljs-comment"># Shelf</span>\n'
             '    <span class="hljs-comment"># </span>\n'
             '    <span class="hljs-comment"># get(self, key, default=None) // '
             ' == data = shelf["key"]</span>\n'
             '    data = d.get(<span class="hljs-string">"key"</span>)\n'
             '    d.sync()  <span class="hljs-comment"># (,)</span>\n'
             '    d.close()  <span class="hljs-comment"># </span>\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># class shelve.Shelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8')</span>\n"
             '    <span class="hljs-comment"># class shelve.BsdDbShelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8') // "
             'Shelf</span>\n'
             '    <span class="hljs-comment"># class '
             "shelve.DbfilenameShelf(filename, flag='c', protocol=None, "
             'writeback=False) // Shelf</span>\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    shelve_write()\n'
             '    shelve_read()\n'
             '\n'
             '    <span class="hljs-comment"># shelve_func()</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.898451;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li '
             'style="color: rgb(153, 153, 153);">55</li><li style="color: '
             'rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, '
             '153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li '
             'style="color: rgb(153, 153, 153);">59</li><li style="color: '
             'rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, '
             '153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li '
             'style="color: rgb(153, 153, 153);">63</li><li style="color: '
             'rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, '
             '153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li '
             'style="color: rgb(153, 153, 153);">67</li><li style="color: '
             'rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, '
             '153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li '
             'style="color: rgb(153, 153, 153);">71</li><li style="color: '
             'rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, '
             '153);">73</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python3 Python(pickle / shelve)']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 14, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-10-30 17:51:47 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 1 pages/min), scraped 39 items (at 5 items/min)
2019-10-30 17:51:47 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-30 17:51:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 41544097,
 'downloader/response_count': 46,
 'downloader/response_status_count/200': 46,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 30, 9, 51, 47, 537241),
 'item_scraped_count': 40,
 'log_count/ERROR': 2,
 'log_count/INFO': 19,
 'request_depth_max': 1,
 'response_received_count': 46,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 46,
 'scheduler/enqueued/memory': 46,
 'start_time': datetime.datetime(2019, 10, 30, 9, 38, 34, 747882)}
2019-10-30 17:51:47 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 13:45:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 13:45:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 13:45:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 13:45:30 [scrapy.extensions.telnet] INFO: Telnet Password: 88241c8bc1edc880
2019-10-31 13:45:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 13:45:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 13:45:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 13:45:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 13:45:31 [scrapy.core.engine] INFO: Spider opened
2019-10-31 13:45:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 13:45:31 [java_spider] INFO: Spider opened: java_spider
2019-10-31 13:45:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 13:46:03 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 13:46:03 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ytusdc/article/details/78878995">https://blog.csdn.net/ytusdc/article/details/78878995</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1364, "Field 'Aid' doesn't have a default value")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    self.__session.commit()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 943, in commit
    self.transaction.commit()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 467, in commit
    self._prepare_impl()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 447, in _prepare_impl
    self.session.flush()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2254, in flush
    self._flush(objects)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2380, in _flush
    transaction.rollback(_capture_exception=True)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 187, in reraise
    raise value
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2344, in _flush
    flush_context.execute()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\unitofwork.py", line 391, in execute
    rec.execute(self)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\unitofwork.py", line 556, in execute
    uow
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\persistence.py", line 181, in save_obj
    mapper, table, insert)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\persistence.py", line 866, in _emit_insert_statements
    execute(statement, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1364, "Field 'Aid' doesn't have a default value") [SQL: 'INSERT INTO article_content (`Atitle`, `Aabstract`, `Acontent`) VALUES (%(Atitle)s, %(Aabstract)s, %(Acontent)s)'] [parameters: {'Atitle': 'Java ', 'Aabstract': None, 'Acontent': '<article class="baidu_pl">\n                <div id="article_content" class="article_content clearfix" style="height: 1166px; overflow: hidden;">\n   ... (16620 characters truncated) ... csdn.net/20171223113657527" alt=""></p>\n<p><br></p>\n<p></p>\n                                    </div>\n                    </div>\n    </article>'}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 13:46:03 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 13:46:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1135845,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 5, 46, 3, 848534),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 5, 45, 31, 883682)}
2019-10-31 13:46:03 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 13:48:00 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 13:48:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 13:48:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 13:48:00 [scrapy.extensions.telnet] INFO: Telnet Password: eed8e7022ac4a704
2019-10-31 13:48:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 13:48:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 13:48:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 13:48:02 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 13:48:02 [scrapy.core.engine] INFO: Spider opened
2019-10-31 13:48:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 13:48:02 [java_spider] INFO: Spider opened: java_spider
2019-10-31 13:48:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 13:48:34 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 13:48:34 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ytusdc/article/details/78878995">https://blog.csdn.net/ytusdc/article/details/78878995</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1364, "Field 'Aid' doesn't have a default value")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    self.__session.commit()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 943, in commit
    self.transaction.commit()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 467, in commit
    self._prepare_impl()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 447, in _prepare_impl
    self.session.flush()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2254, in flush
    self._flush(objects)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2380, in _flush
    transaction.rollback(_capture_exception=True)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 187, in reraise
    raise value
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\session.py", line 2344, in _flush
    flush_context.execute()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\unitofwork.py", line 391, in execute
    rec.execute(self)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\unitofwork.py", line 556, in execute
    uow
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\persistence.py", line 181, in save_obj
    mapper, table, insert)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\persistence.py", line 866, in _emit_insert_statements
    execute(statement, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1364, "Field 'Aid' doesn't have a default value") [SQL: 'INSERT INTO article_content (`Atitle`, `Aabstract`, `Acontent`) VALUES (%(Atitle)s, %(Aabstract)s, %(Acontent)s)'] [parameters: {'Atitle': 'Java ', 'Aabstract': None, 'Acontent': '<article class="baidu_pl">\n                <div id="article_content" class="article_content clearfix" style="height: 1166px; overflow: hidden;">\n   ... (16620 characters truncated) ... csdn.net/20171223113657527" alt=""></p>\n<p><br></p>\n<p></p>\n                                    </div>\n                    </div>\n    </article>'}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 13:48:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 13:48:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1115196,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 5, 48, 34, 458414),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 5, 48, 2, 129568)}
2019-10-31 13:48:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:18:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:18:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:18:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:18:07 [scrapy.extensions.telnet] INFO: Telnet Password: 7f6dee199192d312
2019-10-31 14:18:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:18:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:18:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:18:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:18:08 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:18:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:18:08 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:18:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 14:18:39 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 14:18:40 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 14:18:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1056892,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 6, 18, 40, 116819),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 18, 8, 361981)}
2019-10-31 14:18:40 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:39:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:39:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:39:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:39:51 [scrapy.extensions.telnet] INFO: Telnet Password: ce47dffc654bb428
2019-10-31 14:39:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:39:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:39:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:39:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:39:53 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:39:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:39:53 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:39:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 14:40:24 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 14:40:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 14:40:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1135698,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 6, 40, 25, 10120),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 39, 53, 133339)}
2019-10-31 14:40:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:48:49 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:48:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:48:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:48:49 [scrapy.extensions.telnet] INFO: Telnet Password: f8d91501daee93eb
2019-10-31 14:48:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:48:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:48:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:48:50 [twisted] CRITICAL: Unhandled error in Deferred:
2019-10-31 14:48:50 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "d:\programdata\anaconda3\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34
    content = = re.sub(r'<[\s\S]*?>','',content)
              ^
SyntaxError: invalid syntax
2019-10-31 14:50:03 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:50:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:50:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:50:03 [scrapy.extensions.telnet] INFO: Telnet Password: 404df5b5378b8241
2019-10-31 14:50:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:50:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:50:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:50:05 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:50:05 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:50:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:50:05 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:50:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 14:51:05 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 14:51:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-10-31 14:51:05 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 14:51:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1103392,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 6, 51, 5, 464700),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 50, 5, 132225)}
2019-10-31 14:51:05 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:55:14 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:55:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:55:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:55:14 [scrapy.extensions.telnet] INFO: Telnet Password: 881865009f49fdd8
2019-10-31 14:55:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:55:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:55:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:55:16 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:55:16 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:55:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:55:16 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:55:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 14:55:50 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 14:55:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 14:55:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1056629,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 6, 55, 50, 241499),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 55, 16, 55548)}
2019-10-31 14:55:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:56:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:56:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:56:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:56:30 [scrapy.extensions.telnet] INFO: Telnet Password: eac0a41632a65f96
2019-10-31 14:56:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:56:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:56:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:56:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:56:31 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:56:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:56:31 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:56:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 14:57:06 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 14:57:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 14:57:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1103559,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 6, 57, 6, 707782),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 56, 31, 835599)}
2019-10-31 14:57:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 14:59:26 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 14:59:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 14:59:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 14:59:26 [scrapy.extensions.telnet] INFO: Telnet Password: de27b58a2396fa9a
2019-10-31 14:59:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 14:59:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 14:59:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 14:59:27 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 14:59:27 [scrapy.core.engine] INFO: Spider opened
2019-10-31 14:59:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 14:59:27 [java_spider] INFO: Spider opened: java_spider
2019-10-31 14:59:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:00:00 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 15:00:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:00:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1118452,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 0, 0, 392374),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 6, 59, 27, 880491)}
2019-10-31 15:00:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:07:45 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:07:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:07:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:07:45 [scrapy.extensions.telnet] INFO: Telnet Password: 81039dd3e23efe68
2019-10-31 15:07:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:07:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:07:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:07:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:07:47 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:07:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:07:47 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:07:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:09:35 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-10-31 15:09:35 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-10-31 15:10:08 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 15:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-10-31 15:10:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-10-31 15:10:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1105431,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 10, 9, 66416),
 'item_scraped_count': 1,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 7, 47, 281831)}
2019-10-31 15:10:09 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-10-31 15:10:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:10:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:10:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:10:18 [scrapy.extensions.telnet] INFO: Telnet Password: 25d80d240d49c560
2019-10-31 15:10:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:10:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:10:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:10:20 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:10:20 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:10:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:10:20 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:10:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:11:09 [scrapy.crawler] INFO: Received SIGBREAK, shutting down gracefully. Send again to force 
2019-10-31 15:12:01 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:12:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:12:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:12:01 [scrapy.extensions.telnet] INFO: Telnet Password: ef55b106eda8eef2
2019-10-31 15:12:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:12:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:12:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:12:03 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:12:03 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:12:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:12:03 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:12:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:13:01 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-10-31 15:13:01 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-10-31 15:14:23 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 15:14:23 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-10-31 15:14:23 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-10-31 15:14:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1100951,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 14, 23, 832924),
 'item_scraped_count': 1,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 12, 3, 206261)}
2019-10-31 15:14:23 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-10-31 15:14:41 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:14:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:14:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:14:41 [scrapy.extensions.telnet] INFO: Telnet Password: aeca8ac7f84a9752
2019-10-31 15:14:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:14:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:14:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:14:43 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:14:43 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:14:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:14:43 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:14:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:15:53 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:15:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ytusdc/article/details/78878995">https://blog.csdn.net/ytusdc/article/details/78878995</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 33, in process_item
    content = re.sub(r'<[\s\S]*?>','',article['content'][0])
UnboundLocalError: local variable 'content' referenced before assignment
2019-10-31 15:15:53 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:15:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1134847,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 15, 53, 878824),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 14, 43, 57400)}
2019-10-31 15:15:53 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:26:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:26:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:26:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:26:57 [scrapy.extensions.telnet] INFO: Telnet Password: 91bebc982ab09be9
2019-10-31 15:26:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:26:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:26:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:26:59 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:26:59 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:26:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:26:59 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:26:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:27:31 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 15:27:32 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:27:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1101785,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 27, 32, 148445),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 26, 59, 574584)}
2019-10-31 15:27:32 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:33:37 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:33:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:33:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:33:37 [scrapy.extensions.telnet] INFO: Telnet Password: 4b26132b7b9159e6
2019-10-31 15:33:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:33:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:33:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:33:38 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:33:38 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:33:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:33:38 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:33:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:34:10 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 15:34:10 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:34:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1122593,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 34, 10, 496207),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 33, 38, 689388)}
2019-10-31 15:34:10 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:51:15 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:51:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:51:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:51:15 [scrapy.extensions.telnet] INFO: Telnet Password: ef4f2e237f141490
2019-10-31 15:51:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:51:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:51:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:51:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:51:17 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:51:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:51:17 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:51:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:51:52 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ytusdc/article/details/78878995">https://blog.csdn.net/ytusdc/article/details/78878995</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:51:52 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:51:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1073566,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 51, 52, 967739),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 7, 51, 17, 90675)}
2019-10-31 15:51:52 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:52:45 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:52:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:52:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:52:45 [scrapy.extensions.telnet] INFO: Telnet Password: 28735119e520b950
2019-10-31 15:52:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:52:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:52:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:52:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:52:47 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:52:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:52:47 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:52:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:53:50 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:53:51 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.910399;"><li '
             'style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.910399;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.910399;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.910399;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li><li style="color: '
             'rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.910399;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:53:51 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:53:51 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:53:51 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:53:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 2989093,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 53, 51, 428846),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 7, 52, 47, 80161)}
2019-10-31 15:53:51 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 15:58:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 15:58:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 15:58:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 15:58:17 [scrapy.extensions.telnet] INFO: Telnet Password: 2e89de53e7dda1db
2019-10-31 15:58:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 15:58:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 15:58:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 15:58:18 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 15:58:18 [scrapy.core.engine] INFO: Spider opened
2019-10-31 15:58:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:58:18 [java_spider] INFO: Spider opened: java_spider
2019-10-31 15:58:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 15:59:22 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 15:59:22 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:59:22 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:59:23 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 15:59:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 15:59:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3051282,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 7, 59, 23, 150451),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 7, 58, 18, 622737)}
2019-10-31 15:59:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:00:26 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:00:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:00:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:00:26 [scrapy.extensions.telnet] INFO: Telnet Password: e3c925fb3568d882
2019-10-31 16:00:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:00:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:00:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:00:27 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:00:27 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:00:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:00:27 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:00:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:01:53 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:01:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:01:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:01:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:01:53 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:01:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3097747,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 1, 53, 778302),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 0, 27, 704666)}
2019-10-31 16:01:53 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:02:34 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:02:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:02:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:02:34 [scrapy.extensions.telnet] INFO: Telnet Password: f1a4e9ba06fd03ae
2019-10-31 16:02:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:02:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:02:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:02:36 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:02:36 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:02:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:02:36 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:02:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:03:43 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:03:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:03:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:03:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 35, in process_item
    ac = self.__session.query(ArticleContent).filter(Atitle = article['title'][0]).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:03:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:03:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3089558,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 3, 43, 642017),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 2, 36, 81508)}
2019-10-31 16:03:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:12:39 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:12:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:12:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:12:39 [scrapy.extensions.telnet] INFO: Telnet Password: 9f83f30e872ffd8e
2019-10-31 16:12:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:12:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:12:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:12:40 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:12:40 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:12:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:12:40 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:12:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:13:46 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:13:46 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.988358;"><li '
             'style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.988358;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.988358;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style="opacity: 0.988358;"><li '
             'style="color: rgb(153, 153, 153);">1</li><li style="color: '
             'rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, '
             '153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li '
             'style="color: rgb(153, 153, 153);">5</li><li style="color: '
             'rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.988358;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    articlecontent = self.__session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:13:46 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    articlecontent = self.__session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:13:46 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 34, in process_item
    articlecontent = self.__session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:13:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:13:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3062433,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 13, 46, 677178),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 12, 40, 928384)}
2019-10-31 16:13:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:15:42 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:15:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:15:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:15:42 [scrapy.extensions.telnet] INFO: Telnet Password: 8b3c975d3fecf9fc
2019-10-31 16:15:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:15:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:15:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:15:43 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:15:43 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:15:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:15:43 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:15:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:16:48 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:16:49 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 29, in process_item
    articlecontent = session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:16:49 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 29, in process_item
    articlecontent = session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:16:49 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 29, in process_item
    articlecontent = session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:16:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:16:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3031238,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 16, 49, 372898),
 'log_count/ERROR': 3,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 15, 43, 902122)}
2019-10-31 16:16:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:17:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:17:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:17:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:17:56 [scrapy.extensions.telnet] INFO: Telnet Password: 9cc0bae71b385a02
2019-10-31 16:17:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:17:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:17:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:17:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:17:58 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:17:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:17:58 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:17:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:22:26 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, '', None, 10054, None))': /session/106fb626e2f4e38a414397994c5fba9e/source
2019-10-31 16:22:34 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:22:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:22:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:22:34 [scrapy.extensions.telnet] INFO: Telnet Password: 5ace346a66f3a4fd
2019-10-31 16:22:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:22:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:22:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:22:35 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:22:35 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:22:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:22:35 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:22:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:23:26 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'java',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ytusdc/article/details/78878995">https://blog.csdn.net/ytusdc/article/details/78878995</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p style="color:rgb(85,85,85);font-family:verdana, \'ms song\', '
             "'', Arial, '', Helvetica, "
             'sans-serif;font-size:12px;">\n'
             '</p>\n'
             '<pre><code class="language-java hljs"><ol class="hljs-ln" '
             'style="width:968px"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">package</span> '
             'imge;</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Color;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Font;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Graphics2D;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.Image;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.awt.image.BufferedImage;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'java.io.FileOutputStream;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'javax.swing.ImageIcon;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGCodec;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGEncodeParam;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'com.sun.image.codec.jpeg.JPEGImageEncoder;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">public</span> '
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">ImageEdit</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">void</span> <span '
             'class="hljs-title">main</span><span '
             'class="hljs-params">(String[] a)</span> '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageEdit.createStringMark(<span '
             'class="hljs-string">"D://A.jpg"</span>, <span '
             'class="hljs-string">""</span>,<span '
             'class="hljs-string">"d://B.jpg"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t}</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">      <span class="hljs-comment"><span '
             'class="hljs-comment">/**</span></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> filePath '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> markContent '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * <span '
             'class="hljs-doctag">@param</span> outPath  '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">\t     * '
             '</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-comment">       '
             '*/</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="28"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-comment">//jpg</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="29"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-function"><span '
             'class="hljs-keyword">public</span> <span '
             'class="hljs-keyword">static</span> <span '
             'class="hljs-keyword">boolean</span> <span '
             'class="hljs-title">createStringMark</span><span '
             'class="hljs-params">(String filePath,String markContent,String '
             'outPath)</span> </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="30"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="31"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImageIcon imgIcon=<span '
             'class="hljs-keyword">new</span> ImageIcon(filePath); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="32"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tImage theImg =imgIcon.getImage(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="33"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'width=theImg.getWidth(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getWidth(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="34"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">int</span> '
             'height= theImg.getHeight(<span '
             'class="hljs-keyword">null</span>)==-<span '
             'class="hljs-number">1</span>?<span '
             'class="hljs-number">200</span>:theImg.getHeight(<span '
             'class="hljs-keyword">null</span>); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="35"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(width);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="36"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(height);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="37"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t'
             'System.out.println(theImg);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="38"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tBufferedImage bimage = <span '
             'class="hljs-keyword">new</span> BufferedImage(width,height, '
             'BufferedImage.TYPE_INT_RGB); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="39"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tGraphics2D g=bimage.createGraphics(); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="40"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="41"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tColor mycolor = Color.red; '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="42"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        g.setColor(mycolor); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="43"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setBackground(Color.red); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="44"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawImage(theImg, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-number">0</span>, <span '
             'class="hljs-keyword">null</span> ); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="45"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.setFont(<span '
             'class="hljs-keyword">new</span> Font(<span '
             'class="hljs-string">""</span>,Font.PLAIN,<span '
             'class="hljs-number">50</span>)); <span '
             'class="hljs-comment">// </span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="46"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.drawString(markContent,width/<span '
             'class="hljs-number">2</span>,height/<span '
             'class="hljs-number">2</span>); <span class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="47"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tg.dispose(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="48"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span class="hljs-keyword">try</span> '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="49"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="50"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tFileOutputStream out=<span '
             'class="hljs-keyword">new</span> FileOutputStream(outPath); <span '
             'class="hljs-comment">// '
             '</span></div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="51"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGImageEncoder encoder '
             '=JPEGCodec.createJPEGEncoder(out); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="52"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tJPEGEncodeParam param = '
             'encoder.getDefaultJPEGEncodeParam(bimage); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="53"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tparam.setQuality(<span '
             'class="hljs-number">100</span>, <span '
             'class="hljs-keyword">true</span>);  <span '
             'class="hljs-comment">//</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="54"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tencoder.encode(bimage, param); '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="55"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\tout.close(); </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="56"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="57"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">catch</span>(Exception e) '
             '</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="58"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t{ <span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">false</span>; } </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="59"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t<span '
             'class="hljs-keyword">return</span> <span '
             'class="hljs-keyword">true</span>; </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="60"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">\t\t} </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="61"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="62"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">}</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:center;"><br></p>\n'
             '<p style="text-align:left;">\xa0 </p>\n'
             '<p style="text-align:center;">\xa0<img '
             'src="https://img-blog.csdn.net/20171223113657527" alt=""></p>\n'
             '<p><br></p>\n'
             '<p></p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Java ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 29, in process_item
    articlecontent = session.query(ArticleContent).filter(Atitle = title).first()
TypeError: filter() got an unexpected keyword argument 'Atitle'
2019-10-31 16:23:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:23:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1098439,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 23, 26, 156489),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 8, 22, 35, 987805)}
2019-10-31 16:23:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:24:42 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:24:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:24:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:24:42 [scrapy.extensions.telnet] INFO: Telnet Password: ee5e31e64add0454
2019-10-31 16:24:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:24:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:24:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:24:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:24:44 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:24:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:24:44 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:24:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:25:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:25:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1118329,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 25, 15, 65885),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 8, 24, 44, 291119)}
2019-10-31 16:25:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:26:20 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:26:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:26:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:26:21 [scrapy.extensions.telnet] INFO: Telnet Password: 540f1dc520ee0395
2019-10-31 16:26:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:26:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:26:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:26:22 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:26:22 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:26:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:26:22 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:26:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:26:53 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 16:26:53 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:26:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1055613,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 26, 53, 943320),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 10, 31, 8, 26, 22, 362504)}
2019-10-31 16:26:53 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:31:34 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:31:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:31:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:31:34 [scrapy.extensions.telnet] INFO: Telnet Password: c000dca016867ff2
2019-10-31 16:31:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:31:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:31:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:31:36 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:31:36 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:31:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:31:36 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:31:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:32:41 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:32:42 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 16:32:45 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:32:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 2989787,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 32, 45, 125672),
 'item_scraped_count': 3,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 31, 36, 17709)}
2019-10-31 16:32:45 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:34:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:34:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:34:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:34:23 [scrapy.extensions.telnet] INFO: Telnet Password: 011e0223a81a481d
2019-10-31 16:34:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:34:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:34:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:34:24 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:34:24 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:34:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:34:24 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:34:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:35:54 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:36:26 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:36:27 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 16:36:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 16:36:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 2955160,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 8, 36, 29, 565567),
 'item_scraped_count': 3,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 8, 34, 24, 423382)}
2019-10-31 16:36:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 16:38:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 16:38:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 16:38:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 16:38:47 [scrapy.extensions.telnet] INFO: Telnet Password: 162e61a0d105fc25
2019-10-31 16:38:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 16:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 16:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 16:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 16:38:48 [scrapy.core.engine] INFO: Spider opened
2019-10-31 16:38:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:38:49 [java_spider] INFO: Spider opened: java_spider
2019-10-31 16:38:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 16:40:23 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:41:33 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 16:41:34 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 16:42:18 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2019-10-31 16:44:07 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-10-31 16:45:46 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 11 items (at 6 items/min)
2019-10-31 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2019-10-31 16:48:15 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-10-31 16:50:02 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 6 pages/min), scraped 23 items (at 6 items/min)
2019-10-31 16:51:46 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 6 pages/min), scraped 29 items (at 6 items/min)
2019-10-31 16:51:52 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 0 pages/min), scraped 34 items (at 5 items/min)
2019-10-31 16:53:56 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 6 pages/min), scraped 35 items (at 1 items/min)
2019-10-31 16:59:39 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 6 pages/min), scraped 41 items (at 6 items/min)
2019-10-31 17:00:22 [scrapy.extensions.logstats] INFO: Crawled 53 pages (at 2 pages/min), scraped 47 items (at 6 items/min)
2019-10-31 17:00:24 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:00:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 47709727,
 'downloader/response_count': 53,
 'downloader/response_status_count/200': 53,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 0, 24, 244678),
 'item_scraped_count': 49,
 'log_count/INFO': 23,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 53,
 'scheduler/dequeued': 53,
 'scheduler/dequeued/memory': 53,
 'scheduler/enqueued': 53,
 'scheduler/enqueued/memory': 53,
 'start_time': datetime.datetime(2019, 10, 31, 8, 38, 49, 15529)}
2019-10-31 17:00:24 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 17:04:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:04:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:04:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:04:06 [scrapy.extensions.telnet] INFO: Telnet Password: 6cc409c380b5563b
2019-10-31 17:04:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:04:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:04:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:04:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:04:08 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:04:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:04:08 [java_spider] INFO: Spider opened: java_spider
2019-10-31 17:04:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:05:43 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:06:49 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:06:50 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:07:31 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2019-10-31 17:08:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 5 items (at 0 items/min)
2019-10-31 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 11 items (at 6 items/min)
2019-10-31 17:12:03 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-10-31 17:13:33 [scrapy.extensions.logstats] INFO: Crawled 32 pages (at 5 pages/min), scraped 23 items (at 6 items/min)
2019-10-31 17:15:16 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 6 pages/min), scraped 29 items (at 6 items/min)
2019-10-31 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 7 pages/min), scraped 35 items (at 6 items/min)
2019-10-31 17:19:43 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 6 pages/min), scraped 41 items (at 6 items/min)
2019-10-31 17:20:25 [scrapy.extensions.logstats] INFO: Crawled 53 pages (at 2 pages/min), scraped 47 items (at 6 items/min)
2019-10-31 17:20:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:20:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 47402166,
 'downloader/response_count': 53,
 'downloader/response_status_count/200': 53,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 20, 27, 93623),
 'item_scraped_count': 49,
 'log_count/INFO': 21,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 53,
 'scheduler/dequeued': 53,
 'scheduler/dequeued/memory': 53,
 'scheduler/enqueued': 53,
 'scheduler/enqueued/memory': 53,
 'start_time': datetime.datetime(2019, 10, 31, 9, 4, 8, 179496)}
2019-10-31 17:20:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 17:28:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:28:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:30:36 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:30:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:36:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:36:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:36:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:36:18 [scrapy.extensions.telnet] INFO: Telnet Password: 48ab5efa9bfec452
2019-10-31 17:36:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:36:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:36:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:36:21 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:36:21 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:36:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:36:21 [python_spider] INFO: Spider opened: python_spider
2019-10-31 17:36:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:37:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:38:49 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:38:50 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:38:50 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011269573/article/details/78705233">https://blog.csdn.net/u011269573/article/details/78705233</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h3 '
             'id="1easygui-"><a name="t0"></a>1.EasyGui </h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1easyguicmdeasygui">1.EasyGuicmdEasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="2pythonexe-easygui">2.python.exe EasyGui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs tex '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:<span class="hljs-command">\\python</span><span '
             'class="hljs-command">\\easygui</span>-0.96&gt;D:<span '
             'class="hljs-command">\\python</span><span '
             'class="hljs-command">\\Python</span>36<span '
             'class="hljs-command">\\python</span>.exe setup.py install<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t1"></a>2.</h3>\n'
             '\n'
             '<p>easygui <br>\n'
             '<a href="http://bbs.fishc.com/thread-46069-1-1.html" '
             'rel="nofollow" target="_blank" '
             'data-token="5f5836f81340ae3fb7cfac0319db6a5e">EasyGui</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 id="1easygui">1.easygui</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs haskell '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-import"><span '
             'class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> gui</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="2"><a name="t2"></a>2.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1ccbox-ccboxmsg-title-choices-image-none">1.ccbox() '
             'ccbox(msg, title, choices=( , ), image = None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-keyword">import</span> sys\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ccbox</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> g.ccbox(<span '
             'class="hljs-string">\'ccbox\'</span>,<span '
             'class="hljs-string">\'ccbox\'</span>,choices=(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>)):\n'
             '        g.msgbox(<span class="hljs-string">\'\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        sys.exit(<span class="hljs-number">0</span>)\n'
             'ccbox()<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230234415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2msgbox-msgboxmsg-title-okbuttonok-imagenone">2.msgbox() '
             'msgbox(msg, title, ok_button=ok, image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">msgbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.msgbox(msg, title, ok_button=<span '
             'class="hljs-string">\'ok\'</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'msgbox(msg = <span class="hljs-string">\'content\'</span>,title '
             '= <span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230319672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3ynbox-ynboxmsg-title-choicesyesno-imagenone">3.ynbox() '
             'ynbox(msg, title, choices=(Yes,No), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">ynbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.ynbox(msg, title, choices=(<span '
             'class="hljs-string">\'Yes\'</span>,<span '
             'class="hljs-string">\'No\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'ynbox(msg = <span class="hljs-string">\'content\'</span>,title = '
             '<span class="hljs-string">\'title\'</span>)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230659871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="4buttonbox-buttonboxmsg-title-choices-imagenone">4.buttonbox() '
             'buttonbox(msg, title, choices=( , , ), image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">buttonbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.buttonbox(msg, title, choices=(<span '
             'class="hljs-string">\'button1\'</span>,<span '
             'class="hljs-string">\'button2\'</span>,<span '
             'class="hljs-string">\'button3\'</span>),image=<span '
             'class="hljs-keyword">None</span>)\n'
             '\n'
             'buttonbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230813479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="3"><a name="t3"></a>3.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1choicebox-choiceboxmsg-title-choices">1.choicebox() '
             'choicebox(msg, title, choices=( , , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">choicebox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    g.choicebox(msg, title, choices=(<span '
             'class="hljs-string">\'choice1\'</span>,<span '
             'class="hljs-string">\'mchoice2\'</span>,<span '
             'class="hljs-string">\'nchoice3\'</span>))\n'
             '\n'
             'choicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203230922070?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2multchoicebox-multchoiceboxmsg-title-choices">2.multchoicebox() '
             'multchoicebox(msg, title, choices = ( ,  , ))</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multchoicebox</span><span '
             'class="hljs-params">(msg,title,select)</span>:</span>\n'
             '    msg = g.multchoicebox(msg, title, choices = select)\n'
             '    print(msg) <span class="hljs-comment"># [\'s1\', '
             "'s3']13</span>\n"
             'choices = (<span class="hljs-string">\'s1\'</span>,<span '
             'class="hljs-string">\'s2\'</span>,<span '
             'class="hljs-string">\'s3\'</span>,<span '
             'class="hljs-string">\'s4\'</span>)\n'
             'multchoicebox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>,select = choices)<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231105059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h3 id="4"><a name="t4"></a>4.</h3>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="1enterbox-enterboxmsg-title-default-strip-false-imagenone">1.enterbox() '
             'enterbox(msg, title, default=, strip = False, image=None)</h4>\n'
             '\n'
             '<p>strip = False  <br>\n'
             'strip = True </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">enterbox</span><span '
             'class="hljs-params">(msg,title)</span>:</span>\n'
             '    msg = g.enterbox(msg, title, default=<span '
             'class="hljs-string">\'\'</span>,strip = <span '
             'class="hljs-keyword">False</span>,image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># python</span>\n'
             '\n'
             'enterbox(msg = <span '
             'class="hljs-string">\'content\'</span>,title = <span '
             'class="hljs-string">\'title\'</span>)<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231149794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="2integerbox-integerboxmsg-title-default-lowerbound0-upperbound99-imagenone">2.integerbox() '
             'integerbox(msg, title, default=, lowerbound=0, upperbound=99, '
             'image=None)</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">integerbox</span><span '
             'class="hljs-params">(msg,title,minNum,maxNum)</span>:</span>\n'
             '    msg = g.integerbox(msg, title,default=<span '
             'class="hljs-string">\'\'</span>, lowerbound=minNum, '
             'upperbound=maxNum, image=<span '
             'class="hljs-keyword">None</span>)\n'
             '    print(msg) <span class="hljs-comment"># 85</span>\n'
             'integerbox(<span class="hljs-string">\'content\'</span>, <span '
             'class="hljs-string">\'title\'</span>,<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">99</span>)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171203231219950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h4 '
             'id="3multenterbox-multenterboxmsg-title-fields-values">3.multenterbox() '
             'multenterbox(msg, title, fields, values=())</h4>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> easygui <span '
             'class="hljs-keyword">as</span> g\n'
             'fields = [<span class="hljs-string">\'*\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             'msg = <span class="hljs-string">\'*\'</span>\n'
             'title = <span class="hljs-string">\'\'</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">multenterbox</span><span '
             'class="hljs-params">(msg, title, fields)</span>:</span>\n'
             '    fieldvalue = g.multenterbox(msg, title,fields)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-keyword">True</span>:\n'
             '        <span class="hljs-keyword">if</span> fieldvalue == <span '
             'class="hljs-keyword">None</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        errmsg = <span class="hljs-string">\'\'</span>\n'
             '        <span class="hljs-keyword">for</span> item <span '
             'class="hljs-keyword">in</span> range(len(fields)):\n'
             '            option = fields[item].strip()\n'
             '            <span class="hljs-keyword">if</span> '
             'fieldvalue[item].strip() == <span class="hljs-string">""</span> '
             '<span class="hljs-keyword">and</span> option[<span '
             'class="hljs-number">0</span>] == <span '
             'class="hljs-string">"*"</span>:\n'
             '                errmsg +=(<span '
             'class="hljs-string">\'[%s]\\n\\n\'</span> % fields[item])\n'
             '        <span class="hljs-keyword">if</span> errmsg == <span '
             'class="hljs-string">\'\'</span>:\n'
             '            <span class="hljs-keyword">break</span>\n'
             '        fieldvalue = g.multenterbox(errmsg, title,fields, '
             'fieldvalue)\n'
             '\n'
             '    print(<span class="hljs-string">\'%s\'</span>  % '
             'str(fieldvalue))\n'
             '\n'
             'multenterbox(msg,title,fields)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20171206204834680?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTI2OTU3Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" '
             'alt="" title=""></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:38:51 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_26744901/article/details/80700188">https://blog.csdn.net/qq_26744901/article/details/80700188</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <pre><code '
             'class="language-undefined">whereis '
             'python</code></pre><br>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['linuxpython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:38:52 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq471011042/article/details/81067107">https://blog.csdn.net/qq471011042/article/details/81067107</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python2python3cmd\xa0'
             '<br>\n'
             '<strong>python.exe</strong></p>\n'
             '\n'
             '<h2 id=""></h2>\n'
             '\n'
             '<p>py2.7.10python3.4.3,path</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python2</span><span '
             'class="hljs-selector-class">.7</span><span '
             'class="hljs-selector-class">.10_64</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\;<span '
             'class="hljs-selector-tag">E</span>:\\<span '
             'class="hljs-selector-tag">python3</span><span '
             'class="hljs-selector-class">.4</span><span '
             'class="hljs-selector-class">.3</span>\\<span '
             'class="hljs-selector-tag">Scripts</span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<ul><li>1</li>\n'
             '\t<li>2</li>\n'
             '\t<li>3</li>\n'
             '</ul><p>pythonE:\\python2.7.10_64E:\\python3.4.3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184451331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184555488?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<ol><li>python3python2python.exepython2.exe</li>\n'
             '</ol><p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810184922154?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185137506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">\xa0'
             '<br>\n'
             '2. '
             'python2python3python.exepython3.exe</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185535606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>cmdpython versionpython2</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185624044?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<hr><p>PS: pip</p>\n'
             '\n'
             '<p>(1). python2python3pip</p>\n'
             '\n'
             '<p>(2). python2python3:\xa0<br>\n'
             'python2pip</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810185937152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>python3pip3</p>\n'
             '\n'
             '<p><img alt="" class="has" '
             'src="https://img-blog.csdn.net/20170810190009849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnhqenp5bw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['cmdpython2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:38:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/gaowenhui2008/article/details/72628304">https://blog.csdn.net/gaowenhui2008/article/details/72628304</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div id="cnblogs_post_body" '
             'style="overflow:auto;font-family:Verdana, Arial, Helvetica, '
             'sans-serif;font-size:13.92px;">\n'
             '<p><span style="font-family:\'\';font-size:13pt;">1<a '
             'href="http://www.python.org/download/" rel="nofollow" '
             'style="color:#008000;" '
             'data-token="0899b5ba443cbc8fff0f6013d1ae5553"><span '
             'style="color:#0000FF;">http://www.python.org/download/</span></a>python</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707561049.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">2next</span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">3pythonpth</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707594792.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">4pythoncmd '
             'python </span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201707598937.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">5Hello '
             "World  print 'Hello World!'</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708001445.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python '
             "1.*/2.*3.2 print ('Hello "
             "World!')</span></p>\n"
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708006777.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">6pythonIDEAptana '
             'StudioIDEEclipsepython<a '
             'href="http://aptana.com/products/studio3/download" '
             'rel="nofollow" style="color:#008000;" '
             'data-token="3619b727e6ebbf21cad1f191f5d4703c"><span '
             'style="color:#0000FF;">http://aptana.com/products/studio3/download</span></a></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708058942.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">EclipsePyDev</span></p>\n'
             '<p>\xa0</p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">7okIDE</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;"> '
             '-&gt;(Window-&gt;Preferences...) " '
             'PyDev"-&gt;"Interpreter Python" '
             'NewPythonPython.exeSystem\n'
             ' PYTHONPATH</span></p>\n'
             '<p><span style="font-family:\'\';font-size:13pt;">Auto '
             'Configpython</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170806535.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">8</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708073666.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">python3.23.02.6</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/20120920170809766.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708094911.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">9pythonHello '
             'World</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708095849.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708106438.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/2012092017081092.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">Console</span></p>\n'
             '<p><img '
             'src="http://images.cnblogs.com/cnblogs_com/windinsky/201209/201209201708117933.png" '
             'alt="" style="border:0px;"><span '
             'style="font-family:\'\';font-size:13pt;"></span></p>\n'
             '<p>\xa0</p>\n'
             '<p><span '
             'style="font-family:\'\';font-size:13pt;">ok</span></p>\n'
             '</div>\n'
             '<div class="clear" style="clear:both;font-family:Verdana, Arial, '
             'Helvetica, sans-serif;font-size:13.92px;">\n'
             '</div>\n'
             '<div id="blog_post_info_block" style="font-family:Verdana, '
             'Arial, Helvetica, sans-serif;font-size:13.92px;">\n'
             '<div id="BlogPostCategory"></div>\n'
             '<div id="EntryTag" '
             'style="font-size:9pt;color:#808080;text-align:right;">\n'
             '</div>\n'
             '<div id="blog_post_info">\n'
             '<div id="green_channel" style="border:1px dashed '
             '#C0C0C0;font-size:12px;width:350px;text-align:center;">\n'
             '<a id="green_channel_digg" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_follow" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_favorite" '
             'style="display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"></a>\xa0<a '
             'id="green_channel_weibo" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/icon_weibo_24.png" alt="" '
             'style="border:none;vertical-align:middle;"></a>\xa0<a '
             'id="green_channel_wechat" title="" '
             'style="background:none;display:inline-block;font-weight:bold;vertical-align:middle;color:rgb(255,255,255) '
             '!important;border:none !important;"><img '
             'src="http://common.cnblogs.com/images/wechat.png" alt="" '
             'style="border:medium '
             'none;width:24px;vertical-align:middle;"></a></div>\n'
             '</div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['windowsPython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:38:54 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/a649344475/article/details/81234825">https://blog.csdn.net/a649344475/article/details/81234825</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2 '
             'id="1-django-dwebsocket-"><a name="t0"></a>1 django dwebsocket '
             '</h2>\n'
             '\n'
             '<p><strong>dj_websocket</strong> <br>\n'
             '1 <br>\n'
             'python django-admin.py startproject dj_websocket <br>\n'
             '2 <br>\n'
             'cd dj_websocket <br>\n'
             '3APPmyapp <br>\n'
             'python manage.py startapp myapp <br>\n'
             '4static  templates <br>\n'
             'mkdir static  <br>\n'
             'mkdir templates</p>\n'
             '\n'
             '<p><strong> settings.py</strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs r '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-number">1</span> INSTALLED_APPS '
             'myapp\n'
             'INSTALLED_APPS = [\n'
             '    <span class="hljs-keyword">...</span>,\n'
             '    <span class="hljs-string">\'myapp\'</span>,\n'
             ']\n'
             '\n'
             '<span class="hljs-number">2</span> TEMPLATES DIRS\n'
             'TEMPLATES = [\n'
             '    {\n'
             '        <span class="hljs-keyword">...</span>,\n'
             '        <span class="hljs-string">\'DIRS\'</span>: '
             '[os.path.join(BASE_DIR, <span '
             'class="hljs-string">\'templates\'</span>)],\n'
             '        <span class="hljs-keyword">...</span>,\n'
             '    },\n'
             ']\n'
             '\n'
             '<span class="hljs-number">3</span>\n'
             'STATICFILES_DIRS = [os.path.join(BASE_DIR,<span '
             'class="hljs-string">\'static\'</span>)]<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li></ul>\n'
             '\n'
             '<p><strong>views.py </strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> json\n'
             '<span class="hljs-keyword">import</span> time\n'
             '<span class="hljs-keyword">import</span> datetime\n'
             '<span class="hljs-keyword">from</span> django.shortcuts <span '
             'class="hljs-keyword">import</span> render\n'
             '<span class="hljs-keyword">from</span> dwebsocket.decorators '
             '<span class="hljs-keyword">import</span> '
             'accept_websocket,require_websocket\n'
             '\n'
             '<span class="hljs-comment"># Create your views here.</span>\n'
             '\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">index</span><span '
             'class="hljs-params">(request)</span>:</span>\n'
             '    <span class="hljs-keyword">return</span> render(request, '
             '<span class="hljs-string">\'index.html\'</span>,{<span '
             'class="hljs-string">\'init\'</span>:<span '
             'class="hljs-string">\'init\'</span>})\n'
             '\n'
             '\n'
             '<span class="hljs-decorator">@accept_websocket</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">echo</span><span '
             'class="hljs-params">(request)</span>:</span>\n'
             '    <span class="hljs-keyword">if</span> <span '
             'class="hljs-keyword">not</span> request.is_websocket():<span '
             'class="hljs-comment">#websocket</span>\n'
             '        <span class="hljs-comment">#http</span>\n'
             '        <span class="hljs-keyword">try</span>:\n'
             '            message = request.GET[<span '
             'class="hljs-string">\'message\'</span>]\n'
             '            <span class="hljs-keyword">return</span> '
             'HttpResponse(message)\n'
             '        <span class="hljs-keyword">except</span>:\n'
             '            <span class="hljs-keyword">return</span> '
             'render(request,<span class="hljs-string">\'index.html\'</span>)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        <span class="hljs-comment"># websocket</span>\n'
             '        <span class="hljs-keyword">for</span> message <span '
             'class="hljs-keyword">in</span> request.websocket:\n'
             '            request.websocket.send(message)<span '
             'class="hljs-comment">#</span>\n'
             '            <span '
             'class="hljs-comment">#request.websocket.send(message)</span>\n'
             '            <span class="hljs-comment"># '
             '10</span>\n'
             '            <span class="hljs-keyword">for</span> i <span '
             'class="hljs-keyword">in</span> range(<span '
             'class="hljs-number">10</span>):\n'
             '                dt = str(datetime.datetime.now())\n'
             '                s={<span '
             'class="hljs-string">\'test\'</span>:f<span '
             'class="hljs-string">" {i} {dt}"</span>}\n'
             '                s=json.dumps(s).encode()\n'
             '                request.websocket.send(s)\n'
             '                time.sleep(<span class="hljs-number">0.1</span>) '
             '<span class="hljs-comment"># 0.1</span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li></ul>\n'
             '\n'
             '<p><strong>urls.py </strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">from</span> django.conf.urls '
             '<span class="hljs-keyword">import</span> url\n'
             '<span class="hljs-keyword">from</span> django.contrib <span '
             'class="hljs-keyword">import</span> admin\n'
             '\n'
             '<span class="hljs-keyword">from</span> myapp <span '
             'class="hljs-keyword">import</span> views\n'
             '\n'
             'urlpatterns = [\n'
             '    url(<span class="hljs-string">r\'^admin/\'</span>, '
             'admin.site.urls),\n'
             '    url(<span class="hljs-string">r\'^index/\'</span>, '
             'views.index),\n'
             '    url(<span class="hljs-string">r\'^echo$\'</span>, '
             'views.echo),\n'
             ']<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '\n'
             '<p><strong>index.html templates</strong> <br>\n'
             ' jquery-1.8.3.min.js  static </p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs django '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="xml"><span '
             'class="hljs-doctype">&lt;!DOCTYPE html&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">html</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">meta</span> <span '
             'class="hljs-attribute">charset</span>=<span '
             'class="hljs-value">"utf-8"</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">title</span>&gt;</span>django-websocket<span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">title</span>&gt;</span>\n'
             '    </span><span class="hljs-template_tag">{% <span '
             'class="hljs-keyword">load</span> staticfiles %}</span><span '
             'class="xml">\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">src</span>=<span '
             'class="hljs-value">"</span></span></span><span '
             'class="hljs-template_tag">{% <span '
             'class="hljs-keyword">static</span> \'jquery-1.8.3.min.js\' '
             '%}</span><span class="xml"><span class="hljs-tag"><span '
             'class="hljs-value">"</span>&gt;</span><span '
             'class="javascript"></span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text/javascript"</span>&gt;</span><span '
             'class="javascript"><span '
             'class="hljs-comment">//&lt;![CDATA[</span>\n'
             '    $(<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-comment">/*socket\n'
             '            var socket = new WebSocket("ws://" + '
             'window.location.host + "/echo");\n'
             '            socket.onopen = function () {\n'
             "                console.log('WebSocket open');//Websocket\n"
             '                 '
             "socket.send($('#message').val());//websocket\n"
             '            };\n'
             '            socket.onmessage = function (e) {\n'
             "                console.log('message: ' + "
             'e.data);//\n'
             "                $('#messagecontainer').prepend('&lt;p&gt;' + "
             "e.data + '&lt;/p&gt;');\n"
             '            };\n'
             '            // Call onopen directly if socket is already open\n'
             '            //if (socket.readyState == WebSocket.OPEN) '
             'socket.onopen();\n'
             '            // ,\n'
             '            */</span>\n'
             '\n'
             '        $(<span '
             'class="hljs-string">\'#connect_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();\n'
             '            }\n'
             '            <span class="hljs-comment">/*socket*/</span>\n'
             '            <span class="hljs-keyword">var</span> socket = <span '
             'class="hljs-keyword">new</span> WebSocket(<span '
             'class="hljs-string">"ws://"</span> + window.location.host + '
             '<span class="hljs-string">"/echo"</span>);\n'
             '            socket.onopen = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'WebSocket open\'</span>);<span '
             'class="hljs-comment">//Websocket</span>\n'
             '            };\n'
             '            socket.onmessage = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">(e)</span> {</span>\n'
             '                console.log(<span class="hljs-string">\'message: '
             "'</span> + e.data);<span "
             'class="hljs-comment">//</span>\n'
             '                <span class="hljs-keyword">var</span> d= '
             '$.parseJSON(e.data);\n'
             '                <span '
             'class="hljs-comment">//alert(typeof(d));</span>\n'
             '                $(<span '
             'class="hljs-string">\'#messagecontainer\'</span>).prepend(<span '
             'class="hljs-string">\'&lt;p&gt;\'</span> + d.test + <span '
             'class="hljs-string">\'&lt;/p&gt;\'</span>);\n'
             '            };\n'
             '            <span class="hljs-comment">// Call onopen directly '
             'if socket is already open</span>\n'
             '            <span class="hljs-keyword">if</span> '
             '(socket.readyState == WebSocket.OPEN) socket.onopen();\n'
             '            window.s = socket;\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#send_message\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-comment">//websocket</span>\n'
             '            <span class="hljs-keyword">if</span> (!window.s) {\n'
             '                alert(<span '
             'class="hljs-string">"websocket."</span>);\n'
             '            } <span class="hljs-keyword">else</span> {\n'
             '                window.s.send($(<span '
             'class="hljs-string">\'#message\'</span>).val());<span '
             'class="hljs-comment">//websocket</span>\n'
             '            }\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#close_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();<span '
             'class="hljs-comment">//websocket</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'websocket\'</span>);\n'
             '            }\n'
             '        });\n'
             '\n'
             '    });\n'
             '    <span class="hljs-comment">//]]&gt;</span></span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">br</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">input</span> '
             '<span class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"message"</span> <span '
             'class="hljs-attribute">value</span>=<span '
             'class="hljs-value">"..."</span>/&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"connect_websocket"</span>&gt;</span> '
             'websocket<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"send_message"</span>&gt;</span> '
             'message<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"close_websocket"</span>&gt;</span> '
             'websocket<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">h1</span>&gt;</span>Received Messages<span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">h1</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">div</span> '
             '<span class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"messagecontainer"</span>&gt;</span>\n'
             '\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">div</span>&gt;</span>\n'
             '</span><span class="hljs-variable">{{init}}</span><span '
             'class="xml">\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">html</span>&gt;</span>\n'
             '</span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li><li style="color: '
             'rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, '
             '153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li '
             'style="color: rgb(153, 153, 153);">50</li><li style="color: '
             'rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, '
             '153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li '
             'style="color: rgb(153, 153, 153);">54</li><li style="color: '
             'rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, '
             '153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li '
             'style="color: rgb(153, 153, 153);">58</li><li style="color: '
             'rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, '
             '153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li '
             'style="color: rgb(153, 153, 153);">62</li><li style="color: '
             'rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, '
             '153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li '
             'style="color: rgb(153, 153, 153);">66</li><li style="color: '
             'rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, '
             '153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li '
             'style="color: rgb(153, 153, 153);">70</li><li style="color: '
             'rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, '
             '153);">72</li><li style="color: rgb(153, 153, 153);">73</li><li '
             'style="color: rgb(153, 153, 153);">74</li><li style="color: '
             'rgb(153, 153, 153);">75</li></ul>\n'
             '\n'
             '<p><strong></strong> <br>\n'
             ' <br>\n'
             'python manage.py makemigrations <br>\n'
             'python manage.py migrate</p>\n'
             '\n'
             '<p> <br>\n'
             'python manage.py runserver</p>\n'
             '\n'
             '<p><strong></strong> <br>\n'
             '<a href="http://localhost:8000/index/" rel="nofollow" '
             'data-token="8b56a9790e72780b4ff5fc0f651b163a">http://localhost:8000/index/</a>  '
             '<br>\n'
             ' <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180727115057396?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E2NDkzNDQ0NzU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="img1" title=""></p>\n'
             '\n'
             '<p><strong></strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180727120043196?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E2NDkzNDQ0NzU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="2-websockets-"><a name="t1"></a>2 websockets </h2>\n'
             '\n'
             '<p><strong>1 server.py </strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> websockets\n'
             '<span class="hljs-keyword">import</span> asyncio\n'
             '<span class="hljs-keyword">import</span> time\n'
             '<span class="hljs-keyword">import</span> datetime\n'
             '<span class="hljs-keyword">import</span> json\n'
             '\n'
             'async <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">hello</span><span '
             'class="hljs-params">(websocket,path)</span>:</span>\n'
             '  name = await websocket.recv()\n'
             '  print(f<span class="hljs-string">\'A new client: '
             "{name}'</span>)\n"
             '  <span class="hljs-keyword">for</span> i <span '
             'class="hljs-keyword">in</span> range(<span '
             'class="hljs-number">10</span>):\n'
             '    dt = str(datetime.datetime.now())\n'
             '    s = json.dumps({<span '
             'class="hljs-string">\'test\'</span>:f<span '
             'class="hljs-string">"{name} {i} {dt}"</span>})\n'
             '    await websocket.send(s)\n'
             '    print(f<span class="hljs-string">\'send {name} {i} '
             "{dt}'</span>)\n"
             '    time.sleep(<span class="hljs-number">0.1</span>)\n'
             '\n'
             '\n'
             'start_server = websockets.serve(hello,<span '
             'class="hljs-string">\'localhost\'</span>,<span '
             'class="hljs-number">8000</span>)\n'
             'asyncio.get_event_loop().run_until_complete(start_server)\n'
             'asyncio.get_event_loop().run_forever()\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li></ul>\n'
             '\n'
             '<p><em>run server.py:</em> <br>\n'
             'python server.py</p>\n'
             '\n'
             '<p><strong>2 client.py </strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> websockets\n'
             '<span class="hljs-keyword">import</span> asyncio\n'
             '\n'
             '\n'
             'async <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">hello</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '  async <span class="hljs-keyword">with</span> '
             'websockets.connect(<span '
             'class="hljs-string">\'ws://localhost:8000\'</span>) <span '
             'class="hljs-keyword">as</span> websocket:\n'
             '    name = input(<span class="hljs-string">"what\'s your '
             'name?"</span>)\n'
             '    await websocket.send(name)\n'
             '    print(f<span class="hljs-string">"send '
             'server:{name}"</span>)\n'
             '    <span class="hljs-keyword">while</span> <span '
             'class="hljs-number">1</span>:\n'
             '      greeting = await websocket.recv()\n'
             '      print(f<span class="hljs-string">\'receive from '
             "server:{greeting}'</span>)\n"
             '\n'
             'asyncio.get_event_loop().run_until_complete(hello())\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li></ul>\n'
             '\n'
             '<p><em>run client.py</em> <br>\n'
             'python client.py <br>\n'
             '<em>inputhello</em> <br>\n'
             '<em>output to server</em></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs css '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-tag">A</span> <span '
             'class="hljs-tag">new</span> <span '
             'class="hljs-tag">client</span>: <span '
             'class="hljs-tag">hello</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 0 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.410886</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 1 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.511604</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 2 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.612339</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 3 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.713062</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 4 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.813771</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 5 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:11</span><span '
             'class="hljs-class">.914492</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 6 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:12</span><span '
             'class="hljs-class">.015099</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 7 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:12</span><span '
             'class="hljs-class">.115936</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 8 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:12</span><span '
             'class="hljs-class">.216658</span>\n'
             '<span class="hljs-tag">send</span> <span '
             'class="hljs-tag">hello</span> 9 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:24</span><span '
             'class="hljs-pseudo">:12</span><span '
             'class="hljs-class">.317399</span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '\n'
             '<p><em>output to client.py</em></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs vbscript '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">what<span class="hljs-comment">\'s your '
             'name?hello</span>\n'
             'send <span class="hljs-built_in">server</span>:hello\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 0 2018-07-28 '
             '20:24:11.410886"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 1 2018-07-28 '
             '20:24:11.511604"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 2 2018-07-28 '
             '20:24:11.612339"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 3 2018-07-28 '
             '20:24:11.713062"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 4 2018-07-28 '
             '20:24:11.813771"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 5 2018-07-28 '
             '20:24:11.914492"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 6 2018-07-28 '
             '20:24:12.015099"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 7 2018-07-28 '
             '20:24:12.115936"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 8 2018-07-28 '
             '20:24:12.216658"</span>}\n'
             'receive from <span class="hljs-built_in">server</span>:{<span '
             'class="hljs-string">"test"</span>: <span '
             'class="hljs-string">"hello 9 2018-07-28 '
             '20:24:12.317399"</span>}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '\n'
             '<p><strong>3 client.html</strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs xml '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-tag">&lt;<span '
             'class="hljs-title">html</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">meta</span> <span '
             'class="hljs-attribute">charset</span>=<span '
             'class="hljs-value">"utf-8"</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">title</span>&gt;</span>django-websocket<span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">title</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">src</span>=<span '
             'class="hljs-value">"jquery-1.8.3.min.js"</span>&gt;</span><span '
             'class="javascript"></span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text/javascript"</span>&gt;</span><span '
             'class="javascript">\n'
             '    $(<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '        $(<span '
             'class="hljs-string">\'#connect_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();\n'
             '            }\n'
             '            <span class="hljs-comment">/*socket*/</span>\n'
             '            <span class="hljs-keyword">var</span> socket = <span '
             'class="hljs-keyword">new</span> WebSocket(<span '
             'class="hljs-string">"ws://localhost:8000"</span>);\n'
             '            socket.onopen = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'WebSocket open\'</span>);<span '
             'class="hljs-comment">//Websocket</span>\n'
             '            };\n'
             '            socket.onmessage = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">(e)</span> {</span>\n'
             '                console.log(<span class="hljs-string">\'message: '
             "'</span> + e.data);<span "
             'class="hljs-comment">//</span>\n'
             '                <span class="hljs-keyword">var</span> d= '
             '$.parseJSON(e.data);\n'
             '                $(<span '
             'class="hljs-string">\'#messagecontainer\'</span>).prepend(<span '
             'class="hljs-string">\'&lt;p&gt;\'</span> + d.test + <span '
             'class="hljs-string">\'&lt;/p&gt;\'</span>);\n'
             '            };\n'
             '            <span class="hljs-keyword">if</span> '
             '(socket.readyState == WebSocket.OPEN) socket.onopen();\n'
             '            window.s = socket;\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#send_message\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-comment">//websocket</span>\n'
             '            <span class="hljs-keyword">if</span> (!window.s) {\n'
             '                alert(<span '
             'class="hljs-string">"websocket."</span>);\n'
             '            } <span class="hljs-keyword">else</span> {\n'
             '                window.s.send($(<span '
             'class="hljs-string">\'#message\'</span>).val());<span '
             'class="hljs-comment">//websocket</span>\n'
             '            }\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#close_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();<span '
             'class="hljs-comment">//websocket</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'websocket\'</span>);\n'
             '            }\n'
             '        });\n'
             '\n'
             '    });\n'
             '</span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">br</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">input</span> '
             '<span class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"message"</span> <span '
             'class="hljs-attribute">value</span>=<span '
             'class="hljs-value">"..."</span>/&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"connect_websocket"</span>&gt;</span> '
             'websocket<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"send_message"</span>&gt;</span> '
             'message<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"close_websocket"</span>&gt;</span> '
             'websocket<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">div</span> '
             '<span class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"messagecontainer"</span>&gt;</span>\n'
             '\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">div</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">html</span>&gt;</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, '
             '153);">54</li></ul>\n'
             '\n'
             '<p>run client.html <br>\n'
             'file:///home/huang/Practise/demo1/client.html</p>\n'
             '\n'
             '<p><strong> </strong> <br>\n'
             '<em>output to server</em></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs css '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-tag">A</span> <span '
             'class="hljs-tag">new</span> <span '
             'class="hljs-tag">client</span>: \n'
             '<span class="hljs-tag">send</span>  0 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.384413</span>\n'
             '<span class="hljs-tag">send</span>  1 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.485158</span>\n'
             '<span class="hljs-tag">send</span>  2 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.585793</span>\n'
             '<span class="hljs-tag">send</span>  3 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.686401</span>\n'
             '<span class="hljs-tag">send</span>  4 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.787105</span>\n'
             '<span class="hljs-tag">send</span>  5 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.887769</span>\n'
             '<span class="hljs-tag">send</span>  6 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.988483</span>\n'
             '<span class="hljs-tag">send</span>  7 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.089176</span>\n'
             '<span class="hljs-tag">send</span>  8 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.189867</span>\n'
             '<span class="hljs-tag">send</span>  9 2018<span '
             'class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.290481</span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li></ul>\n'
             '\n'
             '<p><em>output to client.html</em></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs css '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"> 9 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.290481</span>\n'
             '\n'
             ' 8 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.189867</span>\n'
             '\n'
             ' 7 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:35</span><span '
             'class="hljs-class">.089176</span>\n'
             '\n'
             ' 6 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.988483</span>\n'
             '\n'
             ' 5 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.887769</span>\n'
             '\n'
             ' 4 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.787105</span>\n'
             '\n'
             ' 3 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.686401</span>\n'
             '\n'
             ' 2 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.585793</span>\n'
             '\n'
             ' 1 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.485158</span>\n'
             '\n'
             ' 0 2018<span class="hljs-tag">-07-28</span> 20<span '
             'class="hljs-pseudo">:38</span><span '
             'class="hljs-pseudo">:34</span><span '
             'class="hljs-class">.384413</span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="3-websockets-k"><a name="t2"></a>3 '
             'websockets K</h2>\n'
             '\n'
             '<p><strong>1web_server.py</strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs python '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">import</span> json\n'
             '<span class="hljs-keyword">import</span> time\n'
             '<span class="hljs-keyword">import</span> random\n'
             '<span class="hljs-keyword">import</span> datetime\n'
             '<span class="hljs-keyword">import</span> asyncio\n'
             '<span class="hljs-keyword">import</span> websockets\n'
             '\n'
             'async <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">echo2</span><span '
             'class="hljs-params">(websocket, path)</span>:</span>\n'
             '    message = await websocket.recv()\n'
             '    await websocket.send(message)\n'
             '\n'
             '<span class="hljs-decorator">@asyncio.coroutine</span>\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">echo</span><span '
             'class="hljs-params">(websocket, path)</span>:</span>\n'
             '    message = <span class="hljs-keyword">yield</span> <span '
             'class="hljs-keyword">from</span> websocket.recv()\n'
             '    print(<span class="hljs-string">\'recv\'</span>, message)\n'
             '    dt = datetime.datetime.now()\n'
             '    cc = <span class="hljs-number">1000</span>\n'
             '    <span class="hljs-keyword">for</span> i <span '
             'class="hljs-keyword">in</span> range(<span '
             'class="hljs-number">1000</span>):\n'
             '        dt2 = str(dt + datetime.timedelta(minutes=i))[<span '
             'class="hljs-number">11</span>:<span '
             'class="hljs-number">19</span>]\n'
             '        y = [cc + random.randint(-<span '
             'class="hljs-number">80</span>, <span '
             'class="hljs-number">100</span>) <span '
             'class="hljs-keyword">for</span> i <span '
             'class="hljs-keyword">in</span> range(<span '
             'class="hljs-number">4</span>)]\n'
             '        v = []\n'
             '        mi = min(y)\n'
             '        ma = max(y)\n'
             '        y.remove(mi)\n'
             '        y.remove(ma)\n'
             '        y = [y[<span class="hljs-number">0</span>], y[<span '
             'class="hljs-number">1</span>], mi, ma]\n'
             '        cc = y[<span class="hljs-number">2</span>] <span '
             'class="hljs-keyword">if</span> y[<span '
             'class="hljs-number">2</span>] &gt; <span '
             'class="hljs-number">900</span> <span '
             'class="hljs-keyword">else</span> <span '
             'class="hljs-number">1000</span>\n'
             '        s = {<span class="hljs-string">\'datetime\'</span>: dt2, '
             '<span class="hljs-string">\'topic\'</span>: <span '
             'class="hljs-string">\'bar\'</span>,<span '
             'class="hljs-string">\'open\'</span>:y[<span '
             'class="hljs-number">0</span>],<span '
             'class="hljs-string">\'close\'</span>:y[<span '
             'class="hljs-number">1</span>],<span '
             'class="hljs-string">\'high\'</span>:y[<span '
             'class="hljs-number">2</span>],<span '
             'class="hljs-string">\'low\'</span>:y[<span '
             'class="hljs-number">3</span>]}\n'
             '        s = json.dumps(s)<span '
             'class="hljs-comment">#.encode()</span>\n'
             '        <span class="hljs-comment">#print(s)</span>\n'
             '        <span class="hljs-comment"># '
             'request.websocket.send(s)</span>\n'
             '        <span class="hljs-keyword">yield</span> <span '
             'class="hljs-keyword">from</span> websocket.send(s)\n'
             '\n'
             '        v = random.randint(<span '
             'class="hljs-number">0</span>,<span '
             'class="hljs-number">5</span>)\n'
             '        <span class="hljs-keyword">if</span> v <span '
             'class="hljs-keyword">in</span> (<span '
             'class="hljs-number">3</span>,<span '
             'class="hljs-number">4</span>):\n'
             '            v = <span class="hljs-string">\'SELL\'</span> <span '
             'class="hljs-keyword">if</span> v==<span '
             'class="hljs-number">4</span> <span '
             'class="hljs-keyword">else</span> <span '
             'class="hljs-string">\'BULL\'</span> <span class="hljs-comment"># '
             '</span>\n'
             '            s = {<span '
             'class="hljs-string">\'topic\'</span>:<span '
             'class="hljs-string">\'trade\'</span>,<span '
             'class="hljs-string">\'trading_dt\'</span>:dt2,<span '
             'class="hljs-string">\'price\'</span>:y[<span '
             'class="hljs-number">1</span>],<span '
             'class="hljs-string">\'side\'</span>:v}\n'
             '            print(s)\n'
             '        s = json.dumps(s)<span '
             'class="hljs-comment">#.encode()</span>\n'
             '\n'
             '        <span class="hljs-comment"># '
             'request.websocket.send(s)</span>\n'
             '        <span class="hljs-keyword">yield</span> <span '
             'class="hljs-keyword">from</span> websocket.send(s)\n'
             '\n'
             '        time.sleep(<span class="hljs-number">0.5</span>)  <span '
             'class="hljs-comment"># 0.5</span>\n'
             '\n'
             '\n'
             'start_server = websockets.serve(echo, <span '
             'class="hljs-string">\'localhost\'</span>, <span '
             'class="hljs-number">8000</span>)\n'
             '\n'
             'asyncio.get_event_loop().run_until_complete(start_server)\n'
             'asyncio.get_event_loop().run_forever()<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, '
             '153);">50</li></ul>\n'
             '\n'
             '<p><strong>2 web_client.html</strong></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs xml '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-doctype">&lt;!DOCTYPE html&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">html</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">meta</span> <span '
             'class="hljs-attribute">charset</span>=<span '
             'class="hljs-value">"utf-8"</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">title</span>&gt;</span>django-websocket<span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">title</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text/javascript"</span> <span '
             'class="hljs-attribute">src</span>=<span '
             'class="hljs-value">"jquery-1.8.3.min.js"</span>&gt;</span><span '
             'class="javascript"></span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text/javascript"</span> <span '
             'class="hljs-attribute">src</span>=<span '
             'class="hljs-value">"echarts.min.js"</span>&gt;</span><span '
             'class="javascript"></span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">head</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">br</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">input</span> '
             '<span class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"message"</span> <span '
             'class="hljs-attribute">value</span>=<span '
             'class="hljs-value">"200"</span>/&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"connect_websocket"</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"send_message"</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"close_ht"</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span '
             'class="hljs-title">button</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"button"</span> <span '
             'class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"close_websocket"</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">button</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">div</span> '
             '<span class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"messagecontainer"</span>&gt;</span>\n'
             '\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">div</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;<span class="hljs-title">div</span> '
             '<span class="hljs-attribute">id</span>=<span '
             'class="hljs-value">"main"</span> <span '
             'class="hljs-attribute">style</span>=<span '
             'class="hljs-value">"width: auto;height: 800px;"</span> <span '
             'class="hljs-attribute">align</span>=<span '
             'class="hljs-value">"center"</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-title">div</span>&gt;</span>\n'
             '    <span class="hljs-tag">&lt;<span '
             'class="hljs-title">script</span> <span '
             'class="hljs-attribute">type</span>=<span '
             'class="hljs-value">"text/javascript"</span>&gt;</span><span '
             'class="javascript">\n'
             '\n'
             '<span class="hljs-keyword">var</span> myChart = '
             'echarts.init(document.getElementById(<span '
             'class="hljs-string">\'main\'</span>));\n'
             '<span class="hljs-keyword">var</span> bs = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> xzs = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '\n'
             'option = {\n'
             '    title : {\n'
             '        text: <span class="hljs-string">\'\'</span>,\n'
             '        subtext: <span class="hljs-string">\'K\'</span>\n'
             '    },\n'
             '    tooltip : {\n'
             '        trigger: <span class="hljs-string">\'axis\'</span>\n'
             '    },\n'
             '    legend: {\n'
             '        data:[<span class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>]\n'
             '    },\n'
             '    toolbox: {\n'
             '        show : <span class="hljs-literal">true</span>,\n'
             '        feature : {\n'
             '            mark : {show: <span '
             'class="hljs-literal">true</span>},\n'
             '            dataView : {show: <span '
             'class="hljs-literal">true</span>, readOnly: <span '
             'class="hljs-literal">false</span>},\n'
             '            restore : {show: <span '
             'class="hljs-literal">true</span>},\n'
             '            saveAsImage : {show: <span '
             'class="hljs-literal">true</span>}\n'
             '        }\n'
             '    },\n'
             '    dataZoom : {\n'
             '        show : <span class="hljs-literal">true</span>,\n'
             '        realtime: <span class="hljs-literal">true</span>,\n'
             '        start : <span class="hljs-number">50</span>,\n'
             '        end : <span class="hljs-number">100</span>\n'
             '    },\n'
             '    xAxis : [\n'
             '        {\n'
             '            type : <span '
             'class="hljs-string">\'category\'</span>,\n'
             '            boundaryGap : <span '
             'class="hljs-literal">true</span>,\n'
             '            data : [\n'
             '\n'
             '            ]\n'
             '        }\n'
             '    ],\n'
             '    yAxis : [\n'
             '        {\n'
             '            type : <span class="hljs-string">\'value\'</span>,\n'
             '            scale:<span class="hljs-literal">true</span>,\n'
             '            splitNumber: <span class="hljs-number">5</span>,\n'
             '            boundaryGap: [<span class="hljs-number">0.05</span>, '
             '<span class="hljs-number">0.05</span>]\n'
             '        }\n'
             '    ],\n'
             '    series : [\n'
             '        {\n'
             '            name:<span class="hljs-string">\'\'</span>,\n'
             '            type:<span class="hljs-string">\'k\'</span>,\n'
             '            data:[ <span class="hljs-comment">// '
             '</span>\n'
             '            ]\n'
             '        },{\n'
             '            name:<span class="hljs-string">\'\'</span>,\n'
             '            type:<span class="hljs-string">\'scatter\'</span>,\n'
             '            symbol: <span '
             'class="hljs-string">\'arrow\'</span>,<span '
             'class="hljs-comment">//\'star3\',</span>\n'
             '            symbolSize: <span class="hljs-number">12</span>,\n'
             '            smooth:<span class="hljs-literal">true</span>,\n'
             '            symbolRotate:<span class="hljs-number">180</span>,\n'
             '\n'
             '            itemStyle:{\n'
             '                <span '
             'class="hljs-comment">//symbolRotate:-90,</span>\n'
             '                normal: { color:<span '
             'class="hljs-function"><span '
             'class="hljs-keyword">function</span><span '
             'class="hljs-params">(p)</span>{</span>\n'
             '                    <span class="hljs-keyword">return</span> '
             'bs[p.name];\n'
             '                 }\n'
             '                }\n'
             '            },\n'
             '\n'
             '            data: []\n'
             '        },{\n'
             '            name:<span class="hljs-string">\'\'</span>,\n'
             '            type:<span class="hljs-string">\'scatter\'</span>,\n'
             '            symbol: <span '
             'class="hljs-string">\'arrow\'</span>,<span '
             'class="hljs-comment">//\'star3\',</span>\n'
             '            symbolSize: <span class="hljs-number">12</span>,\n'
             '            smooth:<span class="hljs-literal">true</span>,\n'
             '            symbolRotate:<span class="hljs-number">0</span>,\n'
             '\n'
             '            itemStyle:{\n'
             '                <span '
             'class="hljs-comment">//symbolRotate:-90,</span>\n'
             '                normal: { color:<span '
             'class="hljs-function"><span '
             'class="hljs-keyword">function</span><span '
             'class="hljs-params">(p)</span>{</span>\n'
             '                    <span class="hljs-keyword">return</span> '
             'bs[p.name];\n'
             '                 }\n'
             '                }\n'
             '            },\n'
             '\n'
             '            data: []\n'
             '        }\n'
             '    ]\n'
             '};\n'
             '\n'
             'stringToDate = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span><span '
             'class="hljs-params">(dateStr,separator)</span>{</span>\n'
             '     <span class="hljs-keyword">if</span>(!separator){\n'
             '            separator=<span class="hljs-string">"-"</span>;\n'
             '     }\n'
             '     <span class="hljs-keyword">var</span> dateArr = '
             'dateStr.split(separator);\n'
             '     <span class="hljs-keyword">var</span> year = <span '
             'class="hljs-built_in">parseInt</span>(dateArr[<span '
             'class="hljs-number">0</span>]);\n'
             '     <span class="hljs-keyword">var</span> month;\n'
             '     <span class="hljs-comment">//04</span>\n'
             '     <span class="hljs-keyword">if</span>(dateArr[<span '
             'class="hljs-number">1</span>].indexOf(<span '
             'class="hljs-string">"0"</span>) == <span '
             'class="hljs-number">0</span>){\n'
             '         month = <span '
             'class="hljs-built_in">parseInt</span>(dateArr[<span '
             'class="hljs-number">1</span>].substring(<span '
             'class="hljs-number">1</span>));\n'
             '     }<span class="hljs-keyword">else</span>{\n'
             '          month = <span '
             'class="hljs-built_in">parseInt</span>(dateArr[<span '
             'class="hljs-number">1</span>]);\n'
             '     }\n'
             '     <span class="hljs-keyword">var</span> day = <span '
             'class="hljs-built_in">parseInt</span>(dateArr[<span '
             'class="hljs-number">2</span>]);\n'
             '     <span class="hljs-keyword">var</span> date = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Date</span>(year,month -<span '
             'class="hljs-number">1</span>,day);\n'
             '     <span class="hljs-keyword">return</span> date;\n'
             ' }\n'
             '\n'
             '<span class="hljs-keyword">var</span> k_x = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> k_y = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> y_x = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> y_y = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> y_y2 = <span '
             'class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();\n'
             '<span class="hljs-keyword">var</span> is_huatu = <span '
             'class="hljs-literal">true</span>;\n'
             '<span class="hljs-keyword">var</span> size = $(<span '
             'class="hljs-string">\'#message\'</span>).val()-<span '
             'class="hljs-number">0</span>;\n'
             '\n'
             '<span class="hljs-comment">//myChart.setOption(option);</span>\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">timeTicket</span><span '
             'class="hljs-params">(x,y,type,side)</span>{</span>\n'
             '    <span class="hljs-comment">//  addData</span>\n'
             '    <span class="hljs-comment">// lastIndex += 1;</span>\n'
             '    <span class="hljs-comment">// var len2 = '
             'option.series[0].data.length;</span>\n'
             '    <span class="hljs-comment">// var d = '
             'option.xAxis[0].data[len2-1];</span>\n'
             '    <span class="hljs-comment">// d = '
             "stringToDate(d,'/');</span>\n"
             '    <span class="hljs-comment">// '
             'd.setDate(d.getDate()+1);</span>\n'
             '    <span class="hljs-comment">// d = '
             "d.getFullYear()+'/'+(d.getMonth()+1)+'/'+d.getDate();</span>\n"
             '\n'
             '    <span class="hljs-keyword">if</span>(type==<span '
             'class="hljs-string">\'k\'</span>){\n'
             '        <span class="hljs-keyword">var</span> ind = '
             'k_x.indexOf(x);\n'
             '        <span class="hljs-keyword">if</span>(ind&lt;<span '
             'class="hljs-number">0</span>){\n'
             '                k_x.push(x);\n'
             '                k_y.push(y);\n'
             '                y_y.push(<span '
             'class="hljs-string">\'\'</span>);\n'
             '                y_y2.push(<span '
             'class="hljs-string">\'\'</span>);\n'
             '            }<span class="hljs-keyword">else</span>{\n'
             '                k_y[ind] = y;\n'
             '            }\n'
             '\n'
             '            <span class="hljs-keyword">if</span>(is_huatu){\n'
             '                option.xAxis[<span '
             'class="hljs-number">0</span>].data=k_x.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">0</span>].data=k_y.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">1</span>].data=y_y.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">2</span>].data=y_y2.slice(-size);\n'
             '                <span '
             'class="hljs-comment">//option.series[1].symbolRotate=y_y.slice(-size);</span>\n'
             '                myChart.setOption(option);\n'
             '            }\n'
             '    }<span class="hljs-keyword">else</span> <span '
             'class="hljs-keyword">if</span>(type==<span '
             'class="hljs-string">\'y\'</span>){\n'
             '            <span class="hljs-keyword">var</span> ind = '
             'k_x.indexOf(x);\n'
             '\n'
             '            <span class="hljs-keyword">if</span>(ind&lt;<span '
             'class="hljs-number">0</span>){\n'
             '                k_x.push(x);\n'
             '                k_y.push(k_y[k_y.length-<span '
             'class="hljs-number">1</span>]);\n'
             '                <span class="hljs-keyword">if</span>(side==<span '
             'class="hljs-string">\'SELL\'</span>){\n'
             '                    y_y.push(y);\n'
             '                    y_y2.push(<span '
             'class="hljs-string">\'\'</span>)\n'
             '                }<span class="hljs-keyword">else</span>{\n'
             '                    y_y.push(<span '
             'class="hljs-string">\'\'</span>);\n'
             '                    y_y2.push(y)\n'
             '                }\n'
             '            }<span class="hljs-keyword">else</span>{\n'
             '                <span class="hljs-comment">//y_y[ind] = '
             'y;</span>\n'
             '                <span class="hljs-keyword">if</span>(side==<span '
             'class="hljs-string">\'SELL\'</span>){\n'
             '                    y_y[ind] = y;\n'
             '                }<span class="hljs-keyword">else</span>{\n'
             '                   y_y2[ind] = y;\n'
             '                }\n'
             '            }\n'
             '            <span class="hljs-keyword">if</span>(is_huatu){\n'
             '                option.xAxis[<span '
             'class="hljs-number">0</span>].data=k_x.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">0</span>].data=k_y.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">1</span>].data=y_y.slice(-size);\n'
             '                option.series[<span '
             'class="hljs-number">2</span>].data=y_y2.slice(-size);\n'
             '               myChart.setOption(option);\n'
             '            }\n'
             '    }<span class="hljs-keyword">else</span>{\n'
             '        option.xAxis[<span '
             'class="hljs-number">0</span>].data=k_x.slice(-size);\n'
             '        option.series[<span '
             'class="hljs-number">0</span>].data=k_y.slice(-size);\n'
             '        option.series[<span '
             'class="hljs-number">1</span>].data=y_y.slice(-size);\n'
             '        option.series[<span '
             'class="hljs-number">2</span>].data=y_y2.slice(-size);\n'
             '        myChart.setOption(option);\n'
             '    }\n'
             '        <span class="hljs-comment">/*myChart.addData([\n'
             '            [\n'
             '                0,        // \n'
             '                option.series[0].data[lastIndex%len], // \n'
             '                false,     // \n'
             '                false,     // '
             'false\n'
             '                d //option.xAxis[0].data[lastIndex%len]\n'
             '            ]\n'
             '        ]);*/</span>\n'
             '}\n'
             '\n'
             '$(<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '        <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">manages</span><span '
             'class="hljs-params">(info)</span>{</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();\n'
             '            }\n'
             '            <span class="hljs-comment">/*socket*/</span>\n'
             '            <span class="hljs-keyword">var</span> url = <span '
             'class="hljs-string">"ws://localhost:8000"</span>; <span '
             'class="hljs-comment">// </span>\n'
             '            <span class="hljs-keyword">var</span> socket = <span '
             'class="hljs-keyword">new</span> WebSocket(url); <span '
             'class="hljs-comment">//window.location.host</span>\n'
             '            socket.onopen = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">()</span> {</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'WebSocket open\'</span>);<span '
             'class="hljs-comment">//Websocket</span>\n'
             '                <span class="hljs-keyword">if</span>(info) '
             'alert(<span class="hljs-string">\'WebSocket open\'</span>);\n'
             '            };\n'
             '            <span class="hljs-keyword">var</span> x=<span '
             'class="hljs-literal">null</span>,y=<span '
             'class="hljs-literal">null</span>;\n'
             '            socket.onmessage = <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-params">(e)</span> {</span>\n'
             '                console.log(<span class="hljs-string">\'message: '
             "'</span> + e.data);<span "
             'class="hljs-comment">//</span>\n'
             '                <span class="hljs-keyword">var</span> d= '
             '$.parseJSON(e.data);\n'
             '                <span '
             'class="hljs-keyword">if</span>(d.topic==<span '
             'class="hljs-string">\'bar\'</span>){\n'
             '                    x = d.datetime;\n'
             '                    y=[d.open,d.close,d.high,d.low]\n'
             '                    timeTicket(x,y,<span '
             'class="hljs-string">\'k\'</span>,<span '
             'class="hljs-string">\'\'</span>);\n'
             '                }<span class="hljs-keyword">else</span> <span '
             'class="hljs-keyword">if</span>(d.topic==<span '
             'class="hljs-string">\'trade\'</span>){\n'
             '                    x = d.trading_dt;\n'
             '                    y = d.price;\n'
             '                    <span class="hljs-comment">//bs = '
             'd.bs;</span>\n'
             '                    <span '
             'class="hljs-keyword">if</span>(d.side==<span '
             'class="hljs-string">\'SELL\'</span>){\n'
             '                        bs[x]=<span '
             'class="hljs-string">\'green\'</span>;\n'
             '                    }<span class="hljs-keyword">else</span>{\n'
             '                        bs[x]=<span '
             'class="hljs-string">\'red\'</span>;\n'
             '                    }\n'
             '                    timeTicket(x,y,<span '
             'class="hljs-string">\'y\'</span>,d.side);\n'
             '                }\n'
             '            };\n'
             '            <span class="hljs-comment">// Call onopen directly '
             'if socket is already open</span>\n'
             '            <span class="hljs-keyword">if</span> '
             '(socket.readyState == WebSocket.OPEN) socket.onopen();\n'
             '            window.s = socket;\n'
             '        }\n'
             '        manages(<span class="hljs-literal">false</span>);\n'
             '        $(<span '
             'class="hljs-string">\'#connect_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            manages(<span class="hljs-literal">true</span>);\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#send_message\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-comment">//websocket</span>\n'
             '            is_huatu = <span class="hljs-literal">true</span>;\n'
             '            <span class="hljs-keyword">if</span> (!window.s) {\n'
             '                alert(<span '
             'class="hljs-string">"websocket."</span>);\n'
             '            } <span class="hljs-keyword">else</span> {\n'
             '                window.s.send($(<span '
             'class="hljs-string">\'#message\'</span>).val());<span '
             'class="hljs-comment">//websocket</span>\n'
             '            }\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#close_websocket\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            <span class="hljs-keyword">if</span> (window.s) {\n'
             '                window.s.close();<span '
             'class="hljs-comment">//websocket</span>\n'
             '                console.log(<span '
             'class="hljs-string">\'websocket\'</span>);\n'
             '            }\n'
             '        });\n'
             '        $(<span '
             'class="hljs-string">\'#close_ht\'</span>).click(<span '
             'class="hljs-function"><span class="hljs-keyword">function</span> '
             '<span class="hljs-params">()</span> {</span>\n'
             '            is_huatu = <span class="hljs-literal">false</span>;\n'
             '            size = $(<span '
             'class="hljs-string">\'#message\'</span>).val()-<span '
             'class="hljs-number">0</span>;\n'
             '            timeTicket(<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>,<span '
             'class="hljs-string">\'\'</span>);\n'
             '        });\n'
             '    });\n'
             '\n'
             '\n'
             '<span class="hljs-comment">//var '
             't=setInterval("timeTicket()",100);</span>\n'
             '</span><span class="hljs-tag">&lt;/<span '
             'class="hljs-title">script</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">body</span>&gt;</span>\n'
             '<span class="hljs-tag">&lt;/<span '
             'class="hljs-title">html</span>&gt;</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li '
             'style="color: rgb(153, 153, 153);">55</li><li style="color: '
             'rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, '
             '153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li '
             'style="color: rgb(153, 153, 153);">59</li><li style="color: '
             'rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, '
             '153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li '
             'style="color: rgb(153, 153, 153);">63</li><li style="color: '
             'rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, '
             '153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li '
             'style="color: rgb(153, 153, 153);">67</li><li style="color: '
             'rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, '
             '153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li '
             'style="color: rgb(153, 153, 153);">71</li><li style="color: '
             'rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, '
             '153);">73</li><li style="color: rgb(153, 153, 153);">74</li><li '
             'style="color: rgb(153, 153, 153);">75</li><li style="color: '
             'rgb(153, 153, 153);">76</li><li style="color: rgb(153, 153, '
             '153);">77</li><li style="color: rgb(153, 153, 153);">78</li><li '
             'style="color: rgb(153, 153, 153);">79</li><li style="color: '
             'rgb(153, 153, 153);">80</li><li style="color: rgb(153, 153, '
             '153);">81</li><li style="color: rgb(153, 153, 153);">82</li><li '
             'style="color: rgb(153, 153, 153);">83</li><li style="color: '
             'rgb(153, 153, 153);">84</li><li style="color: rgb(153, 153, '
             '153);">85</li><li style="color: rgb(153, 153, 153);">86</li><li '
             'style="color: rgb(153, 153, 153);">87</li><li style="color: '
             'rgb(153, 153, 153);">88</li><li style="color: rgb(153, 153, '
             '153);">89</li><li style="color: rgb(153, 153, 153);">90</li><li '
             'style="color: rgb(153, 153, 153);">91</li><li style="color: '
             'rgb(153, 153, 153);">92</li><li style="color: rgb(153, 153, '
             '153);">93</li><li style="color: rgb(153, 153, 153);">94</li><li '
             'style="color: rgb(153, 153, 153);">95</li><li style="color: '
             'rgb(153, 153, 153);">96</li><li style="color: rgb(153, 153, '
             '153);">97</li><li style="color: rgb(153, 153, 153);">98</li><li '
             'style="color: rgb(153, 153, 153);">99</li><li style="color: '
             'rgb(153, 153, 153);">100</li><li style="color: rgb(153, 153, '
             '153);">101</li><li style="color: rgb(153, 153, '
             '153);">102</li><li style="color: rgb(153, 153, '
             '153);">103</li><li style="color: rgb(153, 153, '
             '153);">104</li><li style="color: rgb(153, 153, '
             '153);">105</li><li style="color: rgb(153, 153, '
             '153);">106</li><li style="color: rgb(153, 153, '
             '153);">107</li><li style="color: rgb(153, 153, '
             '153);">108</li><li style="color: rgb(153, 153, '
             '153);">109</li><li style="color: rgb(153, 153, '
             '153);">110</li><li style="color: rgb(153, 153, '
             '153);">111</li><li style="color: rgb(153, 153, '
             '153);">112</li><li style="color: rgb(153, 153, '
             '153);">113</li><li style="color: rgb(153, 153, '
             '153);">114</li><li style="color: rgb(153, 153, '
             '153);">115</li><li style="color: rgb(153, 153, '
             '153);">116</li><li style="color: rgb(153, 153, '
             '153);">117</li><li style="color: rgb(153, 153, '
             '153);">118</li><li style="color: rgb(153, 153, '
             '153);">119</li><li style="color: rgb(153, 153, '
             '153);">120</li><li style="color: rgb(153, 153, '
             '153);">121</li><li style="color: rgb(153, 153, '
             '153);">122</li><li style="color: rgb(153, 153, '
             '153);">123</li><li style="color: rgb(153, 153, '
             '153);">124</li><li style="color: rgb(153, 153, '
             '153);">125</li><li style="color: rgb(153, 153, '
             '153);">126</li><li style="color: rgb(153, 153, '
             '153);">127</li><li style="color: rgb(153, 153, '
             '153);">128</li><li style="color: rgb(153, 153, '
             '153);">129</li><li style="color: rgb(153, 153, '
             '153);">130</li><li style="color: rgb(153, 153, '
             '153);">131</li><li style="color: rgb(153, 153, '
             '153);">132</li><li style="color: rgb(153, 153, '
             '153);">133</li><li style="color: rgb(153, 153, '
             '153);">134</li><li style="color: rgb(153, 153, '
             '153);">135</li><li style="color: rgb(153, 153, '
             '153);">136</li><li style="color: rgb(153, 153, '
             '153);">137</li><li style="color: rgb(153, 153, '
             '153);">138</li><li style="color: rgb(153, 153, '
             '153);">139</li><li style="color: rgb(153, 153, '
             '153);">140</li><li style="color: rgb(153, 153, '
             '153);">141</li><li style="color: rgb(153, 153, '
             '153);">142</li><li style="color: rgb(153, 153, '
             '153);">143</li><li style="color: rgb(153, 153, '
             '153);">144</li><li style="color: rgb(153, 153, '
             '153);">145</li><li style="color: rgb(153, 153, '
             '153);">146</li><li style="color: rgb(153, 153, '
             '153);">147</li><li style="color: rgb(153, 153, '
             '153);">148</li><li style="color: rgb(153, 153, '
             '153);">149</li><li style="color: rgb(153, 153, '
             '153);">150</li><li style="color: rgb(153, 153, '
             '153);">151</li><li style="color: rgb(153, 153, '
             '153);">152</li><li style="color: rgb(153, 153, '
             '153);">153</li><li style="color: rgb(153, 153, '
             '153);">154</li><li style="color: rgb(153, 153, '
             '153);">155</li><li style="color: rgb(153, 153, '
             '153);">156</li><li style="color: rgb(153, 153, '
             '153);">157</li><li style="color: rgb(153, 153, '
             '153);">158</li><li style="color: rgb(153, 153, '
             '153);">159</li><li style="color: rgb(153, 153, '
             '153);">160</li><li style="color: rgb(153, 153, '
             '153);">161</li><li style="color: rgb(153, 153, '
             '153);">162</li><li style="color: rgb(153, 153, '
             '153);">163</li><li style="color: rgb(153, 153, '
             '153);">164</li><li style="color: rgb(153, 153, '
             '153);">165</li><li style="color: rgb(153, 153, '
             '153);">166</li><li style="color: rgb(153, 153, '
             '153);">167</li><li style="color: rgb(153, 153, '
             '153);">168</li><li style="color: rgb(153, 153, '
             '153);">169</li><li style="color: rgb(153, 153, '
             '153);">170</li><li style="color: rgb(153, 153, '
             '153);">171</li><li style="color: rgb(153, 153, '
             '153);">172</li><li style="color: rgb(153, 153, '
             '153);">173</li><li style="color: rgb(153, 153, '
             '153);">174</li><li style="color: rgb(153, 153, '
             '153);">175</li><li style="color: rgb(153, 153, '
             '153);">176</li><li style="color: rgb(153, 153, '
             '153);">177</li><li style="color: rgb(153, 153, '
             '153);">178</li><li style="color: rgb(153, 153, '
             '153);">179</li><li style="color: rgb(153, 153, '
             '153);">180</li><li style="color: rgb(153, 153, '
             '153);">181</li><li style="color: rgb(153, 153, '
             '153);">182</li><li style="color: rgb(153, 153, '
             '153);">183</li><li style="color: rgb(153, 153, '
             '153);">184</li><li style="color: rgb(153, 153, '
             '153);">185</li><li style="color: rgb(153, 153, '
             '153);">186</li><li style="color: rgb(153, 153, '
             '153);">187</li><li style="color: rgb(153, 153, '
             '153);">188</li><li style="color: rgb(153, 153, '
             '153);">189</li><li style="color: rgb(153, 153, '
             '153);">190</li><li style="color: rgb(153, 153, '
             '153);">191</li><li style="color: rgb(153, 153, '
             '153);">192</li><li style="color: rgb(153, 153, '
             '153);">193</li><li style="color: rgb(153, 153, '
             '153);">194</li><li style="color: rgb(153, 153, '
             '153);">195</li><li style="color: rgb(153, 153, '
             '153);">196</li><li style="color: rgb(153, 153, '
             '153);">197</li><li style="color: rgb(153, 153, '
             '153);">198</li><li style="color: rgb(153, 153, '
             '153);">199</li><li style="color: rgb(153, 153, '
             '153);">200</li><li style="color: rgb(153, 153, '
             '153);">201</li><li style="color: rgb(153, 153, '
             '153);">202</li><li style="color: rgb(153, 153, '
             '153);">203</li><li style="color: rgb(153, 153, '
             '153);">204</li><li style="color: rgb(153, 153, '
             '153);">205</li><li style="color: rgb(153, 153, '
             '153);">206</li><li style="color: rgb(153, 153, '
             '153);">207</li><li style="color: rgb(153, 153, '
             '153);">208</li><li style="color: rgb(153, 153, '
             '153);">209</li><li style="color: rgb(153, 153, '
             '153);">210</li><li style="color: rgb(153, 153, '
             '153);">211</li><li style="color: rgb(153, 153, '
             '153);">212</li><li style="color: rgb(153, 153, '
             '153);">213</li><li style="color: rgb(153, 153, '
             '153);">214</li><li style="color: rgb(153, 153, '
             '153);">215</li><li style="color: rgb(153, 153, '
             '153);">216</li><li style="color: rgb(153, 153, '
             '153);">217</li><li style="color: rgb(153, 153, '
             '153);">218</li><li style="color: rgb(153, 153, '
             '153);">219</li><li style="color: rgb(153, 153, '
             '153);">220</li><li style="color: rgb(153, 153, '
             '153);">221</li><li style="color: rgb(153, 153, '
             '153);">222</li><li style="color: rgb(153, 153, '
             '153);">223</li><li style="color: rgb(153, 153, '
             '153);">224</li><li style="color: rgb(153, 153, '
             '153);">225</li><li style="color: rgb(153, 153, '
             '153);">226</li><li style="color: rgb(153, 153, '
             '153);">227</li><li style="color: rgb(153, 153, '
             '153);">228</li><li style="color: rgb(153, 153, '
             '153);">229</li><li style="color: rgb(153, 153, '
             '153);">230</li><li style="color: rgb(153, 153, '
             '153);">231</li><li style="color: rgb(153, 153, '
             '153);">232</li><li style="color: rgb(153, 153, '
             '153);">233</li><li style="color: rgb(153, 153, '
             '153);">234</li><li style="color: rgb(153, 153, '
             '153);">235</li><li style="color: rgb(153, 153, '
             '153);">236</li><li style="color: rgb(153, 153, '
             '153);">237</li><li style="color: rgb(153, 153, '
             '153);">238</li><li style="color: rgb(153, 153, '
             '153);">239</li><li style="color: rgb(153, 153, '
             '153);">240</li><li style="color: rgb(153, 153, '
             '153);">241</li><li style="color: rgb(153, 153, '
             '153);">242</li><li style="color: rgb(153, 153, '
             '153);">243</li><li style="color: rgb(153, 153, '
             '153);">244</li><li style="color: rgb(153, 153, '
             '153);">245</li><li style="color: rgb(153, 153, '
             '153);">246</li><li style="color: rgb(153, 153, '
             '153);">247</li><li style="color: rgb(153, 153, '
             '153);">248</li><li style="color: rgb(153, 153, '
             '153);">249</li><li style="color: rgb(153, 153, '
             '153);">250</li><li style="color: rgb(153, 153, '
             '153);">251</li><li style="color: rgb(153, 153, '
             '153);">252</li><li style="color: rgb(153, 153, '
             '153);">253</li><li style="color: rgb(153, 153, '
             '153);">254</li><li style="color: rgb(153, 153, '
             '153);">255</li><li style="color: rgb(153, 153, '
             '153);">256</li><li style="color: rgb(153, 153, '
             '153);">257</li><li style="color: rgb(153, 153, '
             '153);">258</li><li style="color: rgb(153, 153, '
             '153);">259</li><li style="color: rgb(153, 153, '
             '153);">260</li><li style="color: rgb(153, 153, '
             '153);">261</li><li style="color: rgb(153, 153, '
             '153);">262</li><li style="color: rgb(153, 153, '
             '153);">263</li><li style="color: rgb(153, 153, '
             '153);">264</li><li style="color: rgb(153, 153, '
             '153);">265</li><li style="color: rgb(153, 153, '
             '153);">266</li><li style="color: rgb(153, 153, '
             '153);">267</li><li style="color: rgb(153, 153, '
             '153);">268</li><li style="color: rgb(153, 153, '
             '153);">269</li><li style="color: rgb(153, 153, '
             '153);">270</li><li style="color: rgb(153, 153, '
             '153);">271</li><li style="color: rgb(153, 153, '
             '153);">272</li><li style="color: rgb(153, 153, '
             '153);">273</li><li style="color: rgb(153, 153, '
             '153);">274</li><li style="color: rgb(153, 153, '
             '153);">275</li><li style="color: rgb(153, 153, '
             '153);">276</li><li style="color: rgb(153, 153, '
             '153);">277</li><li style="color: rgb(153, 153, '
             '153);">278</li><li style="color: rgb(153, 153, '
             '153);">279</li><li style="color: rgb(153, 153, '
             '153);">280</li><li style="color: rgb(153, 153, '
             '153);">281</li></ul>\n'
             '\n'
             '<p><strong>3 </strong> <br>\n'
             '1python web_server.py <br>\n'
             '2web_client.html</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs perl '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">D:\\tools&gt;python server_web.py\n'
             '<span class="hljs-keyword">recv</span> <span '
             'class="hljs-number">200</span>\n'
             '{<span class="hljs-string">\'topic\'</span>: <span '
             'class="hljs-string">\'trade\'</span>, <span '
             'class="hljs-string">\'trading_dt\'</span>: <span '
             'class="hljs-string">\'18:58:22\'</span>, <span '
             'class="hljs-string">\'price\'</span>: <span '
             'class="hljs-number">882</span>, <span '
             'class="hljs-string">\'side\'</span>: <span '
             'class="hljs-string">\'BULL\'</span>}\n'
             '{<span class="hljs-string">\'topic\'</span>: <span '
             'class="hljs-string">\'trade\'</span>, <span '
             'class="hljs-string">\'trading_dt\'</span>: <span '
             'class="hljs-string">\'18:59:22\'</span>, <span '
             'class="hljs-string">\'price\'</span>: <span '
             'class="hljs-number">1032</span>, <span '
             'class="hljs-string">\'side\'</span>: <span '
             'class="hljs-string">\'BULL\'</span>}\n'
             '{<span class="hljs-string">\'topic\'</span>: <span '
             'class="hljs-string">\'trade\'</span>, <span '
             'class="hljs-string">\'trading_dt\'</span>: <span '
             'class="hljs-string">\'19:01:22\'</span>, <span '
             'class="hljs-string">\'price\'</span>: <span '
             'class="hljs-number">856</span>, <span '
             'class="hljs-string">\'side\'</span>: <span '
             'class="hljs-string">\'BULL\'</span>}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '\n'
             '<p> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/2018073019070643?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E2NDkzNDQ0NzU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>                                    '
             '</div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python Websocket']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:43 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:40:44 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/superdangbo/article/details/79680040">https://blog.csdn.net/superdangbo/article/details/79680040</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>macpython</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs mel '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">python</span> -V<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs  '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">Python 2.7.10<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p>python2python3, macjarhomebrew</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs cmake '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">brew <span class="hljs-keyword">install</span> '
             'python3<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p>pythonPython 3.6.4</p>\n'
             '\n'
             '<p>python3</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">python3 <span class="hljs-attribute">-V</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p></p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Mac python']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:44 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/hwq341182_X/article/details/79948504">https://blog.csdn.net/hwq341182_X/article/details/79948504</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>Python2&lt;&gt;!=,</p><pre><code '
             'class="language-python hljs"><ol class="hljs-ln"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">python@python:/home/share/<span '
             'class="hljs-number">2</span>py$ ipython</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">Python <span '
             'class="hljs-number">2.7</span><span '
             'class="hljs-number">.6</span> (default, Jun <span '
             'class="hljs-number">22</span> <span '
             'class="hljs-number">2015</span>, <span '
             'class="hljs-number">17</span>:<span '
             'class="hljs-number">58</span>:<span '
             'class="hljs-number">13</span>) </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">In [<span class="hljs-number">1</span>]: '
             'print(<span class="hljs-number">23</span> &lt;&gt; <span '
             'class="hljs-number">24</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-keyword">True</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">In [<span class="hljs-number">2</span>]: '
             'print(<span class="hljs-number">23</span> != <span '
             'class="hljs-number">24</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-keyword">True</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre><p>----------------------------------------------------------------------------------------------------</p><p>Python3k:!=,&lt;&gt;,</p><pre><code '
             'class="language-python hljs"><ol class="hljs-ln"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">python@python:/home/share/<span '
             'class="hljs-number">2</span>py$ '
             'ipython3</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">Python <span '
             'class="hljs-number">3.4</span><span '
             'class="hljs-number">.3</span> (default, Oct <span '
             'class="hljs-number">14</span> <span '
             'class="hljs-number">2015</span>, <span '
             'class="hljs-number">20</span>:<span '
             'class="hljs-number">28</span>:<span '
             'class="hljs-number">29</span>) </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">In [<span class="hljs-number">1</span>]: '
             'print(<span class="hljs-number">3</span> &lt;&gt; <span '
             'class="hljs-number">3</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">SyntaxError: invalid '
             'syntax</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">In [<span class="hljs-number">2</span>]: '
             'print(<span class="hljs-number">3</span> != <span '
             'class="hljs-number">3</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-keyword">False</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre><br>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python2python3']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:45 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/hongliang2009/article/details/72870321">https://blog.csdn.net/hongliang2009/article/details/72870321</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <p>\u3000'
             '<code>\u3000</code>\u3000'
             '<code>sys.path</code> <br>\n'
             'sudo python <code>\u3000</code>\u3000'
             '<code>sys.path</code>import '
             '.pth '
             '<code>/usr/local/lib/python2.7/dist-packages</code> <br>\n'
             '<a href="https://www.douban.com/note/334738164/" rel="nofollow" '
             'data-token="af1a1216068abdbefc649e15e57a2c60"></a></p>                                    '
             '</div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['pythonsudo python\u3000']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:46 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/u011915230/article/details/77619138">https://blog.csdn.net/u011915230/article/details/77619138</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>pythonMacpythonpython2python3python2python3 '
             '<br>\n'
             'brewpyenvpython <br>\n'
             'blogpython <br>\n'
             '<a '
             'href="http://blog.csdn.net/feifeilyj/article/details/62418916" '
             'rel="nofollow" '
             'data-token="d63a6102301b34488c707fd9ed5ef96b">http://blog.csdn.net/feifeilyj/article/details/62418916</a> '
             '<br>\n'
             'blogmacpython <br>\n'
             '<a href="http://blog.csdn.net/duyisen/article/details/47904575" '
             'rel="nofollow" '
             'data-token="2a7de5d2e6c31625367d316a987f2b74">http://blog.csdn.net/duyisen/article/details/47904575</a></p>\n'
             '\n'
             '<p>macPython <br>\n'
             'python <br>\n'
             'input : python  &gt;import sys  -&gt; print sys.path <br>\n'
             'pyenvpython3pyenv install '
             'listpython.pyenv '
             '<br>\n'
             '/Users/user/.pyenv/versions/3.5.2/bin/python3.5 <br>\n'
             '/System/Library/Frameworks/Python.framework/versions/2.7/bin/python2.7</p>                                    '
             '</div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['macpython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:47 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/coder_oyang/article/details/78864299">https://blog.csdn.net/coder_oyang/article/details/78864299</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             'Pythoncopy '
             'copy\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:40:47 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/zhujuyu/article/details/79303262">https://blog.csdn.net/zhujuyu/article/details/79303262</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<p>python:pythonreadTextFile.pymakeTextFile.py,readNwriteTextFile.py<span '
             'style="color:#ff0000;">os.system(filename)</span></p><pre><code '
             'class="language-python hljs"><ol class="hljs-ln"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">import</span> '
             'os</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">read</span><span '
             'class="hljs-params">()</span>:</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    os.system(<span '
             'class="hljs-string">"./readFileText.py"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">write</span><span '
             'class="hljs-params">()</span>:</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    os.system(<span '
             'class="hljs-string">"./writeFileText.py"</span>)</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre><p>python '
             'readNwriteTextFile.py </p><p>./readTextFile.py: '
             'Permission denied</p><p>ls '
             '-l</p><p><img '
             'src="https://img-blog.csdn.net/20180210095411543" '
             'alt=""><br></p><p>-rw-rw-r-- '
             '</p><p>Terminal chmod +x '
             'readTextFile.pypython '
             'readNwriteFileText.pywriteTextFile.py</p>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['pythonpythonpython']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:42:39 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/sinat_28056533/article/details/80625211">https://blog.csdn.net/sinat_28056533/article/details/80625211</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>PythonanacondaPythonprint(hello '
             'world)</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="pythonwindows-10"><a name="t0"></a>Pythonwindows '
             '10</h2>\n'
             '\n'
             '<p><strong>1. PythonAdd Python to '
             'PATH</strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180608165329685?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             'Eric MattesPythonPython '
             '<br>\n'
             ' <strong>2. python</strong> <br>\n'
             ' +Rcmd; <br>\n'
             ' <img '
             'src="https://img-blog.csdn.net/201806081658212?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180608165906842?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             'PythonEEpython.exe<img '
             'src="https://img-blog.csdn.net/20180608170512959?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             ' <strong>3. pythonpython3.6.164 bit</strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/2018060817060940?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             'windowspython</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="python"><a name="t1"></a>Python</h2>\n'
             '\n'
             '<p>python</p>\n'
             '\n'
             '<p><strong>1. '
             '.pyC</strong> <br>\n'
             ' <img '
             'src="https://img-blog.csdn.net/20180608171343818?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>\n'
             '\n'
             '<p><strong>2. .py</strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180608171853306?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             ' <strong>3. '
             'python.pypythonE.pyCpython '
             'RL_2.pypython</strong> <br>\n'
             ' <img '
             'src="https://img-blog.csdn.net/20180608172608794?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4MDU2NTMz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             ' </p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:40 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/foryouslgme/article/details/51445456">https://blog.csdn.net/foryouslgme/article/details/51445456</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <pre '
             'class="prettyprint" name="code"><code class="hljs avrasm '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">python2<span class="hljs-preprocessor">.x</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p>python2.xurlliburllib2 '
             'urllib2urlliburlliburllib2</p>\n'
             '\n'
             '<p>urllib2urllib2.openurlRequestHeaderUser '
             'Agenturllib2.</p>\n'
             '\n'
             '<p>urlliburllib.urlencode,posturllib</p>\n'
             '\n'
             '<p>urlliburllib2</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs avrasm '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">python3<span class="hljs-preprocessor">.x</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '\n'
             '<p>python 3.xurlliburilib2urllib</p>\n'
             '\n'
             '<p> <br>\n'
             'urllib2.urlopen()urllib.request.urlopen() <br>\n'
             'urllib2.Request()urllib.request.Request()  <br>\n'
             '</p>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python2Python3()urlliburllib2urllib']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:41 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ghui23/article/details/80554560">https://blog.csdn.net/ghui23/article/details/80554560</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>TIOBE20185python '
             '<br>\n'
             '<strong>5  TOP20 </strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180603101336383?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dodWkyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             '<strong>Top 10TIOBE2002-2018</strong> <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/20180603101430524?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dodWkyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             'python <br>\n'
             'PythonGuido van Rossum19891991  <br>\n'
             'python  <br>\n'
             '<img '
             'src="https://img-blog.csdn.net/2018060313065337?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dodWkyMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""> <br>\n'
             '80guidoshellshellUNIXCshellshellshell  '
             '<br>\n'
             'guidoCshell  '
             '<br>\n'
             'CWICentrum Wiskunde &amp; Informatica, '
             'ABCABCIO  '
             '<br>\n'
             'ABCguido <br>\n'
             '1989GuidoABC '
             'pythonMonty Pythons Flying Circus  '
             '<br>\n'
             '1991PythonCC(.so)Python(class)(function)(exception)(list)(dictionary)(module)  '
             '<br>\n'
             'guidoABCpythonCpythonguidoPython  '
             '<br>\n'
             'python1990Intel486windowswindow '
             '3.0InternetInternetpythonpythonpython '
             '<br>\n'
             'GuidomaillistpythonpythonpythonpythonpythonGuidoGuidopythonpython  '
             '<br>\n'
             'python2.0maillistInternetpython  '
             '<br>\n'
             'PythonPython(Everything is '
             'object)(multi-paradigm)(dynamic '
             'typing)(garbage '
             'collection)Python(interpret)CPython '
             '(battery included)Python</p>\n'
             '\n'
             '<h3 id="python-">python </h3>\n'
             '\n'
             '<p>PythonPerlPythonPython[]PythonPythonPythonPerlPythonPythonimport '
             'this <br>\n'
             'PythonPythonPythonPythonJITC/C++JITPyPy '
             '<br>\n'
             'PythonPythonLispPython(functools, '
             'itertools)HaskellStandard ML <br>\n'
             'Pythonscript '
             'languageZopeMnetBitTorrentGooglePythonshellscriptVBScriptPython '
             '<br>\n'
             'PythonPythonAPICC++CythonPythonPythonglue '
             'languagePythonGoogleGoogle '
             'EngineC++PythonJava/GoPythonAlex '
             'Martelli2004 Python Google Google  '
             'Python Python Python where we can, C++ '
             'where we must C++ Python</p>\n'
             '\n'
             '<p>reference: <br>\n'
             'Python <br>\n'
             '<a '
             'href="https://blog.csdn.net/diosmai_kingso/article/details/78767636" '
             'rel="nofollow" '
             'data-token="0811faa56f19c3f9e9070869bcee47cf">https://blog.csdn.net/diosmai_kingso/article/details/78767636</a> '
             '<br>\n'
             'Python  <br>\n'
             '<a '
             'href="https://www.cnblogs.com/vamei/archive/2013/02/06/2892628.html" '
             'rel="nofollow" '
             'data-token="a32ed9c9deeba0901b8606d95d5ce251">https://www.cnblogs.com/vamei/archive/2013/02/06/2892628.html</a>  '
             '<br>\n'
             'Python  <br>\n'
             '<a '
             'href="https://baike.baidu.com/item/Python/407313?fr=aladdin#1" '
             'rel="nofollow" '
             'data-token="2fd551bb2f9a4d5722c922c74fa0e5df">https://baike.baidu.com/item/Python/407313?fr=aladdin#1</a></p>                                    '
             '</div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python---python']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:42 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/wd1603926823/article/details/51786391">https://blog.csdn.net/wd1603926823/article/details/51786391</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<p>Pythonopencv3.1dnncaffecaffePythongooglecaffeleveldblmdbpythonpythonpythonpython</p>\n'
             '<p>pythonpython--Core Python '
             'Programming-----Dive into python-----</p>\n'
             '<p>https://www.python.org/ \xa0'
             'win732 \xa0'
             'python3.5.2-----------------python '
             '3.5IDLE</p>\n'
             '<p>http://blog.csdn.net/wishchin/article/details/9367719 \xa0\xa0'
             'https://www.52ml.net/</p>\n'
             '<p>http://old.sebug.net/paper/python/ch02s02.htmlpython</p>\n'
             '<p></p>\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20160629222820952?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" '
             'alt=""><br></p>\n'
             '<p>http://old.sebug.net/paper/python/ch04s07.html4.1 '
             '4.1linuxpython \xa0'
             'print \xa0'
             'win7pythonprint</p>\n'
             '<p><img src="https://img-blog.csdn.net/20160629223040393" '
             'alt=""></p>\n'
             '<p> \xa0python2.7.11<img '
             'src="https://img-blog.csdn.net/20160630122422363?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" '
             'alt=""></p>\n'
             '<p> \xa0 \xa0'
             'python2.7.11 \xa0python3.5<br></p>\n'
             '<p></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160630124937444" '
             'alt="">6.1 \xa0 \xa0'
             ' \xa0  \xa0  \xa0'
             '<img src="https://img-blog.csdn.net/20160630125418736" '
             'alt=""><img src="https://img-blog.csdn.net/20160630151657944" '
             'alt="">\n'
             ' matlabi=15 4<img '
             'src="https://img-blog.csdn.net/20160630152519301" '
             'alt="">len()<br></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160630154947920" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160630155849361" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160630162348294" '
             'alt="">return<img '
             'src="https://img-blog.csdn.net/20160630164611382" '
             'alt="">-6-4-6\n'
             ' \xa0  \xa0 \xa0<img '
             'src="https://img-blog.csdn.net/20160630170156542" '
             'alt="">_    '
             '<img src="https://img-blog.csdn.net/20160630170725970" '
             'alt=""> \xa0'
             'x=int(x)y=int(y)<img '
             'src="https://img-blog.csdn.net/20160630170319887" '
             'alt="">2554\n'
             '   \xa0<br></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160701095134935" '
             'alt="">dir.py  \xa0'
             'Shell<br></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160701102512619" '
             'alt=""> \xa0 python '
             ' \xa0<img '
             'src="https://img-blog.csdn.net/20160701102731620" '
             'alt="">for list '
             'C++<img '
             'src="https://img-blog.csdn.net/20160701111206904" '
             'alt="">\n'
             ' list0  <img '
             'src="https://img-blog.csdn.net/20160701113459342?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" '
             'alt=""><br></p>\n'
             '<p>nameaddress.items() if\xa0<img '
             'src="https://img-blog.csdn.net/20160701145703798" '
             'alt="">  # '
             'matlab13<img '
             'src="https://img-blog.csdn.net/20160701153207072" '
             'alt="">  <img '
             'src="https://img-blog.csdn.net/20160701155205863" '
             'alt="">python</p>\n'
             '<p> \xa0linux \xa0 windows<img '
             'src="https://img-blog.csdn.net/20160701163452706" '
             'alt="">windowsziphttp://bbs.chinaunix.net/thread-1045367-1-1.htmlhttp://notyour.blog.163.com/blog/static/16941250201091511125788/<img '
             'src="https://img-blog.csdn.net/20160704100008121" alt=""><img '
             'src="https://img-blog.csdn.net/20160704100038793" alt=""><img '
             'src="https://img-blog.csdn.net/20160704100052708" alt=""><img '
             'src="https://img-blog.csdn.net/20160704100100903" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160704110536368" '
             'alt="">pythonLinuxwindows</p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160704110624862" '
             'alt="">Python<img '
             'src="https://img-blog.csdn.net/20160704110840166" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160704110920901" '
             'alt=""> kalam.__del__():<img '
             'src="https://img-blog.csdn.net/20160704111346043" '
             'alt="">\n'
             '  N \xa0  <img '
             'src="https://img-blog.csdn.net/20160704111739895" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160704113813867" alt="">C++ '
             'primer python '
             'C++<br></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160706140409669" '
             'alt=""><img src="https://img-blog.csdn.net/20160706140421747" '
             'alt=""><br></p>\n'
             '<p></p>\n'
             '<p><img src="https://img-blog.csdn.net/20160706144116927" '
             'alt=""> \xa0python example33.py \xa0'
             '--version  windows \xa0 \xa0'
             'append() \xa0<img '
             'src="https://img-blog.csdn.net/20160706144231090" alt=""></p>\n'
             '<p>python</p>\n'
             '<p><img src="https://img-blog.csdn.net/20160706151850963" '
             'alt=""> \xa0python \xa0<img '
             'src="https://img-blog.csdn.net/20160706151936776" '
             'alt=""><img '
             'src="https://img-blog.csdn.net/20160706152333106" '
             'alt="">assertwindows\n'
             ' \xa0'
             'http://notyour.blog.163.com/blog/static/169412502010106105033698/ '
             'windowsreturn \xa0</p>\n'
             '<p>python</p>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python(Win7)python']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/LiJiancheng0614/article/details/45819873">https://blog.csdn.net/LiJiancheng0614/article/details/45819873</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>pythonEXIF</p>\n'
             '\n'
             '<h2 id=""><a name="t0"></a></h2>\n'
             '\n'
             '<ol>\n'
             '<li><code>PIL.Image</code>EXIF</li>\n'
             '<li><a href="https://pypi.python.org/pypi/ExifRead" '
             'rel="nofollow" '
             'data-token="1aa7d94732599d9d1f3190363847a2a6">https://pypi.python.org/pypi/ExifRead</a> '
             'EXIFEXIFdict</li>\n'
             '</ol>\n'
             '\n'
             '<h2 id=""><a name="t1"></a></h2>\n'
             '\n'
             '<ol>\n'
             '<li><p>aEXIFb</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-keyword">from</span> PIL <span '
             'class="hljs-keyword">import</span> Image\n'
             '\n'
             'image1_path = <span class="hljs-string">\'1.jpg\'</span>\n'
             'image2_path = <span class="hljs-string">\'2.jpg\'</span>\n'
             'im = Image.open(image1_path)\n'
             'exif = im.info[<span class="hljs-string">\'exif\'</span>]\n'
             'im = Image.open(image2_path)\n'
             'im.save(image2_path, exif=exif)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul></li>\n'
             '<li><p>EXIFDateTimeOriginal</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-keyword">import</span> os\n'
             '<span class="hljs-keyword">import</span> exifread\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">getExif</span><span '
             'class="hljs-params">(filename)</span>:</span>\n'
             '    FIELD = <span class="hljs-string">\'EXIF '
             "DateTimeOriginal'</span>\n"
             '    fd = open(filename, <span '
             'class="hljs-string">\'rb\'</span>)\n'
             '    tags = exifread.process_file(fd)\n'
             '    fd.close()\n'
             '    print(<span class="hljs-string">\'=== \'</span>, filename)\n'
             '    <span class="hljs-keyword">if</span> FIELD <span '
             'class="hljs-keyword">in</span> tags:\n'
             '        new_name = str(tags[FIELD]).replace(<span '
             'class="hljs-string">\':\'</span>, <span '
             'class="hljs-string">\'\'</span>).replace(<span '
             'class="hljs-string">\' \'</span>, <span '
             'class="hljs-string">\'_\'</span>) + '
             'os.path.splitext(filename)[<span class="hljs-number">1</span>]\n'
             '        tot = <span class="hljs-number">1</span>\n'
             '        <span class="hljs-keyword">while</span> '
             'os.path.exists(new_name):\n'
             '            new_name = str(tags[FIELD]).replace(<span '
             'class="hljs-string">\':\'</span>, <span '
             'class="hljs-string">\'\'</span>).replace(<span '
             'class="hljs-string">\' \'</span>, <span '
             'class="hljs-string">\'_\'</span>) + <span '
             'class="hljs-string">\'_\'</span> + str(tot) + '
             'os.path.splitext(filename)[<span class="hljs-number">1</span>]\n'
             '            tot += <span class="hljs-number">1</span>\n'
             '        print(new_name)\n'
             '        os.rename(filename, new_name)\n'
             '    <span class="hljs-keyword">else</span>:\n'
             '        print(<span class="hljs-string">\'No {} '
             "found'</span>.format(FIELD))\n"
             '\n'
             '<span class="hljs-keyword">for</span> filename <span '
             'class="hljs-keyword">in</span> os.listdir(<span '
             'class="hljs-string">\'.\'</span>):\n'
             '    <span class="hljs-keyword">if</span> '
             'os.path.isfile(filename):\n'
             '        getExif(filename)<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li></ul></li>\n'
             '</ol>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['[Python] pythonEXIF']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/neal1991/article/details/50215215">https://blog.csdn.net/neal1991/article/details/50215215</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>pythonpythonpython '
             '<br>\n'
             'python</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="1python"><a name="t0"></a>1.python</h2>\n'
             '\n'
             '<p>CPython <br>\n'
             'Cpython <br>\n'
             'pythonC <br>\n'
             'C</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs cs '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-keyword">int</span> a = <span '
             'class="hljs-number">1</span>;\n'
             '<span class="hljs-keyword">int</span> b = <span '
             'class="hljs-number">2</span>;\n'
             '<span class="hljs-keyword">int</span> c = a + b;<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.692621;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li></ul>\n'
             '\n'
             '<p>1.1a <br>\n'
             '2.2b <br>\n'
             '3.</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs ini '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-setting">a = <span '
             'class="hljs-value"><span '
             'class="hljs-number">1</span></span></span>\n'
             '<span class="hljs-setting">b = <span class="hljs-value"><span '
             'class="hljs-number">2</span></span></span>\n'
             '<span class="hljs-setting">c = <span class="hljs-value">a + '
             'b</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.692621;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li></ul>\n'
             '\n'
             '<p>1.1a</p>\n'
             '\n'
             '<ul>\n'
             '<li></li>\n'
             '<li><p>1 <br>\n'
             '2.2b</p></li>\n'
             '<li><p></p></li>\n'
             '<li><p>2 <br>\n'
             '3.(a,b)</p></li>\n'
             '<li><p></p></li>\n'
             '<li>aa</li>\n'
             '<li></li>\n'
             '<li>bb</li>\n'
             '<li></li>\n'
             '<li><p> <br>\n'
             '4.c</p></li>\n'
             '<li><p></p></li>\n'
             '<li> <br>\n'
             'pythonc</li>\n'
             '</ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="2python"><a '
             'name="t1"></a>2.python</h2>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="3python"><a '
             'name="t2"></a>3.python</h2>\n'
             '\n'
             '<p>python <br>\n'
             '<img src="https://img-blog.csdn.net/20151208101154529" '
             'alt="" title=""></p>\n'
             '\n'
             '<p>pythonpythonpythonmatlabpythonpython</p>                                    '
             '</div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python--python']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'article_type.Aid' in 'field list'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 26, in process_item
    articletype = session.query(ArticleType).filter_by(Tname = article['Atype']).first()
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2825, in first
    ret = list(self[0:1])
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2617, in __getitem__
    return list(res)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2925, in __iter__
    return self._execute_and_instances(context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\orm\query.py", line 2948, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 948, in execute
    return meth(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\sql\elements.py", line 269, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1060, in _execute_clauseelement
    compiled_sql, distilled_params
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1200, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1413, in _handle_dbapi_exception
    exc_info
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\util\compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\base.py", line 1193, in _execute_context
    context)
  File "d:\programdata\anaconda3\lib\site-packages\sqlalchemy\engine\default.py", line 507, in do_execute
    cursor.execute(statement, parameters)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 170, in execute
    result = self._query(query)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py", line 328, in _query
    conn.query(q)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 732, in _read_query_result
    result.read()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\connections.py", line 684, in _read_packet
    packet.check_error()
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "d:\programdata\anaconda3\lib\site-packages\pymysql\err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1054, "Unknown column 'article_type.Aid' in 'field list'") [SQL: 'SELECT article_type.`Aid` AS `article_type_Aid`, article_type.`Tname` AS `article_type_Tname`, article_type.`Tdescribe` AS `article_type_Tdescribe` \nFROM article_type \nWHERE article_type.`Tname` = %(Tname_1)s \n LIMIT %(param_1)s'] [parameters: {'Tname_1': 'python', 'param_1': 1}] (Background on this error at: http://sqlalche.me/e/2j85)
2019-10-31 17:42:44 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-10-31 17:42:45 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-10-31 17:43:40 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:43:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:43:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:43:40 [scrapy.extensions.telnet] INFO: Telnet Password: 76dbf2f04d0ffb3f
2019-10-31 17:43:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:43:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:43:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:43:42 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:43:42 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:43:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:43:42 [python_spider] INFO: Spider opened: python_spider
2019-10-31 17:43:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:46:03 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:47:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:47:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:47:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:47:47 [scrapy.extensions.telnet] INFO: Telnet Password: 41dd55e69a3d20fc
2019-10-31 17:47:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:47:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:47:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:47:49 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:47:49 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:47:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:47:49 [java_spider] INFO: Spider opened: java_spider
2019-10-31 17:47:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:49:11 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:49:12 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:49:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:49:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1463881,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 49, 12, 447397),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 10, 31, 9, 47, 49, 86421)}
2019-10-31 17:49:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 17:49:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:49:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:49:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:49:58 [scrapy.extensions.telnet] INFO: Telnet Password: 5e37331b994dbf59
2019-10-31 17:49:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:49:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:49:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:49:59 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:49:59 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:49:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:49:59 [java_spider] INFO: Spider opened: java_spider
2019-10-31 17:49:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:51:13 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:51:13 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:51:14 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:51:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1482568,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 51, 14, 188679),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 10, 31, 9, 49, 59, 532718)}
2019-10-31 17:51:14 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 17:51:55 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:51:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:51:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:51:55 [scrapy.extensions.telnet] INFO: Telnet Password: 93de54a3fd309cdc
2019-10-31 17:51:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:51:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:51:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:51:56 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:51:56 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:51:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:51:56 [python_spider] INFO: Spider opened: python_spider
2019-10-31 17:51:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:53:09 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:53:10 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:53:13 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:53:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3045258,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 53, 13, 567543),
 'item_scraped_count': 3,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2019, 10, 31, 9, 51, 56, 955123)}
2019-10-31 17:53:13 [scrapy.core.engine] INFO: Spider closed (finished)
2019-10-31 17:53:41 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-10-31 17:53:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-10-31 17:53:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-10-31 17:53:41 [scrapy.extensions.telnet] INFO: Telnet Password: b816387b005c91b3
2019-10-31 17:53:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-10-31 17:53:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-10-31 17:53:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-10-31 17:53:42 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-10-31 17:53:42 [scrapy.core.engine] INFO: Spider opened
2019-10-31 17:53:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:53:42 [python_spider] INFO: Spider opened: python_spider
2019-10-31 17:53:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-10-31 17:55:11 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-10-31 17:55:35 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-10-31 17:56:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 3 pages/min), scraped 3 items (at 3 items/min)
2019-10-31 17:57:09 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/machitaoX/article/details/85054039">https://blog.csdn.net/machitaoX/article/details/85054039</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2><a '
             'name="t0"></a><a id="1_0"></a>1</h2>\n'
             '<p>python 3<br>\n'
             '&gt;&gt;&gt; print(hello python inter)</p>\n'
             '<h2><a name="t1"></a><a id="2python_4"></a>2python</h2>\n'
             '<p>1geanyrootapt-get install geany<br>\n'
             '2pythonpython commands : compilepython 3<br>\n'
             'execute python 3</p>\n'
             '<h2><a name="t2"></a><a id="3_8"></a>3</h2>\n'
             '<p>Linux python ***.py</p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python:    execute']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-10-31 17:57:09 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 3 pages/min), scraped 5 items (at 2 items/min)
2019-10-31 17:58:07 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 3 pages/min), scraped 8 items (at 3 items/min)
2019-10-31 17:59:16 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 4 pages/min), scraped 11 items (at 3 items/min)
2019-10-31 17:59:18 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/Rozol/article/details/71081854">https://blog.csdn.net/Rozol/article/details/71081854</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="python3-pythonpickle-shelve"><a name="t0"></a>Python3 '
             'Python(pickle / shelve)</h1>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<p><strong> Luzhuo ,.</strong> <br>\n'
             '<strong>: '
             '<code>http://blog.csdn.net/rozol/article/details/71081854</code></strong>  '
             '</p>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<blockquote>\n'
             '  <p>Python3.6.1 <br>\n'
             '  Less is more!</p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="pickle"><a name="t1"></a>pickle</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#coding=utf-8</span>\n'
             '<span class="hljs-comment"># pickledemo.py Pickle</span>\n'
             '<span class="hljs-comment"># Python</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> pickle\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">demo</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>)\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    strs = <span class="hljs-string">""</span>\n'
             '    num = <span class="hljs-number">123</span>\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    pickle.dump(lists, f) <span class="hljs-comment"># '
             '</span>\n'
             '    pickle.dump(strs, f)\n'
             '    pickle.dump(num, f)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    f.close()\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"rb+"</span>)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    data = pickle.load(f) <span class="hljs-comment"># '
             '</span>\n'
             '    <span class="hljs-keyword">print</span> (data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '\n'
             '    f.close()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">pickle_funs</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>) <span '
             'class="hljs-comment"># (:wb+)</span>\n'
             '\n'
             '    num = pickle.HIGHEST_PROTOCOL <span class="hljs-comment"># '
             '(4)</span>\n'
             '    num = pickle.DEFAULT_PROTOCOL <span class="hljs-comment"># '
             '(3) {3:bytes; 4:}</span>\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># dump(obj, file, protocol=None, '
             '*, fix_imports=True) // obj</span>\n'
             '    pickle.dump(lists, f)\n'
             '    <span class="hljs-comment"># dumps(obj, protocol=None, *, '
             'fix_imports=True) // objbytes</span>\n'
             '    bytes = pickle.dumps(lists)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># load(file, *, fix_imports=True, '
             'encoding="ASCII", errors="strict") // fileobj</span>\n'
             '    lists = pickle.load(f)\n'
             '    <span class="hljs-comment"># loads(bytes_object, *, '
             'fix_imports=True, encoding="ASCII", errors="strict") // '
             'bytesobj</span>\n'
             '    lists = pickle.loads(bytes)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-keyword">try</span>:\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.PicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.UnpicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> pickle.PickleError: '
             '<span class="hljs-comment"># pickling</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    demo()\n'
             '    pickle_funs()\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.985197;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li '
             'style="color: rgb(153, 153, 153);">55</li><li style="color: '
             'rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, '
             '153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li '
             'style="color: rgb(153, 153, 153);">59</li><li style="color: '
             'rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, '
             '153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li '
             'style="color: rgb(153, 153, 153);">63</li><li style="color: '
             'rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, '
             '153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li '
             'style="color: rgb(153, 153, 153);">67</li><li style="color: '
             'rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, '
             '153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li '
             'style="color: rgb(153, 153, 153);">71</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="shelve"><a name="t2"></a>shelve</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#!/usr/bin/env python</span>\n'
             '<span class="hljs-comment"># coding=utf-8</span>\n'
             '__author__ = <span class="hljs-string">\'Luzhuo\'</span>\n'
             '__date__ = <span class="hljs-string">\'2017/5/26\'</span>\n'
             '<span class="hljs-comment"># shelve_demo.py '
             ':Python</span>\n'
             '<span class="hljs-comment"># , , '
             'picklePython</span>\n'
             '<span class="hljs-comment"># pickle, '
             '</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> shelve\n'
             '\n'
             '\n'
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">Person</span><span '
             'class="hljs-params">(object)</span>:</span>\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__init__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        self.name = <span class="hljs-string">"luzhuo"</span>\n'
             '        self.age = <span class="hljs-number">21</span>\n'
             '\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__str__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        <span class="hljs-keyword">return</span> <span '
             'class="hljs-string">"name: {}, age: {}"</span>.format(self.name, '
             'self.age)\n'
             '\n'
             'path = <span class="hljs-string">"file.txt"</span>\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_write</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> write: <span '
             'class="hljs-comment"># </span>\n'
             '        write[<span class="hljs-string">"nums"</span>] = [<span '
             'class="hljs-number">1</span>, <span '
             'class="hljs-number">2</span>, <span '
             'class="hljs-number">3</span>, <span '
             'class="hljs-number">4</span>, <span '
             'class="hljs-number">5</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        write[<span class="hljs-string">"obj"</span>] = '
             'Person()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_read</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> read:  <span '
             'class="hljs-comment"># </span>\n'
             '        nums = read.get(<span '
             'class="hljs-string">"nums"</span>)  <span class="hljs-comment"># '
             '</span>\n'
             '        print(nums)\n'
             '        clazz = read[<span class="hljs-string">"obj"</span>]\n'
             '        print(clazz)\n'
             '\n'
             '        <span class="hljs-keyword">del</span> read[<span '
             'class="hljs-string">"obj"</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        print(<span class="hljs-string">"obj"</span> <span '
             'class="hljs-keyword">in</span> read)\n'
             '\n'
             '        keys = list(read.keys())  <span class="hljs-comment"># '
             'key</span>\n'
             '        print(keys)\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_func</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># , filename:, '
             'writeback:(True,), Shelf</span>\n'
             '    <span class="hljs-comment"># shelve.open(filename, '
             "flag='c', protocol=None, writeback=False)</span>\n"
             '    d = shelve.open(path)\n'
             '\n'
             '    <span class="hljs-comment"># Shelf</span>\n'
             '    <span class="hljs-comment"># </span>\n'
             '    <span class="hljs-comment"># get(self, key, default=None) // '
             ' == data = shelf["key"]</span>\n'
             '    data = d.get(<span class="hljs-string">"key"</span>)\n'
             '    d.sync()  <span class="hljs-comment"># (,)</span>\n'
             '    d.close()  <span class="hljs-comment"># </span>\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># class shelve.Shelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8')</span>\n"
             '    <span class="hljs-comment"># class shelve.BsdDbShelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8') // "
             'Shelf</span>\n'
             '    <span class="hljs-comment"># class '
             "shelve.DbfilenameShelf(filename, flag='c', protocol=None, "
             'writeback=False) // Shelf</span>\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    shelve_write()\n'
             '    shelve_read()\n'
             '\n'
             '    <span class="hljs-comment"># shelve_func()</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style="opacity: 0.985197;"><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li '
             'style="color: rgb(153, 153, 153);">11</li><li style="color: '
             'rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li '
             'style="color: rgb(153, 153, 153);">15</li><li style="color: '
             'rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, '
             '153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li '
             'style="color: rgb(153, 153, 153);">19</li><li style="color: '
             'rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, '
             '153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li '
             'style="color: rgb(153, 153, 153);">23</li><li style="color: '
             'rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, '
             '153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li '
             'style="color: rgb(153, 153, 153);">27</li><li style="color: '
             'rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, '
             '153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li '
             'style="color: rgb(153, 153, 153);">31</li><li style="color: '
             'rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, '
             '153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li '
             'style="color: rgb(153, 153, 153);">35</li><li style="color: '
             'rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, '
             '153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li '
             'style="color: rgb(153, 153, 153);">39</li><li style="color: '
             'rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, '
             '153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li '
             'style="color: rgb(153, 153, 153);">43</li><li style="color: '
             'rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, '
             '153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li '
             'style="color: rgb(153, 153, 153);">47</li><li style="color: '
             'rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, '
             '153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li '
             'style="color: rgb(153, 153, 153);">51</li><li style="color: '
             'rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, '
             '153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li '
             'style="color: rgb(153, 153, 153);">55</li><li style="color: '
             'rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, '
             '153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li '
             'style="color: rgb(153, 153, 153);">59</li><li style="color: '
             'rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, '
             '153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li '
             'style="color: rgb(153, 153, 153);">63</li><li style="color: '
             'rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, '
             '153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li '
             'style="color: rgb(153, 153, 153);">67</li><li style="color: '
             'rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, '
             '153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li '
             'style="color: rgb(153, 153, 153);">71</li><li style="color: '
             'rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, '
             '153);">73</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python3 Python(pickle / shelve)']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-10-31 17:59:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-10-31 17:59:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 15788969,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 10, 31, 9, 59, 19, 594563),
 'item_scraped_count': 14,
 'log_count/ERROR': 2,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2019, 10, 31, 9, 53, 42, 434321)}
2019-10-31 17:59:19 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:06:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:06:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:07:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:07:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:07:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:07:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:07:49 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:07:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:08:11 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:08:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:12:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:12:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:12:48 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:12:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:14:01 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:14:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:48:32 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:48:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:48:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:48:32 [scrapy.extensions.telnet] INFO: Telnet Password: c26187d900dc1b5a
2019-11-01 09:48:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:48:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:48:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:48:33 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline']
2019-11-01 09:48:33 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:48:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:48:33 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:48:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 09:49:47 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:49:48 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 09:49:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 09:49:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1509489,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 1, 49, 49, 108291),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 48, 33, 595932)}
2019-11-01 09:49:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:50:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:50:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:50:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:50:47 [scrapy.extensions.telnet] INFO: Telnet Password: 19fbdded5788ee23
2019-11-01 09:50:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:50:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:50:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:50:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 09:50:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:50:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:50:48 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:50:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 09:52:00 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:52:01 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 09:52:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 09:52:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1539636,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 1, 52, 2, 564641),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 50, 48, 603366)}
2019-11-01 09:52:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:53:41 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:53:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:53:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:53:42 [scrapy.extensions.telnet] INFO: Telnet Password: a1f59969a6dcd528
2019-11-01 09:53:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:53:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:53:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:53:43 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 09:53:43 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:53:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:53:43 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:53:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 09:54:58 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:54:59 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 09:55:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 09:55:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1525467,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 1, 55, 0, 253099),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 53, 43, 406935)}
2019-11-01 09:55:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:55:48 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:55:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:55:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:55:48 [scrapy.extensions.telnet] INFO: Telnet Password: 91cfd419b6208755
2019-11-01 09:55:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:55:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:55:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:55:49 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 09:55:49 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:55:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:55:49 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:55:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 09:57:03 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:57:04 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 09:57:05 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 09:57:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1481199,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 1, 57, 5, 757113),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 55, 49, 728715)}
2019-11-01 09:57:05 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:57:39 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:57:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:57:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:57:39 [scrapy.extensions.telnet] INFO: Telnet Password: 1f7e289603330c90
2019-11-01 09:57:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:57:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:57:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:57:41 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 09:57:41 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:57:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:57:41 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:57:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 09:58:54 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:58:55 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 09:58:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 09:58:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1523029,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 1, 58, 56, 417607),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 57, 41, 472566)}
2019-11-01 09:58:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 09:59:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 09:59:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 09:59:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 09:59:57 [scrapy.extensions.telnet] INFO: Telnet Password: 8e93e6c1b9d60e8a
2019-11-01 09:59:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 09:59:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 09:59:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 09:59:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 09:59:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 09:59:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 09:59:58 [java_spider] INFO: Spider opened: java_spider
2019-11-01 09:59:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:01:13 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:01:13 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:01:14 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:01:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1525142,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 1, 14, 950815),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 1, 59, 58, 616651)}
2019-11-01 10:01:14 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:04:00 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:04:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:04:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:04:00 [scrapy.extensions.telnet] INFO: Telnet Password: d59b404ccfd6bb9c
2019-11-01 10:04:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:04:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:04:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:04:01 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:04:01 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:04:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:04:02 [java_spider] INFO: Spider opened: java_spider
2019-11-01 10:04:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:08:23 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-11-01 10:08:23 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, '', None, 10054, None))': /session/bb9ec0d4462df971f7a1bd4879ea8ae1/source
2019-11-01 10:08:24 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-11-01 10:08:24 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EA2A69DDD8>: Failed to establish a new connection: [WinError 10061] ',)': /session/bb9ec0d4462df971f7a1bd4879ea8ae1/source
2019-11-01 10:08:25 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EA2A69DBE0>: Failed to establish a new connection: [WinError 10061] ',)': /session/bb9ec0d4462df971f7a1bd4879ea8ae1/source
2019-11-01 10:08:40 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 10:08:40 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:08:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/ytusdc/article/details/78878995>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001EA2A69DDA0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 91, in process_request
    html = self.driver.page_source
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 66, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 87, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=62233): Max retries exceeded with url: /session/bb9ec0d4462df971f7a1bd4879ea8ae1/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EA2A69DDA0>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 10:08:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:08:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:08:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:08:47 [scrapy.extensions.telnet] INFO: Telnet Password: 52c4a768c0e705c5
2019-11-01 10:08:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:08:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:08:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:08:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:08:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:08:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:08:48 [java_spider] INFO: Spider opened: java_spider
2019-11-01 10:08:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:10:02 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:10:03 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:10:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:10:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1481707,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 10, 7, 795411),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 2, 8, 48, 796343)}
2019-11-01 10:10:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:12:36 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:12:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:12:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:12:36 [scrapy.extensions.telnet] INFO: Telnet Password: d3bd03c595940a94
2019-11-01 10:12:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:12:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:12:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:12:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:12:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:12:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:12:37 [java_spider] INFO: Spider opened: java_spider
2019-11-01 10:12:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:13:51 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:13:52 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:13:53 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:13:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1507680,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 13, 53, 462775),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 2, 12, 37, 734225)}
2019-11-01 10:13:53 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:20:50 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:20:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:20:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:20:51 [scrapy.extensions.telnet] INFO: Telnet Password: f5a8ab3673be1d2c
2019-11-01 10:20:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:20:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:20:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:20:52 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:20:52 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:20:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:20:52 [js_spider] INFO: Spider opened: js_spider
2019-11-01 10:20:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:25:18 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:26:07 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:26:08 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 10:26:14 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js', 'content': [], 'title': []}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 12, in process_item
    html = create_html(article['content'][0], article['title'][0])
IndexError: list index out of range
2019-11-01 10:26:14 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js', 'content': [], 'title': []}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 12, in process_item
    html = create_html(article['content'][0], article['title'][0])
IndexError: list index out of range
2019-11-01 10:26:14 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js', 'content': [], 'title': []}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 12, in process_item
    html = create_html(article['content'][0], article['title'][0])
IndexError: list index out of range
2019-11-01 10:26:14 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js', 'content': [], 'title': []}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 12, in process_item
    html = create_html(article['content'][0], article['title'][0])
IndexError: list index out of range
2019-11-01 10:26:14 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js', 'content': [], 'title': []}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 12, in process_item
    html = create_html(article['content'][0], article['title'][0])
IndexError: list index out of range
2019-11-01 10:27:29 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 5 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 10:27:31 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/weixin_42323802/article/details/82776451">https://blog.csdn.net/weixin_42323802/article/details/82776451</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p><strong>js '
             '/javascrip</strong>t ----&gt;</p>\n'
             '\n'
             '<p><strong>ECMAscript</strong> () DOM ,BOM = browser '
             'object modle</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">&lt;script '
             'type="text/javascript"&gt;&lt;/script&gt;</span> '
             '<strong>HTML</strong><strong>HTML</strong></p>\n'
             '\n'
             '<p><strong>js</strong></p>\n'
             '\n'
             '<p>jsvar js<span '
             'style="color:#86ca5e;"><strong></strong></span>2var,varvar '
             'i=0; </p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">function () {<br>\n'
             '\xa0 \xa0 ;<br>\n'
             '\xa0 \xa0 [return ];<br>\n'
             '}</span></p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span '
             'class="hljs-params">a,b</span>) '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">return</span> a+b;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">     <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span>+getSum(<span '
             'class="hljs-number">5</span>,<span '
             'class="hljs-number">6</span>));</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img alt="" class="has" height="266" '
             'src="https://img-blog.csdn.net/20180919183113385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="853"></p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">js</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-built_in">arguments</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><span style="color:#3399ea;">var  = function() {<br>\n'
             '\xa0\xa0 \xa0;<br>\n'
             '}</span></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln" style="width:717px"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-meta">&lt;!DOCTYPE '
             'html&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">html</span> <span '
             'class="hljs-attr">lang</span>=<span '
             'class="hljs-string">"en"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">meta</span> <span '
             'class="hljs-attr">charset</span>=<span '
             'class="hljs-string">"UTF-8"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">title</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-name">title</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span class="hljs-params">a, '
             'b</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-comment">/* return a '
             '+ b;*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-comment">/*arguments*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"arguments"</span> + <span '
             'class="hljs-built_in">arguments</span>.length+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">for</span> (<span '
             'class="hljs-keyword">var</span> i=<span '
             'class="hljs-number">0</span>;i&lt;<span '
             'class="hljs-built_in">arguments</span>.length;i++){</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">            <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span> + <span '
             'class="hljs-built_in">arguments</span>[i]+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span> + getSum(<span '
             'class="hljs-number">5</span>, <span '
             'class="hljs-number">6</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);<span '
             'class="hljs-comment">//undefined</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-comment">&lt;!----&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'sop=<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> (<span '
             'class="hljs-params">a</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(a)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    sop(<span class="hljs-string">"hello '
             'world"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">html</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><img alt="" class="has" height="124" '
             'src="https://img-blog.csdn.net/20180919220647662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="655"></p>\n'
             '\n'
             '<p>\xa0<strong></strong></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'age=<span '
             'class="hljs-number">15</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span>+(age&gt;=<span '
             'class="hljs-number">18</span>?<span '
             'class="hljs-string">""</span>:<span '
             'class="hljs-string">""</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>---------------</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css">2018<span '
             'class="hljs-selector-class">.12</span><span '
             'class="hljs-selector-class">.5</span> </code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><strong>ES6 let const\xa0 </strong></p>\n'
             '\n'
             '<p>let\xa0   java </p>\n'
             '\n'
             '<p>const\xa0  </p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs java"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span>   '
             'arr = <span class="hljs-keyword">new</span>  '
             'Array();</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">1</span>)</span></span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">2</span>)</span></span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr1=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr2=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">arr1=arr2     <span '
             'class="hljs-comment">//</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['js /javascript']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 10:27:36 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ggh990640782/article/details/44598097">https://blog.csdn.net/ggh990640782/article/details/44598097</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div align="center" '
             'style="font-family:STHeiti;font-size:14px;">\n'
             '<h1><br></h1>\n'
             '<div '
             'style="text-align:left;">WebViewjsalert</div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div '
             'style="text-align:left;">webView.loadUrl("javascript:alert(\'hello\')")<br></div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div style="text-align:left;"> webviewjs</div>\n'
             '</div>\n'
             '<div '
             'style="font-family:STHeiti;line-height:24px;font-size:14px;">\n'
             '<p>1 WebSettingsjavascript</p>\n'
             '<p></p><pre><code class="language-java '
             'hljs">mWebView.getSettings().&lt;span style=<span '
             'class="hljs-string">"font-family: '
             'STHeiti;"</span>&gt;setJavaScriptEnabled(<span '
             'class="hljs-keyword">true</span>);&lt;/span&gt;</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p></p>\n'
             '<p>2) documentload</p>\n'
             '<pre><code class="language-java hljs">webView.loadData(,<span '
             'class="hljs-string">"text/html"</span>,<span '
             'class="hljs-string">"UTF-8"</span>);</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p>3</p>\n'
             '<p><span>webView.loadData(,"text/html","UTF-8");</span></p>\n'
             '<p><span>webView.loadUrl("javascript:alert(\'hello\')");</span></p>\n'
             '<p> \xa01 2) 3onPageFinished</p>\n'
             '<p><span>mWebView.setWebViewClient(new '
             'MyWebViewClient());</span></p>\n'
             '<p><span>private class MyWebViewClient extends WebViewClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public void onPageFinished(WebView '
             'webView, String url) {</span></p>\n'
             '<p><span><span></span>webView.loadUrl("javascript:"+script);</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '4console/alert\n'
             '<p></p>\n'
             '<p>jsconsole.logalert</p>\n'
             '<p>2</p>\n'
             '<p><span>mWebView.setWebChromeClient(new '
             'MyWebChromeClient());</span></p>\n'
             '<p><span>private class MyWebChromeClient extends WebChromeClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean '
             'onConsoleMessage(ConsoleMessage cm) {</span></p>\n'
             '<p><span><span></span>Log.d("test", cm.message() + " -- From '
             'line "\xa0</span><span>+ cm.lineNumber() + " of '
             '"</span><span>\xa0+\n'
             ' cm.sourceId() );</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean onJsAlert(WebView view, '
             'String url, String message, JsResult result) {</span></p>\n'
             '<p><span><span></span>Toast.makeText(mContext, message, '
             'Toast.LENGTH_SHORT).show();</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '<div><br></div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Android webviewjs '
           'webView.loadUrl("javascript:alert(\'hello\')")']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 10:27:56 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 1 pages/min), scraped 8 items (at 3 items/min)
2019-11-01 10:29:10 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 5 pages/min), scraped 8 items (at 0 items/min)
2019-11-01 10:29:47 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:29:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 16713029,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 29, 47, 270718),
 'item_scraped_count': 15,
 'log_count/ERROR': 7,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 2, 20, 52, 423905)}
2019-11-01 10:29:47 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:34:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:34:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:34:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:34:46 [scrapy.extensions.telnet] INFO: Telnet Password: 76e7598f02995e8f
2019-11-01 10:34:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:34:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:34:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:34:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:34:47 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:34:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:34:47 [js_spider] INFO: Spider opened: js_spider
2019-11-01 10:34:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:37:17 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:37:17 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:38:36 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 5 items (at 5 items/min)
2019-11-01 10:38:52 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 1 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 10:38:53 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/weixin_42323802/article/details/82776451">https://blog.csdn.net/weixin_42323802/article/details/82776451</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p><strong>js '
             '/javascrip</strong>t ----&gt;</p>\n'
             '\n'
             '<p><strong>ECMAscript</strong> () DOM ,BOM = browser '
             'object modle</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">&lt;script '
             'type="text/javascript"&gt;&lt;/script&gt;</span> '
             '<strong>HTML</strong><strong>HTML</strong></p>\n'
             '\n'
             '<p><strong>js</strong></p>\n'
             '\n'
             '<p>jsvar js<span '
             'style="color:#86ca5e;"><strong></strong></span>2var,varvar '
             'i=0; </p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">function () {<br>\n'
             '\xa0 \xa0 ;<br>\n'
             '\xa0 \xa0 [return ];<br>\n'
             '}</span></p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span '
             'class="hljs-params">a,b</span>) '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">return</span> a+b;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">     <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span>+getSum(<span '
             'class="hljs-number">5</span>,<span '
             'class="hljs-number">6</span>));</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img alt="" class="has" height="266" '
             'src="https://img-blog.csdn.net/20180919183113385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="853"></p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">js</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-built_in">arguments</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><span style="color:#3399ea;">var  = function() {<br>\n'
             '\xa0\xa0 \xa0;<br>\n'
             '}</span></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln" style="width:717px"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-meta">&lt;!DOCTYPE '
             'html&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">html</span> <span '
             'class="hljs-attr">lang</span>=<span '
             'class="hljs-string">"en"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">meta</span> <span '
             'class="hljs-attr">charset</span>=<span '
             'class="hljs-string">"UTF-8"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">title</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-name">title</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span class="hljs-params">a, '
             'b</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-comment">/* return a '
             '+ b;*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-comment">/*arguments*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"arguments"</span> + <span '
             'class="hljs-built_in">arguments</span>.length+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">for</span> (<span '
             'class="hljs-keyword">var</span> i=<span '
             'class="hljs-number">0</span>;i&lt;<span '
             'class="hljs-built_in">arguments</span>.length;i++){</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">            <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span> + <span '
             'class="hljs-built_in">arguments</span>[i]+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span> + getSum(<span '
             'class="hljs-number">5</span>, <span '
             'class="hljs-number">6</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);<span '
             'class="hljs-comment">//undefined</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-comment">&lt;!----&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'sop=<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> (<span '
             'class="hljs-params">a</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(a)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    sop(<span class="hljs-string">"hello '
             'world"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">html</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><img alt="" class="has" height="124" '
             'src="https://img-blog.csdn.net/20180919220647662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="655"></p>\n'
             '\n'
             '<p>\xa0<strong></strong></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'age=<span '
             'class="hljs-number">15</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span>+(age&gt;=<span '
             'class="hljs-number">18</span>?<span '
             'class="hljs-string">""</span>:<span '
             'class="hljs-string">""</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>---------------</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css">2018<span '
             'class="hljs-selector-class">.12</span><span '
             'class="hljs-selector-class">.5</span> </code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><strong>ES6 let const\xa0 </strong></p>\n'
             '\n'
             '<p>let\xa0   java </p>\n'
             '\n'
             '<p>const\xa0  </p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs java"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span>   '
             'arr = <span class="hljs-keyword">new</span>  '
             'Array();</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">1</span>)</span></span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">2</span>)</span></span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr1=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr2=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">arr1=arr2     <span '
             'class="hljs-comment">//</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['js /javascript']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 10:38:54 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ggh990640782/article/details/44598097">https://blog.csdn.net/ggh990640782/article/details/44598097</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div align="center" '
             'style="font-family:STHeiti;font-size:14px;">\n'
             '<h1><br></h1>\n'
             '<div '
             'style="text-align:left;">WebViewjsalert</div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div '
             'style="text-align:left;">webView.loadUrl("javascript:alert(\'hello\')")<br></div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div style="text-align:left;"> webviewjs</div>\n'
             '</div>\n'
             '<div '
             'style="font-family:STHeiti;line-height:24px;font-size:14px;">\n'
             '<p>1 WebSettingsjavascript</p>\n'
             '<p></p><pre><code class="language-java '
             'hljs">mWebView.getSettings().&lt;span style=<span '
             'class="hljs-string">"font-family: '
             'STHeiti;"</span>&gt;setJavaScriptEnabled(<span '
             'class="hljs-keyword">true</span>);&lt;/span&gt;</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p></p>\n'
             '<p>2) documentload</p>\n'
             '<pre><code class="language-java hljs">webView.loadData(,<span '
             'class="hljs-string">"text/html"</span>,<span '
             'class="hljs-string">"UTF-8"</span>);</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p>3</p>\n'
             '<p><span>webView.loadData(,"text/html","UTF-8");</span></p>\n'
             '<p><span>webView.loadUrl("javascript:alert(\'hello\')");</span></p>\n'
             '<p> \xa01 2) 3onPageFinished</p>\n'
             '<p><span>mWebView.setWebViewClient(new '
             'MyWebViewClient());</span></p>\n'
             '<p><span>private class MyWebViewClient extends WebViewClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public void onPageFinished(WebView '
             'webView, String url) {</span></p>\n'
             '<p><span><span></span>webView.loadUrl("javascript:"+script);</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '4console/alert\n'
             '<p></p>\n'
             '<p>jsconsole.logalert</p>\n'
             '<p>2</p>\n'
             '<p><span>mWebView.setWebChromeClient(new '
             'MyWebChromeClient());</span></p>\n'
             '<p><span>private class MyWebChromeClient extends WebChromeClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean '
             'onConsoleMessage(ConsoleMessage cm) {</span></p>\n'
             '<p><span><span></span>Log.d("test", cm.message() + " -- From '
             'line "\xa0</span><span>+ cm.lineNumber() + " of '
             '"</span><span>\xa0+\n'
             ' cm.sourceId() );</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean onJsAlert(WebView view, '
             'String url, String message, JsResult result) {</span></p>\n'
             '<p><span><span></span>Toast.makeText(mContext, message, '
             'Toast.LENGTH_SHORT).show();</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '<div><br></div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Android webviewjs '
           'webView.loadUrl("javascript:alert(\'hello\')")']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 10:40:33 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 6 pages/min), scraped 9 items (at 3 items/min)
2019-11-01 10:41:47 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 15 items (at 6 items/min)
2019-11-01 10:42:03 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 1 pages/min), scraped 15 items (at 0 items/min)
2019-11-01 10:42:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:42:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21516468,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 42, 22, 699911),
 'item_scraped_count': 20,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 2, 34, 47, 525996)}
2019-11-01 10:42:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:44:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:44:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:44:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:44:52 [scrapy.extensions.telnet] INFO: Telnet Password: 3cb0d1f6c4bb023b
2019-11-01 10:44:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:44:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:44:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:44:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:44:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:44:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:44:53 [html_spider] INFO: Spider opened: html_spider
2019-11-01 10:44:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:46:38 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:46:39 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 10:48:10 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 5 pages/min), scraped 5 items (at 5 items/min)
2019-11-01 10:49:57 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 6 pages/min), scraped 11 items (at 6 items/min)
2019-11-01 10:52:35 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 7 pages/min), scraped 17 items (at 6 items/min)
2019-11-01 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 23 items (at 6 items/min)
2019-11-01 10:53:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 10:53:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 24304916,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 2, 53, 23, 762150),
 'item_scraped_count': 25,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 11, 1, 2, 44, 53, 766935)}
2019-11-01 10:53:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 10:53:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 10:53:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 10:53:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:56 [scrapy.extensions.telnet] INFO: Telnet Password: c58ec5c701ce07c8
2019-11-01 10:53:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [C_spider] INFO: Spider opened: C_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 0611796fa8a9673f
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: ae10cd68eed4417c
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 9c90283f5190be18
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 3989499d95d23f2d
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 584e2f5e52b4e41b
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [html_spider] INFO: Spider opened: html_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 01bcffe47f2592b3
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [java_spider] INFO: Spider opened: java_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 948f5be4d8f3ccee
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [js_spider] INFO: Spider opened: js_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 10:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet Password: 69c9d8ec88df13f5
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 10:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 10:53:58 [scrapy.core.engine] INFO: Spider opened
2019-11-01 10:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:53:58 [python_spider] INFO: Spider opened: python_spider
2019-11-01 10:53:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 10:59:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:12:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 11:12:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 11:12:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:12:53 [scrapy.extensions.telnet] INFO: Telnet Password: f1b66f4b35b558c6
2019-11-01 11:12:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:12:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:12:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:12:57 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:12:57 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:12:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:12:58 [html_spider] INFO: Spider opened: html_spider
2019-11-01 11:12:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 11:13:10 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC771C160>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:11 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7DF8D68>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:12 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E15358>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:14 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E4BF60>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E690F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:17 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E691D0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=2&q=html&t=&viparticle=&domain=&o=&s=&u=&l=>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E155F8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E155F8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:13:19 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E414A8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:20 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E419E8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:21 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E41F28>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:23 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E3AEF0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:24 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E3A320>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:25 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E3A470>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:27 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E32748>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E4B160>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:29 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E4B9E8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:31 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F02390>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F024E0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F025C0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:35 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F023C8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:36 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F02D30>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:37 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F02E10>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:39 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F16630>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:40 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F16780>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F02DA0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:43 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F16668>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:44 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F16F28>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F2C080>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:47 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F167F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F2C358>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F2C8D0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:51 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3D0B8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3D208>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3D2E8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:55 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3D0F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:56 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3DB38>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:57 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3DC18>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:13:59 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3DA20>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56438>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:01 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F564A8>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:03 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56C50>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:04 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56DA0>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:05 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56E80>: Failed to establish a new connection: [WinError 10061] ',)': /session/c7e26f4e269eff60d8a4cea5efaf28b3/url
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/u011046042/article/details/73850368>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E69390>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E69390>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/weixin_42138029/article/details/80361872>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E41B00>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E41B00>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/u010008539/article/details/52187885>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E32BA8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E32BA8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/sipallan/article/details/51049925>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E4B4A8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E4B4A8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/lb812913059/article/details/68070676>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC7E4B080>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC7E4B080>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/ymjring/article/details/7801432>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F02FD0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F02FD0>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/weixin_43249821/article/details/85276190>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC775B898>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC775B898>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/twh6666/article/details/79489024>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F2C208>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F2C208>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/qq_36545656/article/details/53330417>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F2CA58>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F2CA58>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/arvin0/article/details/56839242>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F3D4A8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3D4A8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/Skywalker10/article/details/80446189>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F3DDD8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F3DDD8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/laobai1015/article/details/51354247>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F56668>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56668>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/qq_16371909/article/details/77863283>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002BFC8F56F98>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55764): Max retries exceeded with url: /session/c7e26f4e269eff60d8a4cea5efaf28b3/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002BFC8F56F98>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:14:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 11:14:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 14,
 'downloader/exception_type_count/urllib3.exceptions.MaxRetryError': 14,
 'downloader/response_bytes': 132691,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 3, 14, 6, 468795),
 'log_count/ERROR': 14,
 'log_count/INFO': 11,
 'log_count/WARNING': 42,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 15,
 'scheduler/dequeued/memory': 15,
 'scheduler/enqueued': 15,
 'scheduler/enqueued/memory': 15,
 'start_time': datetime.datetime(2019, 11, 1, 3, 12, 58, 6910)}
2019-11-01 11:14:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 11:15:07 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 11:15:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 11:15:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:15:07 [scrapy.extensions.telnet] INFO: Telnet Password: d368a4890e34210a
2019-11-01 11:15:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:15:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:15:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:15:11 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:15:11 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:15:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:15:11 [html_spider] INFO: Spider opened: html_spider
2019-11-01 11:15:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 11:15:24 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B521C160>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:25 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B58F8D68>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:26 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915358>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B594BF60>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:29 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B59690F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:30 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B59691D0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=2&q=html&t=&viparticle=&domain=&o=&s=&u=&l=>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B59155F8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B59155F8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:15:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5969EF0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5983080>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:34 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B59830B8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:36 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8128>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:37 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8278>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:38 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8358>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:40 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8160>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:41 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8BA8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:42 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8C88>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:44 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0F4A8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:45 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8F60>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:46 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8630>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:48 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0F4E0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0FDA0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0FE80>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A255C0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A25710>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:54 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A257F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:56 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0F8D0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:57 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A255F8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:15:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3D0F0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3D048>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:01 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3D9B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:02 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3DA90>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:04 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A54198>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:05 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A542E8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:06 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A543C8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/u011046042/article/details/73850368>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B5969390>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5969390>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:08 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915668>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:09 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915F28>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:10 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915D30>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:12 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915940>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:13 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B594B6D8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:14 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B594BE80>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:16 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B594B9B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:17 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915EB8>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:18 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3DD68>: Failed to establish a new connection: [WinError 10061] ',)': /session/d800bb0157be701363585cd6ba76249b/url
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/lb812913059/article/details/68070676>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B59833C8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B59833C8>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/ymjring/article/details/7801432>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B69F8518>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8518>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/weixin_43249821/article/details/85276190>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B69F8E48>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B69F8E48>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/twh6666/article/details/79489024>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A0F630>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0F630>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/qq_36545656/article/details/53330417>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A0FF98>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A0FF98>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/arvin0/article/details/56839242>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A259B0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A259B0>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/Skywalker10/article/details/80446189>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A3D240>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3D240>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/laobai1015/article/details/51354247>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A3DC50>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A3DC50>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/qq_16371909/article/details/77863283>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B6A54588>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B6A54588>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/weixin_42138029/article/details/80361872>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B5915E10>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B5915E10>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/u010008539/article/details/52187885>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B594B198>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B594B198>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/sipallan/article/details/51049925>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000162B58F8710>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 85, in process_request
    self.driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=55886): Max retries exceeded with url: /session/d800bb0157be701363585cd6ba76249b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000162B58F8710>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 11:16:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 11:16:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 14,
 'downloader/exception_type_count/urllib3.exceptions.MaxRetryError': 14,
 'downloader/response_bytes': 132804,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 3, 16, 19, 910486),
 'log_count/ERROR': 14,
 'log_count/INFO': 11,
 'log_count/WARNING': 42,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 15,
 'scheduler/dequeued/memory': 15,
 'scheduler/enqueued': 15,
 'scheduler/enqueued/memory': 15,
 'start_time': datetime.datetime(2019, 11, 1, 3, 15, 11, 965180)}
2019-11-01 11:16:19 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 11:22:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 11:22:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 11:22:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:22:16 [scrapy.extensions.telnet] INFO: Telnet Password: 1807d47a9fcada20
2019-11-01 11:22:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:22:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:22:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:22:20 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:22:20 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:22:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:22:21 [html_spider] INFO: Spider opened: html_spider
2019-11-01 11:22:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 11:24:31 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:24:32 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 11:26:01 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 6 pages/min), scraped 5 items (at 5 items/min)
2019-11-01 11:27:09 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 5 pages/min), scraped 11 items (at 6 items/min)
2019-11-01 11:29:01 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 5 pages/min), scraped 16 items (at 5 items/min)
2019-11-01 11:29:23 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 1 pages/min), scraped 21 items (at 5 items/min)
2019-11-01 11:30:14 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 11:30:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 24735002,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 3, 30, 14, 453413),
 'item_scraped_count': 25,
 'log_count/INFO': 15,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 11, 1, 3, 22, 21, 12270)}
2019-11-01 11:30:14 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 11:30:33 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 11:30:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 11:30:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:33 [scrapy.extensions.telnet] INFO: Telnet Password: 63ff81cb1ed86c84
2019-11-01 11:30:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [C_spider] INFO: Spider opened: C_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: 4e49ff16b0499bd3
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: b498f3b1fa1a3f44
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: 78ce52cef702a414
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: b29dc0e74b8df1f2
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: cea7a70749107b90
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [html_spider] INFO: Spider opened: html_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: c82ae58e055b012d
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [java_spider] INFO: Spider opened: java_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: 84000815d2262b0d
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [js_spider] INFO: Spider opened: js_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 11:30:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet Password: 889eb309646f1db5
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:30:37 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:30:37 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:30:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:30:37 [python_spider] INFO: Spider opened: python_spider
2019-11-01 11:30:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:32:41 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/lb812913059/article/details/68070676>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 101, in process_request
    driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: session deleted because of page crash
from unknown error: cannot determine loading status
from tab crashed
  (Session info: headless chrome=76.0.3809.100)

2019-11-01 11:38:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 11:38:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 11:38:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:47 [scrapy.extensions.telnet] INFO: Telnet Password: 98bcd6159c8fb894
2019-11-01 11:38:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [C_spider] INFO: Spider opened: C_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: ddec6fe484f6cc78
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: 70058d7138b253cd
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: 8765073fa553c249
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: cbb6b85635ef2e8c
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: 3d80c153486c0ad7
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [html_spider] INFO: Spider opened: html_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: 4fc362dde3b81bab
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [java_spider] INFO: Spider opened: java_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: a01207c579bb333b
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [js_spider] INFO: Spider opened: js_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 11:38:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet Password: e3ea73203e458a38
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 11:38:48 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 11:38:48 [scrapy.core.engine] INFO: Spider opened
2019-11-01 11:38:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:38:48 [python_spider] INFO: Spider opened: python_spider
2019-11-01 11:38:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:41:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:43:50 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:55:30 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 11:57:18 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 2 items (at 2 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:01:13 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 6 items (at 4 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 5 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 12:07:23 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 12:14:18 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/machitaoX/article/details/85054039">https://blog.csdn.net/machitaoX/article/details/85054039</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2><a '
             'name="t0"></a><a id="1_0"></a>1</h2>\n'
             '<p>python 3<br>\n'
             '&gt;&gt;&gt; print(hello python inter)</p>\n'
             '<h2><a name="t1"></a><a id="2python_4"></a>2python</h2>\n'
             '<p>1geanyrootapt-get install geany<br>\n'
             '2pythonpython commands : compilepython 3<br>\n'
             'execute python 3</p>\n'
             '<h2><a name="t2"></a><a id="3_8"></a>3</h2>\n'
             '<p>Linux python ***.py</p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python:    execute']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 12:16:36 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 12:16:56 [scrapy.core.scraper] ERROR: Error processing {'Atype': '.net',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/hello_word2/article/details/83311880">https://blog.csdn.net/hello_word2/article/details/83311880</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p>MyCat</p>\n'
             '\n'
             '<p>: : java.net.MalformedURLException: Local host name '
             'unknown: java.net.UnknownHostException: node04:</p>\n'
             '\n'
             '<p> node04</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">1.network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">vi '
             '/etc/sysconfig/network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> '
             'HOSTNAME=XXXX</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">2. HOSTS</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> vi /etc/hosts</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> 127.0.0.1  localhost.localdomain localhost '
             'XXXX</div></div></li></ol></code><div class="hljs-button '
             'signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p> rebooot.</p>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['java.net.MalformedURLException: Local host name unknown: '
           'java.net.UnknownHostException']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:17:01 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'erlang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/abv123456789/article/details/40782861">https://blog.csdn.net/abv123456789/article/details/40782861</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<div>\ufeff\ufeff</div><p><strong><a '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html" '
             'rel="nofollow" '
             'data-token="0a9565600d8ed46d87646a52e78e376f">http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html</a></strong></p><p><strong>On '
             'Preserving Term Sharing in the Erlang Virtual '
             'Machine<br></strong>:\xa0<a '
             'href="http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf" '
             'rel="nofollow" '
             'data-token="d8d7e52be5b17e4b0bd99faa342ce30f"><span '
             'style="text-decoration:underline;">http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf</span></a>\xa0'
             '<br>:In this paper we describe our experiences and argue '
             'through examples why attening terms during copying is not a '
             'good idea for<br> a language like Erlang. More importantly, we '
             'propose a sharing\xa0preserving copying mechanism for Erlang/OTP '
             'and describe a pub-<br>licly available complete implementation '
             'of this mechanism.\xa0<br><br> \xa0 \xa0Term Sharing \xa0'
             ',"Efficiency Guide User\'s Guide"4.2"Constructing '
             'binaries"[ <a '
             'href="http://www.erlang.org/doc/efficiency_guide/binaryhandling.html" '
             'rel="nofollow" '
             'data-token="b5ea8aa3ec0e5ebfa54a7e3fac04a6b8"><span '
             'style="text-decoration:underline;"></span></a> ]  8.2 '
             '"Loss of sharing"\xa0[<a '
             'href="http://www.erlang.org/doc/efficiency_guide/processes.html" '
             'rel="nofollow" '
             'data-token="31199e586e502dc4b2759368632240d0"><span '
             'style="text-decoration:underline;"></span></a>](Erlang,,).Binary,Term '
             'Sharing .Guide:ETS. '
             ':</p><blockquote><p>\xa0 \xa0<strong>Loss of '
             'sharing</strong><br> \xa0\xa0<br> \xa0 Shared sub-terms are not '
             'preserved when a term is sent to\xa0another process, passed as '
             'the initial process arguments\xa0in the spawn call, or stored in '
             'an ETS table. That is an\xa0optimization. Most applications do '
             'not send messages with\xa0shared '
             'sub-terms.</p></blockquote><p>\xa0</p><p>\xa0 \xa0'
             ',Erlang.,flat '
             'size(erts/emulator/beam/copy.csize_object\xa0'
             '),\xa0(function copy_structin '
             'erts/emulator/beam/copy.c).<br><br>,erts_debug:size/1erts_debug:flat_size/1</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_112625"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div></td><td '
             'class="code"><div><div class="line number1 index0 alt2"><code '
             'class="csharp plain">s3(L)-&gt;</code></div><div class="line '
             'number2 index1 alt1"><code class="csharp spaces">\xa0\xa0\xa0\xa0'
             '</code><code class="csharp plain">L2=[L,L,L,L],</code></div><div '
             'class="line number3 index2 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{{erts_debug:size(L),erts_debug:flat_size(L)},</code></div><div '
             'class="line number4 index3 alt1"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{erts_debug:size(L2),erts_debug:flat_size(L2)}}</code></div><div '
             'class="line number5 index4 alt2"><code class="csharp '
             'plain">.</code></div><div class="line number6 index5 alt1">\xa0'
             '</div><div class="line number7 index6 alt2"><code class="csharp '
             'plain">9&gt; d:s3([1,2,3,4,5,6]).</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">{{12,12},{20,56}}</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'shell,spawn,,ETS.</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_461953"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div><div class="line number25 index24 '
             'alt2">25</div><div class="line number26 index25 '
             'alt1">26</div><div class="line number27 index26 '
             'alt2">27</div><div class="line number28 index27 '
             'alt1">28</div><div class="line number29 index28 '
             'alt2">29</div><div class="line number30 index29 '
             'alt1">30</div><div class="line number31 index30 '
             'alt2">31</div><div class="line number32 index31 '
             'alt1">32</div><div class="line number33 index32 '
             'alt2">33</div><div class="line number34 index33 '
             'alt1">34</div><div class="line number35 index34 '
             'alt2">35</div><div class="line number36 index35 '
             'alt1">36</div><div class="line number37 index36 '
             'alt2">37</div><div class="line number38 index37 '
             'alt1">38</div><div class="line number39 index38 '
             'alt2">39</div><div class="line number40 index39 '
             'alt1">40</div><div class="line number41 index40 '
             'alt2">41</div><div class="line number42 index41 '
             'alt1">42</div><div class="line number43 index42 '
             'alt2">43</div><div class="line number44 index43 '
             'alt1">44</div><div class="line number45 index44 '
             'alt2">45</div><div class="line number46 index45 '
             'alt1">46</div><div class="line number47 index46 '
             'alt2">47</div><div class="line number48 index47 '
             'alt1">48</div><div class="line number49 index48 '
             'alt2">49</div><div class="line number50 index49 '
             'alt1">50</div><div class="line number51 index50 '
             'alt2">51</div><div class="line number52 index51 '
             'alt1">52</div><div class="line number53 index52 '
             'alt2">53</div><div class="line number54 index53 '
             'alt1">54</div><div class="line number55 index54 '
             'alt2">55</div><div class="line number56 index55 '
             'alt1">56</div><div class="line number57 index56 '
             'alt2">57</div><div class="line number58 index57 '
             'alt1">58</div><div class="line number59 index58 '
             'alt2">59</div><div class="line number60 index59 '
             'alt1">60</div><div class="line number61 index60 '
             'alt2">61</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt; '
             'L=[1,2,3,4,5,6,7,8,9,10].</code></div><div class="line number3 '
             'index2 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">2&gt;\xa0 '
             'L2=[L,L,L,L,L,L].</code></div><div class="line number5 index4 '
             'alt2"><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number11 index10 alt2"><code class="csharp plain">3&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number12 '
             'index11 alt1"><code class="csharp plain">32</code></div><div '
             'class="line number13 index12 alt2"><code class="csharp '
             'plain">4&gt;\xa0 erts_debug:flat_size(L2).</code></div><div '
             'class="line number14 index13 alt1"><code class="csharp '
             'plain">132</code></div><div class="line number15 index14 '
             'alt2"><code class="csharp plain">5&gt;\xa0 spawn(fun () '
             '-&gt;receive Data -&gt;\xa0 io:format(</code><code class="csharp '
             'string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]) end end).</code></div><div '
             'class="line number16 index15 alt1"><code class="csharp '
             'plain">&lt;0.39.0&gt;</code></div><div class="line number17 '
             'index16 alt2"><code class="csharp plain">6&gt; v(5) ! '
             'L2.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp '
             'plain">132[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number19 index18 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number20 index19 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number21 index20 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number22 index21 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number24 index23 alt1"><code class="csharp plain">7&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number25 '
             'index24 alt2"><code class="csharp plain">32</code></div><div '
             'class="line number26 index25 alt1"><code class="csharp '
             'plain">8&gt; ets:</code><code class="csharp '
             'keyword">new</code><code class="csharp '
             'plain">(test,[named_table]).</code></div><div class="line '
             'number27 index26 alt2"><code class="csharp '
             'plain">test</code></div><div class="line number28 index27 '
             'alt1"><code class="csharp plain">9&gt; '
             'ets:insert(test,{1,L2}).</code></div><div class="line number29 '
             'index28 alt2"><code class="csharp keyword">true</code></div><div '
             'class="line number30 index29 alt1"><code class="csharp '
             'plain">10&gt;\xa0 ets:lookup(test ,1).</code></div><div '
             'class="line number31 index30 alt2"><code class="csharp '
             'plain">[{1,</code></div><div class="line number32 index31 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number33 index32 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number34 index33 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number35 index34 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number36 index35 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number37 index36 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number38 index37 alt1"><code class="csharp plain">11&gt; '
             '[{1,Data}]=v(10).</code></div><div class="line number39 index38 '
             'alt2"><code class="csharp plain">[{1,</code></div><div '
             'class="line number40 index39 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number41 index40 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number42 index41 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number43 index42 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number44 index43 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number45 index44 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number46 index45 alt1"><code class="csharp plain">12&gt; '
             'Data.</code></div><div class="line number47 index46 alt2"><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number48 index47 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number49 index48 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number50 index49 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number51 index50 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number52 index51 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number53 index52 alt2"><code class="csharp plain">13&gt;\xa0 '
             'erts_debug:size(Data).</code></div><div class="line number54 '
             'index53 alt1"><code class="csharp plain">132</code></div><div '
             'class="line number55 index54 alt2"><code class="csharp '
             'plain">14&gt; spawn(d,test,[L2]).</code></div><div class="line '
             'number56 index55 alt1"><code class="csharp '
             'plain">132&lt;0.54.0&gt;</code></div><div class="line number57 '
             'index56 alt2">\xa0</div><div class="line number58 index57 '
             'alt1"><code class="csharp spaces">\xa0</code><code class="csharp '
             'plain">test(Data)-&gt;</code></div><div class="line number59 '
             'index58 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">io:format(</code><code '
             'class="csharp string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]).</code></div><div class="line '
             'number60 index59 alt1">\xa0</div><div class="line number61 '
             'index60 alt2"><code class="csharp spaces">\xa0\xa0</code>\xa0'
             '</div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             ',,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_898436"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp '
             'plain">show_printing_may_be_bad() -&gt;</code></div><div '
             'class="line number2 index1 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp plain">F = fun (N) '
             '-&gt;</code></div><div class="line number3 index2 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">T = now(),</code></div><div class="line number4 index3 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">L = mklist(N),</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp spaces">\xa0\xa0'
             '</code><code class="csharp plain">S = '
             'erts_debug:size(L),</code></div><div class="line number6 index5 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"mklist(~w), size ~w, "</code><code class="csharp '
             'plain">, [N, S]),</code></div><div class="line number7 index6 '
             'alt2"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"is ~P, "</code><code class="csharp plain">, [L, 2]), '
             '%%% BAD !!!</code></div><div class="line number8 index7 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">D = timer:now_diff(now(), '
             'T),</code></div><div class="line number9 index8 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">io:format(</code><code class="csharp string">"in ~.3f '
             'sec.~n"</code><code class="csharp plain">, '
             '[D/1000000])</code></div><div class="line number10 index9 '
             'alt1"><code class="csharp spaces">\xa0\xa0\xa0</code><code '
             'class="csharp plain">end,</code></div><div class="line number11 '
             'index10 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">lists:</code><code '
             'class="csharp keyword">foreach</code><code class="csharp '
             'plain">(F, [10, 20, 22, 24, 26, 28, 30]).</code></div><div '
             'class="line number12 index11 alt1">\xa0</div><div class="line '
             'number13 index12 alt2"><code class="csharp plain">mklist(0) '
             '-&gt; 0;</code></div><div class="line number14 index13 '
             'alt1"><code class="csharp plain">mklist(M) -&gt; X = '
             'mklist(M-1), [X, '
             'X].</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'io:format("is ~P, ", [L, 2]), %%% BAD '
             '!!!,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_643843"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number3 index2 alt2"><code class="csharp plain">mklist(10), size '
             '40, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.001 sec.</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">mklist(20), size '
             '80, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp plain">mklist(22), size '
             '88, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp plain">mklist(24), size '
             '96, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp plain">mklist(26), size '
             '104, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp plain">mklist(28), size '
             '112, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp plain">mklist(30), size '
             '120, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">ok</code></div><div class="line number11 index10 '
             'alt2">\xa0</div><div class="line number12 index11 alt1">\xa0'
             '</div><div class="line number13 index12 alt2"><code '
             'class="csharp plain">Eshell V6.0\xa0 (abort with '
             '^G)</code></div><div class="line number14 index13 alt1"><code '
             'class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number15 index14 alt2"><code class="csharp plain">mklist(10), '
             'size 40, </code><code class="csharp keyword">is</code> <code '
             'class="csharp plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.001 '
             'sec.</code></div><div class="line number16 index15 alt1"><code '
             'class="csharp plain">mklist(20), size 80, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.110 '
             'sec.</code></div><div class="line number17 index16 alt2"><code '
             'class="csharp plain">mklist(22), size 88, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.421 '
             'sec.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp plain">mklist(24), size 96, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">43.105 '
             'sec.</code></div><div class="line number19 index18 alt2"><code '
             'class="csharp plain">mklist(26), size 104, </code></div><div '
             'class="line number20 index19 alt1"><code class="csharp '
             'plain">Crash dump was written to: '
             'erl_crash.dump</code></div><div class="line number21 index20 '
             'alt2"><code class="csharp plain">eheap_alloc: Cannot allocate '
             '3280272216 bytes of memory (of type </code><code class="csharp '
             'string">"heap"</code><code class="csharp '
             'plain">).</code></div><div class="line number22 index21 '
             'alt1"><code class="csharp plain">rlwrap: warning: erl killed '
             '</code><code class="csharp keyword">by</code> <code '
             'class="csharp plain">SIGABRT.</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp plain">rlwrap has not '
             'crashed, but </code><code class="csharp keyword">for</code> '
             '<code class="csharp plain">transparency,</code></div><div '
             'class="line number24 index23 alt1"><code class="csharp plain">it '
             'will now kill itself (without dumping core)with the same '
             'signal</code></div></div></td></tr></tbody></table></div></div></div></div><p>\xa0 \xa0'
             ',.<br><br> \xa0 \xa0'
             '?"Loss of '
             'sharing",()?io:format( [Erlang '
             '0041] io:format [<a '
             'href="http://www.cnblogs.com/me-sa/archive/2012/02/26/erlang0041.html" '
             'rel="nofollow" '
             'data-token="32236b65bc756f87d9c77d1a7490fb7a"><span '
             'style="text-decoration:underline;"></span></a>]),Erlang/OTPI/OI/O '
             'ServerI/O.io:formatI/O io request,IO '
             'Server.L"\xa0'
             '[[...]|...]";<br><br> \xa0 \xa0'
             ',releaseio:format;\xa0'
             '</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['[Erlang]Term sharing in Erlang/OTP ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\erlang\\[Erlang]Term sharing in Erlang/OTP \\[Erlang]Term sharing in Erlang/OTP .html'
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 7 items (at 1 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 7 items (at 1 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 8 items (at 2 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 12:18:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-01 12:18:41 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 12:18:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:18:54 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C++\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 12:18:59 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:22:33 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/weixin_42323802/article/details/82776451">https://blog.csdn.net/weixin_42323802/article/details/82776451</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p><strong>js '
             '/javascrip</strong>t ----&gt;</p>\n'
             '\n'
             '<p><strong>ECMAscript</strong> () DOM ,BOM = browser '
             'object modle</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">&lt;script '
             'type="text/javascript"&gt;&lt;/script&gt;</span> '
             '<strong>HTML</strong><strong>HTML</strong></p>\n'
             '\n'
             '<p><strong>js</strong></p>\n'
             '\n'
             '<p>jsvar js<span '
             'style="color:#86ca5e;"><strong></strong></span>2var,varvar '
             'i=0; </p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">function () {<br>\n'
             '\xa0 \xa0 ;<br>\n'
             '\xa0 \xa0 [return ];<br>\n'
             '}</span></p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span '
             'class="hljs-params">a,b</span>) '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">return</span> a+b;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">     <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span>+getSum(<span '
             'class="hljs-number">5</span>,<span '
             'class="hljs-number">6</span>));</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img alt="" class="has" height="266" '
             'src="https://img-blog.csdn.net/20180919183113385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="853"></p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">js</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-built_in">arguments</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><span style="color:#3399ea;">var  = function() {<br>\n'
             '\xa0\xa0 \xa0;<br>\n'
             '}</span></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln" style="width:717px"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-meta">&lt;!DOCTYPE '
             'html&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">html</span> <span '
             'class="hljs-attr">lang</span>=<span '
             'class="hljs-string">"en"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">meta</span> <span '
             'class="hljs-attr">charset</span>=<span '
             'class="hljs-string">"UTF-8"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">title</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-name">title</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span class="hljs-params">a, '
             'b</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-comment">/* return a '
             '+ b;*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-comment">/*arguments*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"arguments"</span> + <span '
             'class="hljs-built_in">arguments</span>.length+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">for</span> (<span '
             'class="hljs-keyword">var</span> i=<span '
             'class="hljs-number">0</span>;i&lt;<span '
             'class="hljs-built_in">arguments</span>.length;i++){</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">            <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span> + <span '
             'class="hljs-built_in">arguments</span>[i]+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span> + getSum(<span '
             'class="hljs-number">5</span>, <span '
             'class="hljs-number">6</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);<span '
             'class="hljs-comment">//undefined</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-comment">&lt;!----&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'sop=<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> (<span '
             'class="hljs-params">a</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(a)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    sop(<span class="hljs-string">"hello '
             'world"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">html</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><img alt="" class="has" height="124" '
             'src="https://img-blog.csdn.net/20180919220647662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="655"></p>\n'
             '\n'
             '<p>\xa0<strong></strong></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'age=<span '
             'class="hljs-number">15</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span>+(age&gt;=<span '
             'class="hljs-number">18</span>?<span '
             'class="hljs-string">""</span>:<span '
             'class="hljs-string">""</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>---------------</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css">2018<span '
             'class="hljs-selector-class">.12</span><span '
             'class="hljs-selector-class">.5</span> </code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><strong>ES6 let const\xa0 </strong></p>\n'
             '\n'
             '<p>let\xa0   java </p>\n'
             '\n'
             '<p>const\xa0  </p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs java"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span>   '
             'arr = <span class="hljs-keyword">new</span>  '
             'Array();</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">1</span>)</span></span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">2</span>)</span></span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr1=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr2=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">arr1=arr2     <span '
             'class="hljs-comment">//</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['js /javascript']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:22:35 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ggh990640782/article/details/44598097">https://blog.csdn.net/ggh990640782/article/details/44598097</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div align="center" '
             'style="font-family:STHeiti;font-size:14px;">\n'
             '<h1><br></h1>\n'
             '<div '
             'style="text-align:left;">WebViewjsalert</div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div '
             'style="text-align:left;">webView.loadUrl("javascript:alert(\'hello\')")<br></div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div style="text-align:left;"> webviewjs</div>\n'
             '</div>\n'
             '<div '
             'style="font-family:STHeiti;line-height:24px;font-size:14px;">\n'
             '<p>1 WebSettingsjavascript</p>\n'
             '<p></p><pre><code class="language-java '
             'hljs">mWebView.getSettings().&lt;span style=<span '
             'class="hljs-string">"font-family: '
             'STHeiti;"</span>&gt;setJavaScriptEnabled(<span '
             'class="hljs-keyword">true</span>);&lt;/span&gt;</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p></p>\n'
             '<p>2) documentload</p>\n'
             '<pre><code class="language-java hljs">webView.loadData(,<span '
             'class="hljs-string">"text/html"</span>,<span '
             'class="hljs-string">"UTF-8"</span>);</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p>3</p>\n'
             '<p><span>webView.loadData(,"text/html","UTF-8");</span></p>\n'
             '<p><span>webView.loadUrl("javascript:alert(\'hello\')");</span></p>\n'
             '<p> \xa01 2) 3onPageFinished</p>\n'
             '<p><span>mWebView.setWebViewClient(new '
             'MyWebViewClient());</span></p>\n'
             '<p><span>private class MyWebViewClient extends WebViewClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public void onPageFinished(WebView '
             'webView, String url) {</span></p>\n'
             '<p><span><span></span>webView.loadUrl("javascript:"+script);</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '4console/alert\n'
             '<p></p>\n'
             '<p>jsconsole.logalert</p>\n'
             '<p>2</p>\n'
             '<p><span>mWebView.setWebChromeClient(new '
             'MyWebChromeClient());</span></p>\n'
             '<p><span>private class MyWebChromeClient extends WebChromeClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean '
             'onConsoleMessage(ConsoleMessage cm) {</span></p>\n'
             '<p><span><span></span>Log.d("test", cm.message() + " -- From '
             'line "\xa0</span><span>+ cm.lineNumber() + " of '
             '"</span><span>\xa0+\n'
             ' cm.sourceId() );</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean onJsAlert(WebView view, '
             'String url, String message, JsResult result) {</span></p>\n'
             '<p><span><span></span>Toast.makeText(mContext, message, '
             'Toast.LENGTH_SHORT).show();</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '<div><br></div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Android webviewjs '
           'webView.loadUrl("javascript:alert(\'hello\')")']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 9 items (at 3 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 10 items (at 3 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 11 items (at 4 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 6 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 12 items (at 4 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 12 items (at 2 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 9 items (at 3 items/min)
2019-11-01 12:22:39 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 9 items (at 4 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 10 items (at 1 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 5 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 4 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 12 items (at 2 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 1 items/min)
2019-11-01 12:29:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 2 items/min)
2019-11-01 12:29:38 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'golang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/chao2016/article/details/81292210">https://blog.csdn.net/chao2016/article/details/81292210</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="1-golang"><a name="t0"></a>1. Golang</h1>\n'
             '\n'
             '<p><a href="https://golang.google.cn/dl/" rel="nofollow" '
             'data-token="1b3ca1c4968194e8253e8b40f9d493aa">https://golang.google.cn/dl/</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">wget https:<span '
             'class="hljs-comment">//dl.google.com/go/go1.10.3.darwin-amd64.tar.gz</span>\n'
             'tar <span class="hljs-attribute">-zxvf</span> go1<span '
             'class="hljs-number">.4</span><span '
             'class="hljs-built_in">.</span>linux<span '
             'class="hljs-attribute">-amd64</span><span '
             'class="hljs-built_in">.</span>tar<span '
             'class="hljs-built_in">.</span>gz <span '
             'class="hljs-attribute">-C</span> /usr/<span '
             'class="hljs-built_in">local</span> \n'
             '\n'
             'vim ~<span class="hljs-subst">/</span><span '
             'class="hljs-built_in">.</span>bash_profile\n'
             'export GOROOT<span class="hljs-subst">=</span>/usr/<span '
             'class="hljs-built_in">local</span>/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOROOT</span>/bin\n'
             'export GOPATH<span '
             'class="hljs-subst">=</span>/Users/chao/Documents/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOPATH</span>/bin<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li></ul>\n'
             '\n'
             '<p>golangGOPATHimportpackage</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs perl '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">cd <span class="hljs-variable">$GOPATH</span>\n'
             '<span class="hljs-keyword">mkdir</span> src\n'
             '<span class="hljs-keyword">mkdir</span> bin\n'
             '<span class="hljs-keyword">mkdir</span> pkg<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>\n'
             '\n'
             '<p>srcmydemotree</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs avrasm '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">tree\n'
             '.\n'
             ' bin\n'
             ' pkg\n'
             '    darwin_amd64\n'
             '        mydemo<span class="hljs-preprocessor">.a</span>\n'
             ' src\n'
             '     mydemo\n'
             '             main<span '
             'class="hljs-preprocessor">.go</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li></ul>\n'
             '\n'
             '<blockquote>\n'
             '  <p>bin :  <br>\n'
             '  pkg:  <br>\n'
             '  src : </p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="2-goland"><a name="t1"></a>2. GoLand</h1>\n'
             '\n'
             '<p>JetbrainIDEIDEAPycharm</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id=""><a name="t2"></a></h1>\n'
             '\n'
             '<p>goland</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="1importpackage"><a '
             'name="t3"></a>1importpackage</h2>\n'
             '\n'
             '<p>GOPATHsrc</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="2package"><a '
             'name="t4"></a>2package</h2>\n'
             '\n'
             '<p> <br>\n'
             'package</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="goland"><a name="t5"></a>Goland</h1>\n'
             '\n'
             '<p>goimports</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20180828072703748?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW8yMDE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>\n'
             '\n'
             '<p> <br>\n'
             'Preference -&gt; tools -&gt; File Watchers -&gt; + -&gt; '
             'goimports</p>\n'
             '\n'
             '<p>googlegoimports</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-comment">// 1. '
             'gopm$GOPATH/srcgithub.com/gpmgo</span>\n'
             'go get <span class="hljs-attribute">-v</span> github<span '
             'class="hljs-built_in">.</span>com/gpmgo/gopm\n'
             '<span class="hljs-comment">// 2. '
             'gopmgoimports$GOPATH/srcgolang.org</span>\n'
             '<span class="hljs-comment">// '
             '-g$GOPATH-v-u</span>\n'
             'gopm get <span class="hljs-attribute">-g</span> <span '
             'class="hljs-attribute">-v</span> golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports\n'
             '<span class="hljs-comment">// 3. $GOPATH/bin/</span>\n'
             'go install src/golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports<span '
             'class="hljs-subst">/</span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li></ul>\n'
             '\n'
             '<p>goland$GOPATHgoimports</p>\n'
             '\n'
             '<p>goimportsimportimport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"chao"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p>ctrl+simport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Golang: ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 6 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 13 items (at 2 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 17 items (at 6 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 4 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 1 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 12:34:21 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 15 items (at 5 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 2 pages/min), scraped 17 items (at 4 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 2 pages/min), scraped 17 items (at 1 items/min)
2019-11-01 12:37:46 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 0 pages/min), scraped 16 items (at 4 items/min)
2019-11-01 12:37:48 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 2 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 12:37:48 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 12:37:48 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/Rozol/article/details/71081854">https://blog.csdn.net/Rozol/article/details/71081854</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="python3-pythonpickle-shelve"><a name="t0"></a>Python3 '
             'Python(pickle / shelve)</h1>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<p><strong> Luzhuo ,.</strong> <br>\n'
             '<strong>: '
             '<code>http://blog.csdn.net/rozol/article/details/71081854</code></strong>  '
             '</p>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<blockquote>\n'
             '  <p>Python3.6.1 <br>\n'
             '  Less is more!</p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="pickle"><a name="t1"></a>pickle</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#coding=utf-8</span>\n'
             '<span class="hljs-comment"># pickledemo.py Pickle</span>\n'
             '<span class="hljs-comment"># Python</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> pickle\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">demo</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>)\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    strs = <span class="hljs-string">""</span>\n'
             '    num = <span class="hljs-number">123</span>\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    pickle.dump(lists, f) <span class="hljs-comment"># '
             '</span>\n'
             '    pickle.dump(strs, f)\n'
             '    pickle.dump(num, f)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    f.close()\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"rb+"</span>)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    data = pickle.load(f) <span class="hljs-comment"># '
             '</span>\n'
             '    <span class="hljs-keyword">print</span> (data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '\n'
             '    f.close()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">pickle_funs</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>) <span '
             'class="hljs-comment"># (:wb+)</span>\n'
             '\n'
             '    num = pickle.HIGHEST_PROTOCOL <span class="hljs-comment"># '
             '(4)</span>\n'
             '    num = pickle.DEFAULT_PROTOCOL <span class="hljs-comment"># '
             '(3) {3:bytes; 4:}</span>\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># dump(obj, file, protocol=None, '
             '*, fix_imports=True) // obj</span>\n'
             '    pickle.dump(lists, f)\n'
             '    <span class="hljs-comment"># dumps(obj, protocol=None, *, '
             'fix_imports=True) // objbytes</span>\n'
             '    bytes = pickle.dumps(lists)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># load(file, *, fix_imports=True, '
             'encoding="ASCII", errors="strict") // fileobj</span>\n'
             '    lists = pickle.load(f)\n'
             '    <span class="hljs-comment"># loads(bytes_object, *, '
             'fix_imports=True, encoding="ASCII", errors="strict") // '
             'bytesobj</span>\n'
             '    lists = pickle.loads(bytes)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-keyword">try</span>:\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.PicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.UnpicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> pickle.PickleError: '
             '<span class="hljs-comment"># pickling</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    demo()\n'
             '    pickle_funs()\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li><li style="color: '
             'rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, '
             '153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li '
             'style="color: rgb(153, 153, 153);">50</li><li style="color: '
             'rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, '
             '153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li '
             'style="color: rgb(153, 153, 153);">54</li><li style="color: '
             'rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, '
             '153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li '
             'style="color: rgb(153, 153, 153);">58</li><li style="color: '
             'rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, '
             '153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li '
             'style="color: rgb(153, 153, 153);">62</li><li style="color: '
             'rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, '
             '153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li '
             'style="color: rgb(153, 153, 153);">66</li><li style="color: '
             'rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, '
             '153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li '
             'style="color: rgb(153, 153, 153);">70</li><li style="color: '
             'rgb(153, 153, 153);">71</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="shelve"><a name="t2"></a>shelve</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#!/usr/bin/env python</span>\n'
             '<span class="hljs-comment"># coding=utf-8</span>\n'
             '__author__ = <span class="hljs-string">\'Luzhuo\'</span>\n'
             '__date__ = <span class="hljs-string">\'2017/5/26\'</span>\n'
             '<span class="hljs-comment"># shelve_demo.py '
             ':Python</span>\n'
             '<span class="hljs-comment"># , , '
             'picklePython</span>\n'
             '<span class="hljs-comment"># pickle, '
             '</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> shelve\n'
             '\n'
             '\n'
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">Person</span><span '
             'class="hljs-params">(object)</span>:</span>\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__init__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        self.name = <span class="hljs-string">"luzhuo"</span>\n'
             '        self.age = <span class="hljs-number">21</span>\n'
             '\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__str__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        <span class="hljs-keyword">return</span> <span '
             'class="hljs-string">"name: {}, age: {}"</span>.format(self.name, '
             'self.age)\n'
             '\n'
             'path = <span class="hljs-string">"file.txt"</span>\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_write</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> write: <span '
             'class="hljs-comment"># </span>\n'
             '        write[<span class="hljs-string">"nums"</span>] = [<span '
             'class="hljs-number">1</span>, <span '
             'class="hljs-number">2</span>, <span '
             'class="hljs-number">3</span>, <span '
             'class="hljs-number">4</span>, <span '
             'class="hljs-number">5</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        write[<span class="hljs-string">"obj"</span>] = '
             'Person()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_read</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> read:  <span '
             'class="hljs-comment"># </span>\n'
             '        nums = read.get(<span '
             'class="hljs-string">"nums"</span>)  <span class="hljs-comment"># '
             '</span>\n'
             '        print(nums)\n'
             '        clazz = read[<span class="hljs-string">"obj"</span>]\n'
             '        print(clazz)\n'
             '\n'
             '        <span class="hljs-keyword">del</span> read[<span '
             'class="hljs-string">"obj"</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        print(<span class="hljs-string">"obj"</span> <span '
             'class="hljs-keyword">in</span> read)\n'
             '\n'
             '        keys = list(read.keys())  <span class="hljs-comment"># '
             'key</span>\n'
             '        print(keys)\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_func</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># , filename:, '
             'writeback:(True,), Shelf</span>\n'
             '    <span class="hljs-comment"># shelve.open(filename, '
             "flag='c', protocol=None, writeback=False)</span>\n"
             '    d = shelve.open(path)\n'
             '\n'
             '    <span class="hljs-comment"># Shelf</span>\n'
             '    <span class="hljs-comment"># </span>\n'
             '    <span class="hljs-comment"># get(self, key, default=None) // '
             ' == data = shelf["key"]</span>\n'
             '    data = d.get(<span class="hljs-string">"key"</span>)\n'
             '    d.sync()  <span class="hljs-comment"># (,)</span>\n'
             '    d.close()  <span class="hljs-comment"># </span>\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># class shelve.Shelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8')</span>\n"
             '    <span class="hljs-comment"># class shelve.BsdDbShelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8') // "
             'Shelf</span>\n'
             '    <span class="hljs-comment"># class '
             "shelve.DbfilenameShelf(filename, flag='c', protocol=None, "
             'writeback=False) // Shelf</span>\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    shelve_write()\n'
             '    shelve_read()\n'
             '\n'
             '    <span class="hljs-comment"># shelve_func()</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li><li style="color: '
             'rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, '
             '153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li '
             'style="color: rgb(153, 153, 153);">50</li><li style="color: '
             'rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, '
             '153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li '
             'style="color: rgb(153, 153, 153);">54</li><li style="color: '
             'rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, '
             '153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li '
             'style="color: rgb(153, 153, 153);">58</li><li style="color: '
             'rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, '
             '153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li '
             'style="color: rgb(153, 153, 153);">62</li><li style="color: '
             'rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, '
             '153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li '
             'style="color: rgb(153, 153, 153);">66</li><li style="color: '
             'rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, '
             '153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li '
             'style="color: rgb(153, 153, 153);">70</li><li style="color: '
             'rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, '
             '153);">72</li><li style="color: rgb(153, 153, '
             '153);">73</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python3 Python(pickle / shelve)']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 1 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 5 pages/min), scraped 17 items (at 1 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 15 items (at 5 items/min)
2019-11-01 12:43:34 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 13 items (at 2 items/min)
2019-11-01 12:43:41 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 0 pages/min), scraped 18 items (at 6 items/min)
2019-11-01 12:46:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:46:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 14609914,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 46, 22, 308893),
 'item_scraped_count': 13,
 'log_count/ERROR': 11,
 'log_count/INFO': 118,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 17,
 'scheduler/dequeued': 17,
 'scheduler/dequeued/memory': 17,
 'scheduler/enqueued': 17,
 'scheduler/enqueued/memory': 17,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 757220)}
2019-11-01 12:46:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 4 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 21 items (at 4 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 18 items (at 1 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 0 pages/min), scraped 21 items (at 4 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 4 pages/min), scraped 18 items (at 0 items/min)
2019-11-01 12:46:35 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 1 items/min)
2019-11-01 12:47:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:47:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 18013718,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 47, 27, 669639),
 'item_scraped_count': 18,
 'log_count/ERROR': 11,
 'log_count/INFO': 179,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 528210)}
2019-11-01 12:47:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 4 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 0 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 21 items (at 0 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 0 pages/min), scraped 22 items (at 1 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 0 pages/min), scraped 22 items (at 5 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 2 pages/min), scraped 18 items (at 0 items/min)
2019-11-01 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:47:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21268715,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 47, 43, 547568),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 219,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 423186)}
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:47:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21258139,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 47, 43, 549565),
 'item_scraped_count': 21,
 'log_count/ERROR': 11,
 'log_count/INFO': 202,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 488191)}
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:47:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21143158,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 47, 43, 552553),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 215,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 457201)}
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:47:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21860528,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 47, 43, 555554),
 'item_scraped_count': 22,
 'log_count/ERROR': 11,
 'log_count/INFO': 188,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 560193)}
2019-11-01 12:47:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:48:18 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 23 items (at 1 items/min)
2019-11-01 12:48:18 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 23 items (at 5 items/min)
2019-11-01 12:48:18 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 4 items/min)
2019-11-01 12:49:28 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:49:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21563682,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 49, 28, 140571),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 164,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 728218)}
2019-11-01 12:49:28 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:50:22 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 24 items (at 1 items/min)
2019-11-01 12:50:22 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 6 pages/min), scraped 24 items (at 1 items/min)
2019-11-01 12:50:31 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 24312721,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 50, 31, 265217),
 'item_scraped_count': 25,
 'log_count/ERROR': 11,
 'log_count/INFO': 189,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 591209)}
2019-11-01 12:50:31 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:51:58 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 5 pages/min), scraped 30 items (at 6 items/min)
2019-11-01 12:54:08 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 7 pages/min), scraped 36 items (at 6 items/min)
2019-11-01 12:55:42 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 4 pages/min), scraped 42 items (at 6 items/min)
2019-11-01 12:55:59 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 1 pages/min), scraped 42 items (at 0 items/min)
2019-11-01 12:56:52 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 3 pages/min), scraped 47 items (at 5 items/min)
2019-11-01 12:56:58 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 12:56:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 48499157,
 'downloader/response_count': 54,
 'downloader/response_status_count/200': 54,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 4, 56, 58, 37141),
 'item_scraped_count': 50,
 'log_count/ERROR': 11,
 'log_count/INFO': 187,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 54,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'start_time': datetime.datetime(2019, 11, 1, 3, 38, 48, 625198)}
2019-11-01 12:56:58 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 12:58:43 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 12:58:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 12:58:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:43 [scrapy.extensions.telnet] INFO: Telnet Password: e96f8e2dd7bdd7d2
2019-11-01 12:58:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [C_spider] INFO: Spider opened: C_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: a53993eddeb0ee77
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: 685c3a54a3f3c90d
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: 11d1cdac780050ad
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: 05e86bdf4de930b7
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: cdd73c674d8b49bd
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [html_spider] INFO: Spider opened: html_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: 0199368df61fb6d7
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [java_spider] INFO: Spider opened: java_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: ecd52cc492568777
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [js_spider] INFO: Spider opened: js_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 12:58:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet Password: 050682435edfdcce
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 12:58:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 12:58:44 [scrapy.core.engine] INFO: Spider opened
2019-11-01 12:58:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 12:58:44 [python_spider] INFO: Spider opened: python_spider
2019-11-01 12:58:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:01:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:04:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:15:10 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:16:33 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:19:41 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 13:23:26 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 13:33:35 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 4 items (at 3 items/min)
2019-11-01 13:35:35 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/machitaoX/article/details/85054039">https://blog.csdn.net/machitaoX/article/details/85054039</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2><a '
             'name="t0"></a><a id="1_0"></a>1</h2>\n'
             '<p>python 3<br>\n'
             '&gt;&gt;&gt; print(hello python inter)</p>\n'
             '<h2><a name="t1"></a><a id="2python_4"></a>2python</h2>\n'
             '<p>1geanyrootapt-get install geany<br>\n'
             '2pythonpython commands : compilepython 3<br>\n'
             'execute python 3</p>\n'
             '<h2><a name="t2"></a><a id="3_8"></a>3</h2>\n'
             '<p>Linux python ***.py</p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python:    execute']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:35:41 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 13:35:43 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:36:45 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'erlang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/abv123456789/article/details/40782861">https://blog.csdn.net/abv123456789/article/details/40782861</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<div>\ufeff\ufeff</div><p><strong><a '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html" '
             'rel="nofollow" '
             'data-token="0a9565600d8ed46d87646a52e78e376f">http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html</a></strong></p><p><strong>On '
             'Preserving Term Sharing in the Erlang Virtual '
             'Machine<br></strong>:\xa0<a '
             'href="http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf" '
             'rel="nofollow" '
             'data-token="d8d7e52be5b17e4b0bd99faa342ce30f"><span '
             'style="text-decoration:underline;">http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf</span></a>\xa0'
             '<br>:In this paper we describe our experiences and argue '
             'through examples why attening terms during copying is not a '
             'good idea for<br> a language like Erlang. More importantly, we '
             'propose a sharing\xa0preserving copying mechanism for Erlang/OTP '
             'and describe a pub-<br>licly available complete implementation '
             'of this mechanism.\xa0<br><br> \xa0 \xa0Term Sharing \xa0'
             ',"Efficiency Guide User\'s Guide"4.2"Constructing '
             'binaries"[ <a '
             'href="http://www.erlang.org/doc/efficiency_guide/binaryhandling.html" '
             'rel="nofollow" '
             'data-token="b5ea8aa3ec0e5ebfa54a7e3fac04a6b8"><span '
             'style="text-decoration:underline;"></span></a> ]  8.2 '
             '"Loss of sharing"\xa0[<a '
             'href="http://www.erlang.org/doc/efficiency_guide/processes.html" '
             'rel="nofollow" '
             'data-token="31199e586e502dc4b2759368632240d0"><span '
             'style="text-decoration:underline;"></span></a>](Erlang,,).Binary,Term '
             'Sharing .Guide:ETS. '
             ':</p><blockquote><p>\xa0 \xa0<strong>Loss of '
             'sharing</strong><br> \xa0\xa0<br> \xa0 Shared sub-terms are not '
             'preserved when a term is sent to\xa0another process, passed as '
             'the initial process arguments\xa0in the spawn call, or stored in '
             'an ETS table. That is an\xa0optimization. Most applications do '
             'not send messages with\xa0shared '
             'sub-terms.</p></blockquote><p>\xa0</p><p>\xa0 \xa0'
             ',Erlang.,flat '
             'size(erts/emulator/beam/copy.csize_object\xa0'
             '),\xa0(function copy_structin '
             'erts/emulator/beam/copy.c).<br><br>,erts_debug:size/1erts_debug:flat_size/1</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_112625"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div></td><td '
             'class="code"><div><div class="line number1 index0 alt2"><code '
             'class="csharp plain">s3(L)-&gt;</code></div><div class="line '
             'number2 index1 alt1"><code class="csharp spaces">\xa0\xa0\xa0\xa0'
             '</code><code class="csharp plain">L2=[L,L,L,L],</code></div><div '
             'class="line number3 index2 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{{erts_debug:size(L),erts_debug:flat_size(L)},</code></div><div '
             'class="line number4 index3 alt1"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{erts_debug:size(L2),erts_debug:flat_size(L2)}}</code></div><div '
             'class="line number5 index4 alt2"><code class="csharp '
             'plain">.</code></div><div class="line number6 index5 alt1">\xa0'
             '</div><div class="line number7 index6 alt2"><code class="csharp '
             'plain">9&gt; d:s3([1,2,3,4,5,6]).</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">{{12,12},{20,56}}</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'shell,spawn,,ETS.</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_461953"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div><div class="line number25 index24 '
             'alt2">25</div><div class="line number26 index25 '
             'alt1">26</div><div class="line number27 index26 '
             'alt2">27</div><div class="line number28 index27 '
             'alt1">28</div><div class="line number29 index28 '
             'alt2">29</div><div class="line number30 index29 '
             'alt1">30</div><div class="line number31 index30 '
             'alt2">31</div><div class="line number32 index31 '
             'alt1">32</div><div class="line number33 index32 '
             'alt2">33</div><div class="line number34 index33 '
             'alt1">34</div><div class="line number35 index34 '
             'alt2">35</div><div class="line number36 index35 '
             'alt1">36</div><div class="line number37 index36 '
             'alt2">37</div><div class="line number38 index37 '
             'alt1">38</div><div class="line number39 index38 '
             'alt2">39</div><div class="line number40 index39 '
             'alt1">40</div><div class="line number41 index40 '
             'alt2">41</div><div class="line number42 index41 '
             'alt1">42</div><div class="line number43 index42 '
             'alt2">43</div><div class="line number44 index43 '
             'alt1">44</div><div class="line number45 index44 '
             'alt2">45</div><div class="line number46 index45 '
             'alt1">46</div><div class="line number47 index46 '
             'alt2">47</div><div class="line number48 index47 '
             'alt1">48</div><div class="line number49 index48 '
             'alt2">49</div><div class="line number50 index49 '
             'alt1">50</div><div class="line number51 index50 '
             'alt2">51</div><div class="line number52 index51 '
             'alt1">52</div><div class="line number53 index52 '
             'alt2">53</div><div class="line number54 index53 '
             'alt1">54</div><div class="line number55 index54 '
             'alt2">55</div><div class="line number56 index55 '
             'alt1">56</div><div class="line number57 index56 '
             'alt2">57</div><div class="line number58 index57 '
             'alt1">58</div><div class="line number59 index58 '
             'alt2">59</div><div class="line number60 index59 '
             'alt1">60</div><div class="line number61 index60 '
             'alt2">61</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt; '
             'L=[1,2,3,4,5,6,7,8,9,10].</code></div><div class="line number3 '
             'index2 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">2&gt;\xa0 '
             'L2=[L,L,L,L,L,L].</code></div><div class="line number5 index4 '
             'alt2"><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number11 index10 alt2"><code class="csharp plain">3&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number12 '
             'index11 alt1"><code class="csharp plain">32</code></div><div '
             'class="line number13 index12 alt2"><code class="csharp '
             'plain">4&gt;\xa0 erts_debug:flat_size(L2).</code></div><div '
             'class="line number14 index13 alt1"><code class="csharp '
             'plain">132</code></div><div class="line number15 index14 '
             'alt2"><code class="csharp plain">5&gt;\xa0 spawn(fun () '
             '-&gt;receive Data -&gt;\xa0 io:format(</code><code class="csharp '
             'string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]) end end).</code></div><div '
             'class="line number16 index15 alt1"><code class="csharp '
             'plain">&lt;0.39.0&gt;</code></div><div class="line number17 '
             'index16 alt2"><code class="csharp plain">6&gt; v(5) ! '
             'L2.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp '
             'plain">132[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number19 index18 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number20 index19 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number21 index20 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number22 index21 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number24 index23 alt1"><code class="csharp plain">7&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number25 '
             'index24 alt2"><code class="csharp plain">32</code></div><div '
             'class="line number26 index25 alt1"><code class="csharp '
             'plain">8&gt; ets:</code><code class="csharp '
             'keyword">new</code><code class="csharp '
             'plain">(test,[named_table]).</code></div><div class="line '
             'number27 index26 alt2"><code class="csharp '
             'plain">test</code></div><div class="line number28 index27 '
             'alt1"><code class="csharp plain">9&gt; '
             'ets:insert(test,{1,L2}).</code></div><div class="line number29 '
             'index28 alt2"><code class="csharp keyword">true</code></div><div '
             'class="line number30 index29 alt1"><code class="csharp '
             'plain">10&gt;\xa0 ets:lookup(test ,1).</code></div><div '
             'class="line number31 index30 alt2"><code class="csharp '
             'plain">[{1,</code></div><div class="line number32 index31 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number33 index32 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number34 index33 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number35 index34 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number36 index35 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number37 index36 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number38 index37 alt1"><code class="csharp plain">11&gt; '
             '[{1,Data}]=v(10).</code></div><div class="line number39 index38 '
             'alt2"><code class="csharp plain">[{1,</code></div><div '
             'class="line number40 index39 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number41 index40 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number42 index41 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number43 index42 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number44 index43 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number45 index44 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number46 index45 alt1"><code class="csharp plain">12&gt; '
             'Data.</code></div><div class="line number47 index46 alt2"><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number48 index47 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number49 index48 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number50 index49 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number51 index50 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number52 index51 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number53 index52 alt2"><code class="csharp plain">13&gt;\xa0 '
             'erts_debug:size(Data).</code></div><div class="line number54 '
             'index53 alt1"><code class="csharp plain">132</code></div><div '
             'class="line number55 index54 alt2"><code class="csharp '
             'plain">14&gt; spawn(d,test,[L2]).</code></div><div class="line '
             'number56 index55 alt1"><code class="csharp '
             'plain">132&lt;0.54.0&gt;</code></div><div class="line number57 '
             'index56 alt2">\xa0</div><div class="line number58 index57 '
             'alt1"><code class="csharp spaces">\xa0</code><code class="csharp '
             'plain">test(Data)-&gt;</code></div><div class="line number59 '
             'index58 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">io:format(</code><code '
             'class="csharp string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]).</code></div><div class="line '
             'number60 index59 alt1">\xa0</div><div class="line number61 '
             'index60 alt2"><code class="csharp spaces">\xa0\xa0</code>\xa0'
             '</div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             ',,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_898436"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp '
             'plain">show_printing_may_be_bad() -&gt;</code></div><div '
             'class="line number2 index1 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp plain">F = fun (N) '
             '-&gt;</code></div><div class="line number3 index2 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">T = now(),</code></div><div class="line number4 index3 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">L = mklist(N),</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp spaces">\xa0\xa0'
             '</code><code class="csharp plain">S = '
             'erts_debug:size(L),</code></div><div class="line number6 index5 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"mklist(~w), size ~w, "</code><code class="csharp '
             'plain">, [N, S]),</code></div><div class="line number7 index6 '
             'alt2"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"is ~P, "</code><code class="csharp plain">, [L, 2]), '
             '%%% BAD !!!</code></div><div class="line number8 index7 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">D = timer:now_diff(now(), '
             'T),</code></div><div class="line number9 index8 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">io:format(</code><code class="csharp string">"in ~.3f '
             'sec.~n"</code><code class="csharp plain">, '
             '[D/1000000])</code></div><div class="line number10 index9 '
             'alt1"><code class="csharp spaces">\xa0\xa0\xa0</code><code '
             'class="csharp plain">end,</code></div><div class="line number11 '
             'index10 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">lists:</code><code '
             'class="csharp keyword">foreach</code><code class="csharp '
             'plain">(F, [10, 20, 22, 24, 26, 28, 30]).</code></div><div '
             'class="line number12 index11 alt1">\xa0</div><div class="line '
             'number13 index12 alt2"><code class="csharp plain">mklist(0) '
             '-&gt; 0;</code></div><div class="line number14 index13 '
             'alt1"><code class="csharp plain">mklist(M) -&gt; X = '
             'mklist(M-1), [X, '
             'X].</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'io:format("is ~P, ", [L, 2]), %%% BAD '
             '!!!,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_643843"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number3 index2 alt2"><code class="csharp plain">mklist(10), size '
             '40, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.001 sec.</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">mklist(20), size '
             '80, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp plain">mklist(22), size '
             '88, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp plain">mklist(24), size '
             '96, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp plain">mklist(26), size '
             '104, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp plain">mklist(28), size '
             '112, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp plain">mklist(30), size '
             '120, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">ok</code></div><div class="line number11 index10 '
             'alt2">\xa0</div><div class="line number12 index11 alt1">\xa0'
             '</div><div class="line number13 index12 alt2"><code '
             'class="csharp plain">Eshell V6.0\xa0 (abort with '
             '^G)</code></div><div class="line number14 index13 alt1"><code '
             'class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number15 index14 alt2"><code class="csharp plain">mklist(10), '
             'size 40, </code><code class="csharp keyword">is</code> <code '
             'class="csharp plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.001 '
             'sec.</code></div><div class="line number16 index15 alt1"><code '
             'class="csharp plain">mklist(20), size 80, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.110 '
             'sec.</code></div><div class="line number17 index16 alt2"><code '
             'class="csharp plain">mklist(22), size 88, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.421 '
             'sec.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp plain">mklist(24), size 96, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">43.105 '
             'sec.</code></div><div class="line number19 index18 alt2"><code '
             'class="csharp plain">mklist(26), size 104, </code></div><div '
             'class="line number20 index19 alt1"><code class="csharp '
             'plain">Crash dump was written to: '
             'erl_crash.dump</code></div><div class="line number21 index20 '
             'alt2"><code class="csharp plain">eheap_alloc: Cannot allocate '
             '3280272216 bytes of memory (of type </code><code class="csharp '
             'string">"heap"</code><code class="csharp '
             'plain">).</code></div><div class="line number22 index21 '
             'alt1"><code class="csharp plain">rlwrap: warning: erl killed '
             '</code><code class="csharp keyword">by</code> <code '
             'class="csharp plain">SIGABRT.</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp plain">rlwrap has not '
             'crashed, but </code><code class="csharp keyword">for</code> '
             '<code class="csharp plain">transparency,</code></div><div '
             'class="line number24 index23 alt1"><code class="csharp plain">it '
             'will now kill itself (without dumping core)with the same '
             'signal</code></div></div></td></tr></tbody></table></div></div></div></div><p>\xa0 \xa0'
             ',.<br><br> \xa0 \xa0'
             '?"Loss of '
             'sharing",()?io:format( [Erlang '
             '0041] io:format [<a '
             'href="http://www.cnblogs.com/me-sa/archive/2012/02/26/erlang0041.html" '
             'rel="nofollow" '
             'data-token="32236b65bc756f87d9c77d1a7490fb7a"><span '
             'style="text-decoration:underline;"></span></a>]),Erlang/OTPI/OI/O '
             'ServerI/O.io:formatI/O io request,IO '
             'Server.L"\xa0'
             '[[...]|...]";<br><br> \xa0 \xa0'
             ',releaseio:format;\xa0'
             '</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['[Erlang]Term sharing in Erlang/OTP ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\erlang\\[Erlang]Term sharing in Erlang/OTP \\[Erlang]Term sharing in Erlang/OTP .html'
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 9 items (at 3 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 13:36:45 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 5 items (at 1 items/min)
2019-11-01 13:38:46 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C++\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 13:38:48 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:41:01 [scrapy.core.scraper] ERROR: Error processing {'Atype': '.net',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/hello_word2/article/details/83311880">https://blog.csdn.net/hello_word2/article/details/83311880</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p>MyCat</p>\n'
             '\n'
             '<p>: : java.net.MalformedURLException: Local host name '
             'unknown: java.net.UnknownHostException: node04:</p>\n'
             '\n'
             '<p> node04</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">1.network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">vi '
             '/etc/sysconfig/network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> '
             'HOSTNAME=XXXX</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">2. HOSTS</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> vi /etc/hosts</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> 127.0.0.1  localhost.localdomain localhost '
             'XXXX</div></div></li></ol></code><div class="hljs-button '
             'signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p> rebooot.</p>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['java.net.MalformedURLException: Local host name unknown: '
           'java.net.UnknownHostException']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 10 items (at 1 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 12 items (at 6 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 12 items (at 6 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 9 items (at 4 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 13:41:06 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-01 13:41:06 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/weixin_42323802/article/details/82776451">https://blog.csdn.net/weixin_42323802/article/details/82776451</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p><strong>js '
             '/javascrip</strong>t ----&gt;</p>\n'
             '\n'
             '<p><strong>ECMAscript</strong> () DOM ,BOM = browser '
             'object modle</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">&lt;script '
             'type="text/javascript"&gt;&lt;/script&gt;</span> '
             '<strong>HTML</strong><strong>HTML</strong></p>\n'
             '\n'
             '<p><strong>js</strong></p>\n'
             '\n'
             '<p>jsvar js<span '
             'style="color:#86ca5e;"><strong></strong></span>2var,varvar '
             'i=0; </p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">function () {<br>\n'
             '\xa0 \xa0 ;<br>\n'
             '\xa0 \xa0 [return ];<br>\n'
             '}</span></p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span '
             'class="hljs-params">a,b</span>) '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">return</span> a+b;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">     <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span>+getSum(<span '
             'class="hljs-number">5</span>,<span '
             'class="hljs-number">6</span>));</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img alt="" class="has" height="266" '
             'src="https://img-blog.csdn.net/20180919183113385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="853"></p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">js</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-built_in">arguments</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><span style="color:#3399ea;">var  = function() {<br>\n'
             '\xa0\xa0 \xa0;<br>\n'
             '}</span></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln" style="width:717px"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-meta">&lt;!DOCTYPE '
             'html&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">html</span> <span '
             'class="hljs-attr">lang</span>=<span '
             'class="hljs-string">"en"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">meta</span> <span '
             'class="hljs-attr">charset</span>=<span '
             'class="hljs-string">"UTF-8"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">title</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-name">title</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span class="hljs-params">a, '
             'b</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-comment">/* return a '
             '+ b;*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-comment">/*arguments*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"arguments"</span> + <span '
             'class="hljs-built_in">arguments</span>.length+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">for</span> (<span '
             'class="hljs-keyword">var</span> i=<span '
             'class="hljs-number">0</span>;i&lt;<span '
             'class="hljs-built_in">arguments</span>.length;i++){</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">            <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span> + <span '
             'class="hljs-built_in">arguments</span>[i]+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span> + getSum(<span '
             'class="hljs-number">5</span>, <span '
             'class="hljs-number">6</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);<span '
             'class="hljs-comment">//undefined</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-comment">&lt;!----&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'sop=<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> (<span '
             'class="hljs-params">a</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(a)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    sop(<span class="hljs-string">"hello '
             'world"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">html</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><img alt="" class="has" height="124" '
             'src="https://img-blog.csdn.net/20180919220647662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="655"></p>\n'
             '\n'
             '<p>\xa0<strong></strong></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'age=<span '
             'class="hljs-number">15</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span>+(age&gt;=<span '
             'class="hljs-number">18</span>?<span '
             'class="hljs-string">""</span>:<span '
             'class="hljs-string">""</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>---------------</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css">2018<span '
             'class="hljs-selector-class">.12</span><span '
             'class="hljs-selector-class">.5</span> </code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><strong>ES6 let const\xa0 </strong></p>\n'
             '\n'
             '<p>let\xa0   java </p>\n'
             '\n'
             '<p>const\xa0  </p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs java"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span>   '
             'arr = <span class="hljs-keyword">new</span>  '
             'Array();</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">1</span>)</span></span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">2</span>)</span></span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr1=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr2=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">arr1=arr2     <span '
             'class="hljs-comment">//</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['js /javascript']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:41:08 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ggh990640782/article/details/44598097">https://blog.csdn.net/ggh990640782/article/details/44598097</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div align="center" '
             'style="font-family:STHeiti;font-size:14px;">\n'
             '<h1><br></h1>\n'
             '<div '
             'style="text-align:left;">WebViewjsalert</div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div '
             'style="text-align:left;">webView.loadUrl("javascript:alert(\'hello\')")<br></div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div style="text-align:left;"> webviewjs</div>\n'
             '</div>\n'
             '<div '
             'style="font-family:STHeiti;line-height:24px;font-size:14px;">\n'
             '<p>1 WebSettingsjavascript</p>\n'
             '<p></p><pre><code class="language-java '
             'hljs">mWebView.getSettings().&lt;span style=<span '
             'class="hljs-string">"font-family: '
             'STHeiti;"</span>&gt;setJavaScriptEnabled(<span '
             'class="hljs-keyword">true</span>);&lt;/span&gt;</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p></p>\n'
             '<p>2) documentload</p>\n'
             '<pre><code class="language-java hljs">webView.loadData(,<span '
             'class="hljs-string">"text/html"</span>,<span '
             'class="hljs-string">"UTF-8"</span>);</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p>3</p>\n'
             '<p><span>webView.loadData(,"text/html","UTF-8");</span></p>\n'
             '<p><span>webView.loadUrl("javascript:alert(\'hello\')");</span></p>\n'
             '<p> \xa01 2) 3onPageFinished</p>\n'
             '<p><span>mWebView.setWebViewClient(new '
             'MyWebViewClient());</span></p>\n'
             '<p><span>private class MyWebViewClient extends WebViewClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public void onPageFinished(WebView '
             'webView, String url) {</span></p>\n'
             '<p><span><span></span>webView.loadUrl("javascript:"+script);</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '4console/alert\n'
             '<p></p>\n'
             '<p>jsconsole.logalert</p>\n'
             '<p>2</p>\n'
             '<p><span>mWebView.setWebChromeClient(new '
             'MyWebChromeClient());</span></p>\n'
             '<p><span>private class MyWebChromeClient extends WebChromeClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean '
             'onConsoleMessage(ConsoleMessage cm) {</span></p>\n'
             '<p><span><span></span>Log.d("test", cm.message() + " -- From '
             'line "\xa0</span><span>+ cm.lineNumber() + " of '
             '"</span><span>\xa0+\n'
             ' cm.sourceId() );</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean onJsAlert(WebView view, '
             'String url, String message, JsResult result) {</span></p>\n'
             '<p><span><span></span>Toast.makeText(mContext, message, '
             'Toast.LENGTH_SHORT).show();</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '<div><br></div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Android webviewjs '
           'webView.loadUrl("javascript:alert(\'hello\')")']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 15 items (at 5 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 6 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 5 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 6 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 6 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 2 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-01 13:50:47 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 6 items/min)
2019-11-01 13:54:30 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'golang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/chao2016/article/details/81292210">https://blog.csdn.net/chao2016/article/details/81292210</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="1-golang"><a name="t0"></a>1. Golang</h1>\n'
             '\n'
             '<p><a href="https://golang.google.cn/dl/" rel="nofollow" '
             'data-token="1b3ca1c4968194e8253e8b40f9d493aa">https://golang.google.cn/dl/</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">wget https:<span '
             'class="hljs-comment">//dl.google.com/go/go1.10.3.darwin-amd64.tar.gz</span>\n'
             'tar <span class="hljs-attribute">-zxvf</span> go1<span '
             'class="hljs-number">.4</span><span '
             'class="hljs-built_in">.</span>linux<span '
             'class="hljs-attribute">-amd64</span><span '
             'class="hljs-built_in">.</span>tar<span '
             'class="hljs-built_in">.</span>gz <span '
             'class="hljs-attribute">-C</span> /usr/<span '
             'class="hljs-built_in">local</span> \n'
             '\n'
             'vim ~<span class="hljs-subst">/</span><span '
             'class="hljs-built_in">.</span>bash_profile\n'
             'export GOROOT<span class="hljs-subst">=</span>/usr/<span '
             'class="hljs-built_in">local</span>/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOROOT</span>/bin\n'
             'export GOPATH<span '
             'class="hljs-subst">=</span>/Users/chao/Documents/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOPATH</span>/bin<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li></ul>\n'
             '\n'
             '<p>golangGOPATHimportpackage</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs perl '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">cd <span class="hljs-variable">$GOPATH</span>\n'
             '<span class="hljs-keyword">mkdir</span> src\n'
             '<span class="hljs-keyword">mkdir</span> bin\n'
             '<span class="hljs-keyword">mkdir</span> pkg<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>\n'
             '\n'
             '<p>srcmydemotree</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs avrasm '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">tree\n'
             '.\n'
             ' bin\n'
             ' pkg\n'
             '    darwin_amd64\n'
             '        mydemo<span class="hljs-preprocessor">.a</span>\n'
             ' src\n'
             '     mydemo\n'
             '             main<span '
             'class="hljs-preprocessor">.go</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li></ul>\n'
             '\n'
             '<blockquote>\n'
             '  <p>bin :  <br>\n'
             '  pkg:  <br>\n'
             '  src : </p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="2-goland"><a name="t1"></a>2. GoLand</h1>\n'
             '\n'
             '<p>JetbrainIDEIDEAPycharm</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id=""><a name="t2"></a></h1>\n'
             '\n'
             '<p>goland</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="1importpackage"><a '
             'name="t3"></a>1importpackage</h2>\n'
             '\n'
             '<p>GOPATHsrc</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="2package"><a '
             'name="t4"></a>2package</h2>\n'
             '\n'
             '<p> <br>\n'
             'package</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="goland"><a name="t5"></a>Goland</h1>\n'
             '\n'
             '<p>goimports</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20180828072703748?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW8yMDE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>\n'
             '\n'
             '<p> <br>\n'
             'Preference -&gt; tools -&gt; File Watchers -&gt; + -&gt; '
             'goimports</p>\n'
             '\n'
             '<p>googlegoimports</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-comment">// 1. '
             'gopm$GOPATH/srcgithub.com/gpmgo</span>\n'
             'go get <span class="hljs-attribute">-v</span> github<span '
             'class="hljs-built_in">.</span>com/gpmgo/gopm\n'
             '<span class="hljs-comment">// 2. '
             'gopmgoimports$GOPATH/srcgolang.org</span>\n'
             '<span class="hljs-comment">// '
             '-g$GOPATH-v-u</span>\n'
             'gopm get <span class="hljs-attribute">-g</span> <span '
             'class="hljs-attribute">-v</span> golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports\n'
             '<span class="hljs-comment">// 3. $GOPATH/bin/</span>\n'
             'go install src/golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports<span '
             'class="hljs-subst">/</span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li></ul>\n'
             '\n'
             '<p>goland$GOPATHgoimports</p>\n'
             '\n'
             '<p>goimportsimportimport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"chao"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p>ctrl+simport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Golang: ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 13:56:06 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 13:56:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 13:56:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:06 [scrapy.extensions.telnet] INFO: Telnet Password: 9cf0a95024f3e840
2019-11-01 13:56:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [C_spider] INFO: Spider opened: C_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 8c77b825505a369d
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 32de155ac9583460
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 01ea6f6d1431b8fa
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: d8e56eeeea02a9f0
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 8a903acbcbe8fc49
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [html_spider] INFO: Spider opened: html_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 174c5cb89fddcdc1
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [java_spider] INFO: Spider opened: java_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: 76220630aee5dbe1
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [js_spider] INFO: Spider opened: js_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 13:56:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet Password: b16232c36c709372
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 13:56:08 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 13:56:08 [scrapy.core.engine] INFO: Spider opened
2019-11-01 13:56:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:56:08 [python_spider] INFO: Spider opened: python_spider
2019-11-01 13:56:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 13:59:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:01:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:17:02 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 14:17:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 14:17:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:17:02 [scrapy.extensions.telnet] INFO: Telnet Password: cb1359061bccdcdc
2019-11-01 14:17:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:17:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:17:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:17:03 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:17:03 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:17:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:17:03 [java_spider] INFO: Spider opened: java_spider
2019-11-01 14:17:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 14:17:48 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-11-01 14:17:49 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022C02449400>: Failed to establish a new connection: [WinError 10061] ',)': /session/05ab8d1b3f2122945456ad331298ed94/source
2019-11-01 14:17:50 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022C018F0CC0>: Failed to establish a new connection: [WinError 10061] ',)': /session/05ab8d1b3f2122945456ad331298ed94/source
2019-11-01 14:17:51 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022C024162B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/05ab8d1b3f2122945456ad331298ed94/source
2019-11-01 14:18:04 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:18:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.csdn.net/java1995_com/article/details/5953933>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022C02416278>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 97, in process_request
    html = self.driver.page_source
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 66, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 87, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=57915): Max retries exceeded with url: /session/05ab8d1b3f2122945456ad331298ed94/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022C02416278>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 14:18:04 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:18:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/urllib3.exceptions.MaxRetryError': 1,
 'downloader/response_bytes': 551864,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 6, 18, 5, 47090),
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'log_count/WARNING': 3,
 'request_depth_max': 1,
 'response_received_count': 4,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 55,
 'scheduler/enqueued/memory': 55,
 'start_time': datetime.datetime(2019, 11, 1, 6, 17, 3, 537830)}
2019-11-01 14:18:05 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 14:18:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 14:18:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 14:18:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:18:16 [scrapy.extensions.telnet] INFO: Telnet Password: 8de50406d185ae74
2019-11-01 14:18:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:18:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:18:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:18:18 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:18:18 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:18:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:18:18 [java_spider] INFO: Spider opened: java_spider
2019-11-01 14:18:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 14:19:23 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:19:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 14:19:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1540727,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 6, 19, 23, 158049),
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 6, 18, 18, 423125)}
2019-11-01 14:19:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 14:21:58 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 14:21:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 14:21:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:21:58 [scrapy.extensions.telnet] INFO: Telnet Password: 10e2c6cc5071353c
2019-11-01 14:21:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:22:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:22:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:22:02 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:22:02 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:22:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:22:02 [java_spider] INFO: Spider opened: java_spider
2019-11-01 14:22:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 14:22:32 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 14:22:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1507327,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 6, 22, 32, 408619),
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 6, 22, 2, 744907)}
2019-11-01 14:22:32 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 14:24:49 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 14:24:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 14:24:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:49 [scrapy.extensions.telnet] INFO: Telnet Password: 020ee26b82cc1187
2019-11-01 14:24:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [C_spider] INFO: Spider opened: C_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: 082fe0aea7fb5b50
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: d4fba9ed490e42cc
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: 0ba3b3c38285c002
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: c31ab4b36df7e8b5
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: fe2f91e083122e57
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [html_spider] INFO: Spider opened: html_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: fd5f930a1087b74d
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:53 [java_spider] INFO: Spider opened: java_spider
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 14:24:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: 868db96a0931f123
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:53 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:54 [js_spider] INFO: Spider opened: js_spider
2019-11-01 14:24:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 14:24:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:24:54 [scrapy.extensions.telnet] INFO: Telnet Password: 5d731ad25ba858c3
2019-11-01 14:24:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:24:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:24:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:24:54 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:24:54 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:24:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:24:54 [python_spider] INFO: Spider opened: python_spider
2019-11-01 14:24:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 14:25:27 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-11-01 14:25:28 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2019-11-01 14:25:28 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936B99B38>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:29 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936B99320>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:30 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936B992B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:32 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936BBC9B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:33 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936BBCB38>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:34 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020936BBCBA8>: Failed to establish a new connection: [WinError 10061] ',)': /session/151dc9ede1c7e6d5f323b45df118a842/url
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 14:25:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=1&q=java&t=&viparticle=&domain=&o=&s=&u=&l=>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 383, in _make_request
    httplib_response = conn.getresponse()
  File "d:\programdata\anaconda3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "d:\programdata\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "d:\programdata\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "d:\programdata\anaconda3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 101, in process_request
    driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 357, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\packages\six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 383, in _make_request
    httplib_response = conn.getresponse()
  File "d:\programdata\anaconda3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "d:\programdata\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "d:\programdata\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "d:\programdata\anaconda3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '', None, 10054, None))
2019-11-01 14:25:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=1&q=js&t=&viparticle=&domain=&o=&s=&u=&l=>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 357, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "d:\programdata\anaconda3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "d:\programdata\anaconda3\lib\http\client.py", line 964, in send
    self.connect()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 166, in connect
    conn = self._new_conn()
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000209363DAF28>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 101, in process_request
    driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 668, in urlopen
    **response_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=58418): Max retries exceeded with url: /session/151dc9ede1c7e6d5f323b45df118a842/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000209363DAF28>: Failed to establish a new connection: [WinError 10061] ',))
2019-11-01 14:25:45 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 14:25:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 14:25:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:45 [scrapy.extensions.telnet] INFO: Telnet Password: 53941de256af46dd
2019-11-01 14:25:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:49 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:49 [C_spider] INFO: Spider opened: C_spider
2019-11-01 14:25:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 14:25:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:49 [scrapy.extensions.telnet] INFO: Telnet Password: 64a7269d26969a71
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:49 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:49 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 14:25:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 14:25:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:49 [scrapy.extensions.telnet] INFO: Telnet Password: 8c9e1270f221f07d
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 3355e483504ade45
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 4ba279a497f36ecf
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 95c076657c18c8bf
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [html_spider] INFO: Spider opened: html_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 304e2f61da72b626
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [java_spider] INFO: Spider opened: java_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 0d3c42482179252b
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [js_spider] INFO: Spider opened: js_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 14:25:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet Password: 499ca8fc1f38b522
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 14:25:50 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 14:25:50 [scrapy.core.engine] INFO: Spider opened
2019-11-01 14:25:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:25:50 [python_spider] INFO: Spider opened: python_spider
2019-11-01 14:25:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:34:33 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:38:30 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:41:33 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 5 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 2 items (at 2 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 6 items/min)
2019-11-01 14:46:04 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 5 items (at 3 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 4 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 4 items (at 3 items/min)
2019-11-01 14:54:45 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/machitaoX/article/details/85054039">https://blog.csdn.net/machitaoX/article/details/85054039</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h2><a '
             'name="t0"></a><a id="1_0"></a>1</h2>\n'
             '<p>python 3<br>\n'
             '&gt;&gt;&gt; print(hello python inter)</p>\n'
             '<h2><a name="t1"></a><a id="2python_4"></a>2python</h2>\n'
             '<p>1geanyrootapt-get install geany<br>\n'
             '2pythonpython commands : compilepython 3<br>\n'
             'execute python 3</p>\n'
             '<h2><a name="t2"></a><a id="3_8"></a>3</h2>\n'
             '<p>Linux python ***.py</p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['python:    execute']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:56:17 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'erlang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/abv123456789/article/details/40782861">https://blog.csdn.net/abv123456789/article/details/40782861</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            '
             '<div>\ufeff\ufeff</div><p><strong><a '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html" '
             'rel="nofollow" '
             'data-token="0a9565600d8ed46d87646a52e78e376f">http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html</a></strong></p><p><strong>On '
             'Preserving Term Sharing in the Erlang Virtual '
             'Machine<br></strong>:\xa0<a '
             'href="http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf" '
             'rel="nofollow" '
             'data-token="d8d7e52be5b17e4b0bd99faa342ce30f"><span '
             'style="text-decoration:underline;">http://user.it.uu.se/~kostis/Papers/erlang12_sharing.pdf</span></a>\xa0'
             '<br>:In this paper we describe our experiences and argue '
             'through examples why attening terms during copying is not a '
             'good idea for<br> a language like Erlang. More importantly, we '
             'propose a sharing\xa0preserving copying mechanism for Erlang/OTP '
             'and describe a pub-<br>licly available complete implementation '
             'of this mechanism.\xa0<br><br> \xa0 \xa0Term Sharing \xa0'
             ',"Efficiency Guide User\'s Guide"4.2"Constructing '
             'binaries"[ <a '
             'href="http://www.erlang.org/doc/efficiency_guide/binaryhandling.html" '
             'rel="nofollow" '
             'data-token="b5ea8aa3ec0e5ebfa54a7e3fac04a6b8"><span '
             'style="text-decoration:underline;"></span></a> ]  8.2 '
             '"Loss of sharing"\xa0[<a '
             'href="http://www.erlang.org/doc/efficiency_guide/processes.html" '
             'rel="nofollow" '
             'data-token="31199e586e502dc4b2759368632240d0"><span '
             'style="text-decoration:underline;"></span></a>](Erlang,,).Binary,Term '
             'Sharing .Guide:ETS. '
             ':</p><blockquote><p>\xa0 \xa0<strong>Loss of '
             'sharing</strong><br> \xa0\xa0<br> \xa0 Shared sub-terms are not '
             'preserved when a term is sent to\xa0another process, passed as '
             'the initial process arguments\xa0in the spawn call, or stored in '
             'an ETS table. That is an\xa0optimization. Most applications do '
             'not send messages with\xa0shared '
             'sub-terms.</p></blockquote><p>\xa0</p><p>\xa0 \xa0'
             ',Erlang.,flat '
             'size(erts/emulator/beam/copy.csize_object\xa0'
             '),\xa0(function copy_structin '
             'erts/emulator/beam/copy.c).<br><br>,erts_debug:size/1erts_debug:flat_size/1</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_112625"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div></td><td '
             'class="code"><div><div class="line number1 index0 alt2"><code '
             'class="csharp plain">s3(L)-&gt;</code></div><div class="line '
             'number2 index1 alt1"><code class="csharp spaces">\xa0\xa0\xa0\xa0'
             '</code><code class="csharp plain">L2=[L,L,L,L],</code></div><div '
             'class="line number3 index2 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{{erts_debug:size(L),erts_debug:flat_size(L)},</code></div><div '
             'class="line number4 index3 alt1"><code class="csharp '
             'spaces">\xa0\xa0\xa0\xa0\xa0\xa0</code><code class="csharp '
             'plain">{erts_debug:size(L2),erts_debug:flat_size(L2)}}</code></div><div '
             'class="line number5 index4 alt2"><code class="csharp '
             'plain">.</code></div><div class="line number6 index5 alt1">\xa0'
             '</div><div class="line number7 index6 alt2"><code class="csharp '
             'plain">9&gt; d:s3([1,2,3,4,5,6]).</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">{{12,12},{20,56}}</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'shell,spawn,,ETS.</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_461953"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div><div class="line number25 index24 '
             'alt2">25</div><div class="line number26 index25 '
             'alt1">26</div><div class="line number27 index26 '
             'alt2">27</div><div class="line number28 index27 '
             'alt1">28</div><div class="line number29 index28 '
             'alt2">29</div><div class="line number30 index29 '
             'alt1">30</div><div class="line number31 index30 '
             'alt2">31</div><div class="line number32 index31 '
             'alt1">32</div><div class="line number33 index32 '
             'alt2">33</div><div class="line number34 index33 '
             'alt1">34</div><div class="line number35 index34 '
             'alt2">35</div><div class="line number36 index35 '
             'alt1">36</div><div class="line number37 index36 '
             'alt2">37</div><div class="line number38 index37 '
             'alt1">38</div><div class="line number39 index38 '
             'alt2">39</div><div class="line number40 index39 '
             'alt1">40</div><div class="line number41 index40 '
             'alt2">41</div><div class="line number42 index41 '
             'alt1">42</div><div class="line number43 index42 '
             'alt2">43</div><div class="line number44 index43 '
             'alt1">44</div><div class="line number45 index44 '
             'alt2">45</div><div class="line number46 index45 '
             'alt1">46</div><div class="line number47 index46 '
             'alt2">47</div><div class="line number48 index47 '
             'alt1">48</div><div class="line number49 index48 '
             'alt2">49</div><div class="line number50 index49 '
             'alt1">50</div><div class="line number51 index50 '
             'alt2">51</div><div class="line number52 index51 '
             'alt1">52</div><div class="line number53 index52 '
             'alt2">53</div><div class="line number54 index53 '
             'alt1">54</div><div class="line number55 index54 '
             'alt2">55</div><div class="line number56 index55 '
             'alt1">56</div><div class="line number57 index56 '
             'alt2">57</div><div class="line number58 index57 '
             'alt1">58</div><div class="line number59 index58 '
             'alt2">59</div><div class="line number60 index59 '
             'alt1">60</div><div class="line number61 index60 '
             'alt2">61</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt; '
             'L=[1,2,3,4,5,6,7,8,9,10].</code></div><div class="line number3 '
             'index2 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">2&gt;\xa0 '
             'L2=[L,L,L,L,L,L].</code></div><div class="line number5 index4 '
             'alt2"><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number11 index10 alt2"><code class="csharp plain">3&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number12 '
             'index11 alt1"><code class="csharp plain">32</code></div><div '
             'class="line number13 index12 alt2"><code class="csharp '
             'plain">4&gt;\xa0 erts_debug:flat_size(L2).</code></div><div '
             'class="line number14 index13 alt1"><code class="csharp '
             'plain">132</code></div><div class="line number15 index14 '
             'alt2"><code class="csharp plain">5&gt;\xa0 spawn(fun () '
             '-&gt;receive Data -&gt;\xa0 io:format(</code><code class="csharp '
             'string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]) end end).</code></div><div '
             'class="line number16 index15 alt1"><code class="csharp '
             'plain">&lt;0.39.0&gt;</code></div><div class="line number17 '
             'index16 alt2"><code class="csharp plain">6&gt; v(5) ! '
             'L2.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp '
             'plain">132[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number19 index18 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number20 index19 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number21 index20 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number22 index21 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number24 index23 alt1"><code class="csharp plain">7&gt;\xa0 '
             'erts_debug:size(L2).</code></div><div class="line number25 '
             'index24 alt2"><code class="csharp plain">32</code></div><div '
             'class="line number26 index25 alt1"><code class="csharp '
             'plain">8&gt; ets:</code><code class="csharp '
             'keyword">new</code><code class="csharp '
             'plain">(test,[named_table]).</code></div><div class="line '
             'number27 index26 alt2"><code class="csharp '
             'plain">test</code></div><div class="line number28 index27 '
             'alt1"><code class="csharp plain">9&gt; '
             'ets:insert(test,{1,L2}).</code></div><div class="line number29 '
             'index28 alt2"><code class="csharp keyword">true</code></div><div '
             'class="line number30 index29 alt1"><code class="csharp '
             'plain">10&gt;\xa0 ets:lookup(test ,1).</code></div><div '
             'class="line number31 index30 alt2"><code class="csharp '
             'plain">[{1,</code></div><div class="line number32 index31 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number33 index32 alt2"><code class="csharp '
             'spaces">\xa0\xa0\xa0</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number34 index33 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number35 index34 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number36 index35 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number37 index36 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number38 index37 alt1"><code class="csharp plain">11&gt; '
             '[{1,Data}]=v(10).</code></div><div class="line number39 index38 '
             'alt2"><code class="csharp plain">[{1,</code></div><div '
             'class="line number40 index39 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp '
             'plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number41 index40 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number42 index41 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number43 index42 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number44 index43 alt1"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number45 index44 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]}]</code></div><div class="line '
             'number46 index45 alt1"><code class="csharp plain">12&gt; '
             'Data.</code></div><div class="line number47 index46 alt2"><code '
             'class="csharp plain">[[1,2,3,4,5,6,7,8,9,10],</code></div><div '
             'class="line number48 index47 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number49 index48 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number50 index49 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number51 index50 alt2"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10],</code></div><div class="line '
             'number52 index51 alt1"><code class="csharp '
             'plain">[1,2,3,4,5,6,7,8,9,10]]</code></div><div class="line '
             'number53 index52 alt2"><code class="csharp plain">13&gt;\xa0 '
             'erts_debug:size(Data).</code></div><div class="line number54 '
             'index53 alt1"><code class="csharp plain">132</code></div><div '
             'class="line number55 index54 alt2"><code class="csharp '
             'plain">14&gt; spawn(d,test,[L2]).</code></div><div class="line '
             'number56 index55 alt1"><code class="csharp '
             'plain">132&lt;0.54.0&gt;</code></div><div class="line number57 '
             'index56 alt2">\xa0</div><div class="line number58 index57 '
             'alt1"><code class="csharp spaces">\xa0</code><code class="csharp '
             'plain">test(Data)-&gt;</code></div><div class="line number59 '
             'index58 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">io:format(</code><code '
             'class="csharp string">"~p"</code><code class="csharp '
             'plain">,[erts_debug:size(Data)]).</code></div><div class="line '
             'number60 index59 alt1">\xa0</div><div class="line number61 '
             'index60 alt2"><code class="csharp spaces">\xa0\xa0</code>\xa0'
             '</div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             ',,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_898436"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp '
             'plain">show_printing_may_be_bad() -&gt;</code></div><div '
             'class="line number2 index1 alt1"><code class="csharp '
             'spaces">\xa0\xa0</code><code class="csharp plain">F = fun (N) '
             '-&gt;</code></div><div class="line number3 index2 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">T = now(),</code></div><div class="line number4 index3 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">L = mklist(N),</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp spaces">\xa0\xa0'
             '</code><code class="csharp plain">S = '
             'erts_debug:size(L),</code></div><div class="line number6 index5 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"mklist(~w), size ~w, "</code><code class="csharp '
             'plain">, [N, S]),</code></div><div class="line number7 index6 '
             'alt2"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">io:format(</code><code class="csharp '
             'string">"is ~P, "</code><code class="csharp plain">, [L, 2]), '
             '%%% BAD !!!</code></div><div class="line number8 index7 '
             'alt1"><code class="csharp spaces">\xa0\xa0</code><code '
             'class="csharp plain">D = timer:now_diff(now(), '
             'T),</code></div><div class="line number9 index8 alt2"><code '
             'class="csharp spaces">\xa0\xa0</code><code class="csharp '
             'plain">io:format(</code><code class="csharp string">"in ~.3f '
             'sec.~n"</code><code class="csharp plain">, '
             '[D/1000000])</code></div><div class="line number10 index9 '
             'alt1"><code class="csharp spaces">\xa0\xa0\xa0</code><code '
             'class="csharp plain">end,</code></div><div class="line number11 '
             'index10 alt2"><code class="csharp spaces">\xa0\xa0\xa0'
             '</code><code class="csharp plain">lists:</code><code '
             'class="csharp keyword">foreach</code><code class="csharp '
             'plain">(F, [10, 20, 22, 24, 26, 28, 30]).</code></div><div '
             'class="line number12 index11 alt1">\xa0</div><div class="line '
             'number13 index12 alt2"><code class="csharp plain">mklist(0) '
             '-&gt; 0;</code></div><div class="line number14 index13 '
             'alt1"><code class="csharp plain">mklist(M) -&gt; X = '
             'mklist(M-1), [X, '
             'X].</code></div></div></td></tr></tbody></table></div></div></div></div><p>\u3000\u3000'
             'io:format("is ~P, ", [L, 2]), %%% BAD '
             '!!!,:</p><div '
             'class="cnblogs_Highlighter"><div><div class="syntaxhighlighter '
             'csharp ie" id="highlighter_643843"><div class="toolbar"><span><a '
             'class="toolbar_item command_help help" '
             'href="http://www.cnblogs.com/me-sa/p/term_sharing_in_erlang_otp_one.html#" '
             'rel="nofollow" '
             'data-token="436b655aa88e0a26522b9de5463e217e">?</a></span></div><div '
             'class="table-box"><table border="0" cellspacing="0" '
             'cellpadding="0"><tbody><tr><td class="gutter"><div class="line '
             'number1 index0 alt2">1</div><div class="line number2 index1 '
             'alt1">2</div><div class="line number3 index2 alt2">3</div><div '
             'class="line number4 index3 alt1">4</div><div class="line number5 '
             'index4 alt2">5</div><div class="line number6 index5 '
             'alt1">6</div><div class="line number7 index6 alt2">7</div><div '
             'class="line number8 index7 alt1">8</div><div class="line number9 '
             'index8 alt2">9</div><div class="line number10 index9 '
             'alt1">10</div><div class="line number11 index10 '
             'alt2">11</div><div class="line number12 index11 '
             'alt1">12</div><div class="line number13 index12 '
             'alt2">13</div><div class="line number14 index13 '
             'alt1">14</div><div class="line number15 index14 '
             'alt2">15</div><div class="line number16 index15 '
             'alt1">16</div><div class="line number17 index16 '
             'alt2">17</div><div class="line number18 index17 '
             'alt1">18</div><div class="line number19 index18 '
             'alt2">19</div><div class="line number20 index19 '
             'alt1">20</div><div class="line number21 index20 '
             'alt2">21</div><div class="line number22 index21 '
             'alt1">22</div><div class="line number23 index22 '
             'alt2">23</div><div class="line number24 index23 '
             'alt1">24</div></td><td class="code"><div><div class="line '
             'number1 index0 alt2"><code class="csharp plain">Eshell V6.0\xa0 '
             '(abort with ^G)</code></div><div class="line number2 index1 '
             'alt1"><code class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number3 index2 alt2"><code class="csharp plain">mklist(10), size '
             '40, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.001 sec.</code></div><div class="line '
             'number4 index3 alt1"><code class="csharp plain">mklist(20), size '
             '80, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number5 index4 alt2"><code class="csharp plain">mklist(22), size '
             '88, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number6 index5 alt1"><code class="csharp plain">mklist(24), size '
             '96, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number7 index6 alt2"><code class="csharp plain">mklist(26), size '
             '104, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number8 index7 alt1"><code class="csharp plain">mklist(28), size '
             '112, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number9 index8 alt2"><code class="csharp plain">mklist(30), size '
             '120, </code><code class="csharp keyword">in</code> <code '
             'class="csharp plain">0.000 sec.</code></div><div class="line '
             'number10 index9 alt1"><code class="csharp '
             'plain">ok</code></div><div class="line number11 index10 '
             'alt2">\xa0</div><div class="line number12 index11 alt1">\xa0'
             '</div><div class="line number13 index12 alt2"><code '
             'class="csharp plain">Eshell V6.0\xa0 (abort with '
             '^G)</code></div><div class="line number14 index13 alt1"><code '
             'class="csharp plain">1&gt;\xa0 '
             'd:show_printing_may_be_bad().</code></div><div class="line '
             'number15 index14 alt2"><code class="csharp plain">mklist(10), '
             'size 40, </code><code class="csharp keyword">is</code> <code '
             'class="csharp plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.001 '
             'sec.</code></div><div class="line number16 index15 alt1"><code '
             'class="csharp plain">mklist(20), size 80, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.110 '
             'sec.</code></div><div class="line number17 index16 alt2"><code '
             'class="csharp plain">mklist(22), size 88, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">0.421 '
             'sec.</code></div><div class="line number18 index17 alt1"><code '
             'class="csharp plain">mklist(24), size 96, </code><code '
             'class="csharp keyword">is</code> <code class="csharp '
             'plain">[[...]|...], </code><code class="csharp '
             'keyword">in</code> <code class="csharp plain">43.105 '
             'sec.</code></div><div class="line number19 index18 alt2"><code '
             'class="csharp plain">mklist(26), size 104, </code></div><div '
             'class="line number20 index19 alt1"><code class="csharp '
             'plain">Crash dump was written to: '
             'erl_crash.dump</code></div><div class="line number21 index20 '
             'alt2"><code class="csharp plain">eheap_alloc: Cannot allocate '
             '3280272216 bytes of memory (of type </code><code class="csharp '
             'string">"heap"</code><code class="csharp '
             'plain">).</code></div><div class="line number22 index21 '
             'alt1"><code class="csharp plain">rlwrap: warning: erl killed '
             '</code><code class="csharp keyword">by</code> <code '
             'class="csharp plain">SIGABRT.</code></div><div class="line '
             'number23 index22 alt2"><code class="csharp plain">rlwrap has not '
             'crashed, but </code><code class="csharp keyword">for</code> '
             '<code class="csharp plain">transparency,</code></div><div '
             'class="line number24 index23 alt1"><code class="csharp plain">it '
             'will now kill itself (without dumping core)with the same '
             'signal</code></div></div></td></tr></tbody></table></div></div></div></div><p>\xa0 \xa0'
             ',.<br><br> \xa0 \xa0'
             '?"Loss of '
             'sharing",()?io:format( [Erlang '
             '0041] io:format [<a '
             'href="http://www.cnblogs.com/me-sa/archive/2012/02/26/erlang0041.html" '
             'rel="nofollow" '
             'data-token="32236b65bc756f87d9c77d1a7490fb7a"><span '
             'style="text-decoration:underline;"></span></a>]),Erlang/OTPI/OI/O '
             'ServerI/O.io:formatI/O io request,IO '
             'Server.L"\xa0'
             '[[...]|...]";<br><br> \xa0 \xa0'
             ',releaseio:format;\xa0'
             '</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['[Erlang]Term sharing in Erlang/OTP ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\erlang\\[Erlang]Term sharing in Erlang/OTP \\[Erlang]Term sharing in Erlang/OTP .html'
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 7 items (at 1 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 8 items (at 2 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 5 pages/min), scraped 5 items (at 0 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:56:48 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 3 pages/min), scraped 5 items (at 1 items/min)
2019-11-01 14:57:51 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C++\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 14:57:52 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C++',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:57:52 [scrapy.core.scraper] ERROR: Error processing {'Atype': '.net',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/hello_word2/article/details/83311880">https://blog.csdn.net/hello_word2/article/details/83311880</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p>MyCat</p>\n'
             '\n'
             '<p>: : java.net.MalformedURLException: Local host name '
             'unknown: java.net.UnknownHostException: node04:</p>\n'
             '\n'
             '<p> node04</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">1.network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">vi '
             '/etc/sysconfig/network</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> '
             'HOSTNAME=XXXX</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">2. HOSTS</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> vi /etc/hosts</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> 127.0.0.1  localhost.localdomain localhost '
             'XXXX</div></div></li></ol></code><div class="hljs-button '
             'signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p> rebooot.</p>                                    '
             '</div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['java.net.MalformedURLException: Local host name unknown: '
           'java.net.UnknownHostException']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:57:55 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/qq_28249373/article/details/77191934">https://blog.csdn.net/qq_28249373/article/details/77191934</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>C#OpenGLC#OpenGLC#OpenGLC#C#OpenGLOpenGL4.0OpenGL4.6OpenGL</p>\n'
             '<h2><a name="t0"></a><a id="COpenGL_2"></a>C#OpenGL</h2>\n'
             '<p>C#OpenGLC#OpenGLCOpenGLopengl32.dll<br>\n'
             '1.1OpenGLopengl32.dll300opengl32.dllwindowsstdcallC<br>\n'
             'OpenGLwindows1.1OpenGL1.2opengl32.dllopengl32.dllwglGetProcAddressOpenGL<br>\n'
             'C#OpenGLopengl32.dllCC#C/C++</p>\n'
             '<h2><a name="t1"></a><a id="CCCdll_9"></a>C#C/C++dll</h2>\n'
             '<p>C#dll</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>System.Runtime.InteropServices<br>\n'
             '</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DLLImport("XXX.dll")] extern   \n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p><br>\n'
             '**1.DLLImport**[]DllImportAttributedll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">*CharSet '
             'CharSet=CharSet.Ansi\n'
             '*SetLastError  Win32""SetLastError=true\n'
             '*ExactSpelling  EntryPoint '
             'ExactSpelling=false\n'
             '*PreserveSig PreserveSig=true\n'
             '*CallingConvention '
             'CallingConvention=CallingConvention.Cdec\n'
             '*EntryPointdlldll\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>**2.**abstractstatic '
             ',private,publicpublic+static<br>\n'
             '**3.**DLL<br>\n'
             '**4.**DLL<br>\n'
             '**5.**DLL</p>\n'
             '<p></p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">//\n'
             'System.Runtime.InteropServices\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glBegin",CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void glBegin(uint mode);\n'
             '\n'
             '//\n'
             '[DllImport("opengl32.dll",ExactSpelling =false,EntryPoint = '
             '"glEnd",CharSet = CharSet.Auto,CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static extern  void End();\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li></ul>\n'
             '<p><br>\n'
             '1.System.Runtime.InteropServices<br>\n'
             '2.static<br>\n'
             '3.dllVC/VSCdecC#CdecdllC#OpenGLStdCallCallingConvention '
             '= CallingConvention.StdCall<br>\n'
             '4.C#CdlldllC++C++dllC#<a '
             'href="https://download.csdn.net/download/qq_28249373/11273072" '
             'rel="nofollow" '
             'data-token="6b7cf7cbabdbeff206b65e060419604b">depends</a>dllC#EntryPointdllAddC++dlldll?Add@@YAHHH@ZAddEntryPoint '
             '= ?Add@@YAHHH@Z</p>\n'
             '<p><strong>C#dll</strong></p>\n'
             '<p>CdllwinAPILoadLibraryGetPrcAddressdlldllwinAPIC#winAPI</p>\n'
             '<p>1</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//stringCharSet = CharSet.Ansi\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"Loadlibrary",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr Loadlibrary(string fileName);\n'
             '\n'
             '[DllImport("kernel32.dll",ExactSpelling =false,EntryPoint = '
             '"GetProcAddress",CharSet = CharSet.Ansi, CallingConvention = '
             'CallingConvention.StdCall)]\n'
             'public static IntPtr GetProcAddress(IntPtr hmodule,string '
             'functionName);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li></ul>\n'
             '<p>2glBegin</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">internal '
             'delegate void FUNC(uint mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li></ul>\n'
             '<p>3opengl32.dllglBegin<br>\n'
             'dll</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">//opengl32.dll\n'
             'IntPtr hmodule=LoadLibrary("opengl32.dll");\n'
             '//opengl32.dllglBegin\n'
             'IntPtr funcPointer=GetProcAddress(hmodule,"glBegin");\n'
             '//\n'
             'FUNC '
             'glBegin=Marshal.GetDelegateForFunctionPointer(funcPointer,typeof(FUNC));\n'
             '//\n'
             'glBegin(mode);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<h2><a name="t2"></a><a '
             'id="CCC_91"></a>C#C/C++</h2>\n'
             '<p>C#C/C++</p>\n'
             '\n'
             '<div class="table-box"><table>\n'
             '<thead>\n'
             '<tr>\n'
             '<th align="center">C#</th>\n'
             '<th align="center">C/C++</th>\n'
             '<th align="center">OpenGL</th>\n'
             '</tr>\n'
             '</thead>\n'
             '<tbody>\n'
             '<tr>\n'
             '<td align="center">byte</td>\n'
             '<td align="center">unsigned char</td>\n'
             '<td align="center">GLubyte/GLboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte</td>\n'
             '<td align="center">char</td>\n'
             '<td align="center">GLchar/GLbyte</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">short</td>\n'
             '<td align="center">short</td>\n'
             '<td align="center">GLshort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ushortchar</td>\n'
             '<td align="center">unsigned short</td>\n'
             '<td align="center">GLushort</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">int</td>\n'
             '<td align="center">int/long</td>\n'
             '<td align="center">GLint/GLsizei</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">uint</td>\n'
             '<td align="center">unsigned int/unsigend long</td>\n'
             '<td align="center">GLuint/GLemun/GLbitfield/GLulong</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">long</td>\n'
             '<td align="center">long long</td>\n'
             '<td align="center">GLint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">ulong</td>\n'
             '<td align="center">unsigned long long</td>\n'
             '<td align="center">GLuint64</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">float</td>\n'
             '<td align="center">flaot</td>\n'
             '<td align="center">GLfloat/GLclampf</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">double</td>\n'
             '<td align="center">double</td>\n'
             '<td align="center">GLdouble/GLclampd</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">decimal</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">bool</td>\n'
             '<td align="center">Glboolean</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">byte[]</td>\n'
             '<td align="center">unsigned char*unsigned char[]</td>\n'
             '<td align="center">GLuchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">sbyte[]</td>\n'
             '<td align="center">char*/char[]</td>\n'
             '<td align="center">GLchar*</td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center">/</td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">refout</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '<tr>\n'
             '<td align="center">IntPtr</td>\n'
             '<td align="center"></td>\n'
             '<td align="center"></td>\n'
             '</tr>\n'
             '</tbody>\n'
             '</table></div><p>C#C#IntPtrC#IntPtrIntPtrC<br>\n'
             'CC#C#Cunsafe-&gt;<a '
             'href="http://jingyan.baidu.com/article/afd8f4de55e99c34e286e995.html" '
             'rel="nofollow" '
             'data-token="61b5d5cbecac2c5fe59041262b8ce48d">C#</a></p>\n'
             '<p></p>\n'
             '<p>C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">#include&lt;stdlib.h&gt;\n'
             '//\n'
             'typedef struct MyStruct\n'
             '{\n'
             '\tint x;\n'
             '\tint y;\n'
             '}MyStruct;\n'
             '\n'
             '//FUNC1\n'
             '_declspec(dllexport)int * FUNC1(int A[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tint *B = (int*)malloc(n * sizeof(int));\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '\treturn B;\n'
             '}\n'
             '//FUNC2,\n'
             '_declspec(dllexport)void FUNC2(int *A,int n,int *B)\n'
             '{\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FUNC3\n'
             '_declspec(dllexport)void FUNC3(int A[],int B[])\n'
             '{\n'
             '\tint n;\n'
             '\tn = sizeof(A);\n'
             '\tfor (int i = 0;i &lt; n;i++)\n'
             '\t{\n'
             '\t\tB[i] = A[i] + 1;\n'
             '\t}\n'
             '}\n'
             '//FYNC4\n'
             '_declspec(dllexport)MyStruct FUNC4(MyStruct s)\n'
             '{\n'
             '\tMyStruct *B = (MyStruct*)malloc(sizeof(MyStruct));\n'
             '\t(*B).x = s.x + 1;\n'
             '\t(*B).y = s.y + 1;\n'
             '\treturn *B;\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: '
             'unset;">[DllImport("mydll.dll", ExactSpelling = false, '
             'EntryPoint = "FUNC1", CharSet = CharSet.Auto, CallingConvention '
             '= CallingConvention.Cdecl)]\n'
             'public static extern IntPtr FUNC1(Int32[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(Int32[] a, Int32 n, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li></ul>\n'
             '<p>C#C</p>\n'
             '<pre class="prettyprint"><code class="has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;">unsafe{\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC1", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern int* FUNC1(int[] a);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC2", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC2(int* a, Int32 n,int* b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC3", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             'public static extern void FUNC3(Int32[] a, Int32[] b);\n'
             '\n'
             '[DllImport("mydll.dll", ExactSpelling = false, EntryPoint = '
             '"FUNC4", CharSet = CharSet.Auto, CallingConvention = '
             'CallingConvention.Cdecl)]\n'
             ' public static extern MYSTRUCT FUNC4(MYSTRUCT S);\n'
             '}\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, '
             '153);">13</li></ul>\n'
             '<h2><a name="t3"></a><a id="_207"></a></h2>\n'
             '<p>C#OpenGLjC#OpenGL.lib.dll</p>\n'
             '<p><a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77128556" '
             'rel="nofollow" '
             'data-token="7fdd3bc0d6434630c29793550589dfa4">C#OpenGL</a><br>\n'
             '<a '
             'href="http://blog.csdn.net/qq_28249373/article/details/77373503" '
             'rel="nofollow" '
             'data-token="93d026defac60f89f0e117b3c995b791">C#OpenGL.lib.dll</a></p>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C#OpenGLC#C/C++dll']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 16, in process_item
    downloader.download_Html(html, article['title'][0], path)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\download\downloader.py", line 47, in download_Html
    with open('%s%s%s' % (path,filename,'.html'),'w', encoding='utf-8') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\webCrawler_bishe\\test\\C\\C#OpenGLC#C/C++dll\\C#OpenGLC#C/C++dll.html'
2019-11-01 14:57:56 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'C',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/perry0528/article/details/82495489">https://blog.csdn.net/perry0528/article/details/82495489</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views prism-atom-one-dark">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            '
             '<p>main.c hello.c hello.h<br>\n'
             'main.chello.cahello.hunsigned '
             'int a;<br>\n'
             'main.chello.c"hello.h"</p>\n'
             '<ul>\n'
             '<li>\n'
             '<p><strong></strong></p>\n'
             '</li>\n'
             '<li>\n'
             '<p><em>hello.h</em></p>\n'
             '</li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">ifndef</span> HELLO_H_</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">define</span> HELLO_H_</span>\n'
             '<span class="token keyword">extern</span> <span class="token '
             'keyword">int</span> a<span class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">endif</span></span>\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '<ul>\n'
             '<li><em>hello.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> a <span class="token '
             'operator">=</span> <span class="token number">0</span><span '
             'class="token punctuation">;</span>\n'
             '<span class="token keyword">void</span> fun <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">1</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li></ul>\n'
             '<ul>\n'
             '<li><em>main.c</em></li>\n'
             '</ul>\n'
             '<pre class="prettyprint"><code class="prism language-c '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="token macro property">#<span class="token '
             'directive keyword">include</span> <span class="token '
             'string">&lt;stdio.h&gt;</span></span>\n'
             '<span class="token macro property">#<span class="token directive '
             'keyword">include</span> <span class="token '
             'string">"hello.h"</span></span>\n'
             '<span class="token keyword">int</span> main <span class="token '
             'punctuation">(</span><span class="token punctuation">)</span> '
             '<span class="token punctuation">{</span>\n'
             '\t<span class="token function">fun</span><span class="token '
             'punctuation">(</span><span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\ta <span class="token operator">=</span> <span class="token '
             'number">10</span><span class="token punctuation">;</span>\n'
             '\t<span class="token function">printf</span><span class="token '
             'punctuation">(</span><span class="token '
             'string">"%d\\n"</span><span class="token '
             'punctuation">,</span>a<span class="token '
             'punctuation">)</span><span class="token punctuation">;</span>\n'
             '\t<span class="token keyword">return</span> <span class="token '
             'number">0</span><span class="token punctuation">;</span>\n'
             '<span class="token punctuation">}</span>\n'
             '\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li></ul>\n'
             '<p>110<br>\n'
             'externhello.hextern int '
             'ahello.cint a</p>\n'
             '<ul>\n'
             '<li>externaa</li>\n'
             '<li>int a = 0a</li>\n'
             '</ul>\n'
             '<p>extern int a = 0;</p>\n'
             '<ul>\n'
             '<li>cextern int a = 0int a = '
             '0aextern</li>\n'
             '</ul>\n'
             '\n'
             '                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['C | C++']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:58:00 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/weixin_42323802/article/details/82776451">https://blog.csdn.net/weixin_42323802/article/details/82776451</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            <p><strong>js '
             '/javascrip</strong>t ----&gt;</p>\n'
             '\n'
             '<p><strong>ECMAscript</strong> () DOM ,BOM = browser '
             'object modle</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">&lt;script '
             'type="text/javascript"&gt;&lt;/script&gt;</span> '
             '<strong>HTML</strong><strong>HTML</strong></p>\n'
             '\n'
             '<p><strong>js</strong></p>\n'
             '\n'
             '<p>jsvar js<span '
             'style="color:#86ca5e;"><strong></strong></span>2var,varvar '
             'i=0; </p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><span style="color:#3399ea;">function () {<br>\n'
             '\xa0 \xa0 ;<br>\n'
             '\xa0 \xa0 [return ];<br>\n'
             '}</span></p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span '
             'class="hljs-params">a,b</span>) '
             '</span>{</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">return</span> a+b;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">     <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span>+getSum(<span '
             'class="hljs-number">5</span>,<span '
             'class="hljs-number">6</span>));</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img alt="" class="has" height="266" '
             'src="https://img-blog.csdn.net/20180919183113385?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="853"></p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">js</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-built_in">arguments</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"> </div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><span style="color:#3399ea;">var  = function() {<br>\n'
             '\xa0\xa0 \xa0;<br>\n'
             '}</span></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln" style="width:717px"><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-meta">&lt;!DOCTYPE '
             'html&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">html</span> <span '
             'class="hljs-attr">lang</span>=<span '
             'class="hljs-string">"en"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">meta</span> <span '
             'class="hljs-attr">charset</span>=<span '
             'class="hljs-string">"UTF-8"</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="5"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-tag">&lt;<span '
             'class="hljs-name">title</span>&gt;</span><span '
             'class="hljs-tag">&lt;/<span '
             'class="hljs-name">title</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="6"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">head</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="7"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="8"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="9"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-function"><span '
             'class="hljs-keyword">function</span> <span '
             'class="hljs-title">getSum</span>(<span class="hljs-params">a, '
             'b</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="10"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-comment">/* return a '
             '+ b;*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="11"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-comment">/*arguments*/</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="12"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"arguments"</span> + <span '
             'class="hljs-built_in">arguments</span>.length+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="13"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-keyword">for</span> (<span '
             'class="hljs-keyword">var</span> i=<span '
             'class="hljs-number">0</span>;i&lt;<span '
             'class="hljs-built_in">arguments</span>.length;i++){</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="14"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">            <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span> + <span '
             'class="hljs-built_in">arguments</span>[i]+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="15"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="16"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="17"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">"getSum(a,b)"</span> + getSum(<span '
             'class="hljs-number">5</span>, <span '
             'class="hljs-number">6</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>);<span '
             'class="hljs-comment">//undefined</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="18"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="19"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span '
             'class="hljs-comment">&lt;!----&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="20"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="21"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'sop=<span class="hljs-function"><span '
             'class="hljs-keyword">function</span> (<span '
             'class="hljs-params">a</span>) </span>{</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="22"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">        <span '
             'class="hljs-built_in">document</span>.write(a)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="23"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    }</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="24"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    sop(<span class="hljs-string">"hello '
             'world"</span>);</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="25"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="26"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">body</span>&gt;</span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="27"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">html</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p>\xa0</p>\n'
             '\n'
             '<p><img alt="" class="has" height="124" '
             'src="https://img-blog.csdn.net/20180919220647662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjMyMzgwMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'width="655"></p>\n'
             '\n'
             '<p>\xa0<strong></strong></p>\n'
             '\n'
             '<pre class="has" name="code"><code class="language-html hljs '
             'xml"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;<span '
             'class="hljs-name">script</span> <span '
             'class="hljs-attr">type</span>=<span '
             'class="hljs-string">"text/javascript"</span>&gt;</span><span '
             'class="javascript"></span></div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span class="hljs-keyword">var</span> '
             'age=<span '
             'class="hljs-number">15</span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">    <span '
             'class="hljs-built_in">document</span>.write(<span '
             'class="hljs-string">""</span>+(age&gt;=<span '
             'class="hljs-number">18</span>?<span '
             'class="hljs-string">""</span>:<span '
             'class="hljs-string">""</span>)+<span '
             'class="hljs-string">"&lt;br/&gt;"</span>)</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="4"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-tag">&lt;/<span '
             'class="hljs-name">script</span>&gt;</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>---------------</p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs css">2018<span '
             'class="hljs-selector-class">.12</span><span '
             'class="hljs-selector-class">.5</span> </code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p><strong>ES6 let const\xa0 </strong></p>\n'
             '\n'
             '<p>let\xa0   java </p>\n'
             '\n'
             '<p>const\xa0  </p>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs java"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span>   '
             'arr = <span class="hljs-keyword">new</span>  '
             'Array();</div></div></li><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">1</span>)</span></span>;</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-function">arr <span '
             'class="hljs-title">put</span><span class="hljs-params">(<span '
             'class="hljs-number">2</span>)</span></span>;</div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<pre class="has" name="code"><code class="hljs javascript"><ol '
             'class="hljs-ln"><li><div class="hljs-ln-numbers"><div '
             'class="hljs-ln-line hljs-ln-n" '
             'data-line-number="1"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr1=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="2"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line"><span class="hljs-keyword">const</span> '
             'arr2=<span class="hljs-keyword">new</span> <span '
             'class="hljs-built_in">Array</span>();</div></div></li><li><div '
             'class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" '
             'data-line-number="3"></div></div><div class="hljs-ln-code"><div '
             'class="hljs-ln-line">arr1=arr2     <span '
             'class="hljs-comment">//</span></div></div></li></ol></code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '\n'
             '<p>\xa0</p>                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['js /javascript']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:58:02 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'js',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/ggh990640782/article/details/44598097">https://blog.csdn.net/ggh990640782/article/details/44598097</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <link rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                <div class="htmledit_views" id="content_views">\n'
             '                                            \n'
             '<div align="center" '
             'style="font-family:STHeiti;font-size:14px;">\n'
             '<h1><br></h1>\n'
             '<div '
             'style="text-align:left;">WebViewjsalert</div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div '
             'style="text-align:left;">webView.loadUrl("javascript:alert(\'hello\')")<br></div>\n'
             '<div style="text-align:left;"><br></div>\n'
             '<div style="text-align:left;"> webviewjs</div>\n'
             '</div>\n'
             '<div '
             'style="font-family:STHeiti;line-height:24px;font-size:14px;">\n'
             '<p>1 WebSettingsjavascript</p>\n'
             '<p></p><pre><code class="language-java '
             'hljs">mWebView.getSettings().&lt;span style=<span '
             'class="hljs-string">"font-family: '
             'STHeiti;"</span>&gt;setJavaScriptEnabled(<span '
             'class="hljs-keyword">true</span>);&lt;/span&gt;</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p></p>\n'
             '<p>2) documentload</p>\n'
             '<pre><code class="language-java hljs">webView.loadData(,<span '
             'class="hljs-string">"text/html"</span>,<span '
             'class="hljs-string">"UTF-8"</span>);</code><div '
             'class="hljs-button signin" data-title="" '
             'onclick="hljs.signin(event)"></div></pre>\n'
             '<p>3</p>\n'
             '<p><span>webView.loadData(,"text/html","UTF-8");</span></p>\n'
             '<p><span>webView.loadUrl("javascript:alert(\'hello\')");</span></p>\n'
             '<p> \xa01 2) 3onPageFinished</p>\n'
             '<p><span>mWebView.setWebViewClient(new '
             'MyWebViewClient());</span></p>\n'
             '<p><span>private class MyWebViewClient extends WebViewClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public void onPageFinished(WebView '
             'webView, String url) {</span></p>\n'
             '<p><span><span></span>webView.loadUrl("javascript:"+script);</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '4console/alert\n'
             '<p></p>\n'
             '<p>jsconsole.logalert</p>\n'
             '<p>2</p>\n'
             '<p><span>mWebView.setWebChromeClient(new '
             'MyWebChromeClient());</span></p>\n'
             '<p><span>private class MyWebChromeClient extends WebChromeClient '
             '{</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean '
             'onConsoleMessage(ConsoleMessage cm) {</span></p>\n'
             '<p><span><span></span>Log.d("test", cm.message() + " -- From '
             'line "\xa0</span><span>+ cm.lineNumber() + " of '
             '"</span><span>\xa0+\n'
             ' cm.sourceId() );</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span><span></span>@Override</span></p>\n'
             '<p><span><span></span>public boolean onJsAlert(WebView view, '
             'String url, String message, JsResult result) {</span></p>\n'
             '<p><span><span></span>Toast.makeText(mContext, message, '
             'Toast.LENGTH_SHORT).show();</span></p>\n'
             '<p><span><span></span>return true;</span></p>\n'
             '<p><span><span></span>}</span></p>\n'
             '<p><span>}</span></p>\n'
             '<div><br></div>\n'
             '</div>\n'
             '                                    </div>\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Android webviewjs '
           'webView.loadUrl("javascript:alert(\'hello\')")']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 10 items (at 3 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 9 items (at 3 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 2 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 12 items (at 1 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 0 pages/min), scraped 6 items (at 1 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-01 14:59:08 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 5 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 10 items (at 1 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 4 pages/min), scraped 11 items (at 1 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 5 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 12 items (at 6 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 11 items (at 5 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 6 pages/min), scraped 10 items (at 0 items/min)
2019-11-01 15:04:07 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 11 items (at 6 items/min)
2019-11-01 15:07:41 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'golang',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/chao2016/article/details/81292210">https://blog.csdn.net/chao2016/article/details/81292210</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="1-golang"><a name="t0"></a>1. Golang</h1>\n'
             '\n'
             '<p><a href="https://golang.google.cn/dl/" rel="nofollow" '
             'data-token="1b3ca1c4968194e8253e8b40f9d493aa">https://golang.google.cn/dl/</a></p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">wget https:<span '
             'class="hljs-comment">//dl.google.com/go/go1.10.3.darwin-amd64.tar.gz</span>\n'
             'tar <span class="hljs-attribute">-zxvf</span> go1<span '
             'class="hljs-number">.4</span><span '
             'class="hljs-built_in">.</span>linux<span '
             'class="hljs-attribute">-amd64</span><span '
             'class="hljs-built_in">.</span>tar<span '
             'class="hljs-built_in">.</span>gz <span '
             'class="hljs-attribute">-C</span> /usr/<span '
             'class="hljs-built_in">local</span> \n'
             '\n'
             'vim ~<span class="hljs-subst">/</span><span '
             'class="hljs-built_in">.</span>bash_profile\n'
             'export GOROOT<span class="hljs-subst">=</span>/usr/<span '
             'class="hljs-built_in">local</span>/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOROOT</span>/bin\n'
             'export GOPATH<span '
             'class="hljs-subst">=</span>/Users/chao/Documents/go\n'
             'export PATH<span class="hljs-subst">=</span><span '
             'class="hljs-variable">$PATH</span>:<span '
             'class="hljs-variable">$GOPATH</span>/bin<div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li></ul>\n'
             '\n'
             '<p>golangGOPATHimportpackage</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs perl '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">cd <span class="hljs-variable">$GOPATH</span>\n'
             '<span class="hljs-keyword">mkdir</span> src\n'
             '<span class="hljs-keyword">mkdir</span> bin\n'
             '<span class="hljs-keyword">mkdir</span> pkg<div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>\n'
             '\n'
             '<p>srcmydemotree</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs avrasm '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;">tree\n'
             '.\n'
             ' bin\n'
             ' pkg\n'
             '    darwin_amd64\n'
             '        mydemo<span class="hljs-preprocessor">.a</span>\n'
             ' src\n'
             '     mydemo\n'
             '             main<span '
             'class="hljs-preprocessor">.go</span><div class="hljs-button '
             'signin" data-title=""></div></code></pre><ul '
             'class="pre-numbering" style=""><li style="color: rgb(153, 153, '
             '153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li '
             'style="color: rgb(153, 153, 153);">3</li><li style="color: '
             'rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, '
             '153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li '
             'style="color: rgb(153, 153, 153);">7</li><li style="color: '
             'rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, '
             '153);">9</li></ul>\n'
             '\n'
             '<blockquote>\n'
             '  <p>bin :  <br>\n'
             '  pkg:  <br>\n'
             '  src : </p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="2-goland"><a name="t1"></a>2. GoLand</h1>\n'
             '\n'
             '<p>JetbrainIDEIDEAPycharm</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id=""><a name="t2"></a></h1>\n'
             '\n'
             '<p>goland</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="1importpackage"><a '
             'name="t3"></a>1importpackage</h2>\n'
             '\n'
             '<p>GOPATHsrc</p>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="2package"><a '
             'name="t4"></a>2package</h2>\n'
             '\n'
             '<p> <br>\n'
             'package</p>\n'
             '\n'
             '\n'
             '\n'
             '<h1 id="goland"><a name="t5"></a>Goland</h1>\n'
             '\n'
             '<p>goimports</p>\n'
             '\n'
             '<p></p>\n'
             '\n'
             '<p><img '
             'src="https://img-blog.csdn.net/20180828072703748?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW8yMDE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" '
             'alt="" title=""></p>\n'
             '\n'
             '<p> <br>\n'
             'Preference -&gt; tools -&gt; File Watchers -&gt; + -&gt; '
             'goimports</p>\n'
             '\n'
             '<p>googlegoimports</p>\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs lasso '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-comment">// 1. '
             'gopm$GOPATH/srcgithub.com/gpmgo</span>\n'
             'go get <span class="hljs-attribute">-v</span> github<span '
             'class="hljs-built_in">.</span>com/gpmgo/gopm\n'
             '<span class="hljs-comment">// 2. '
             'gopmgoimports$GOPATH/srcgolang.org</span>\n'
             '<span class="hljs-comment">// '
             '-g$GOPATH-v-u</span>\n'
             'gopm get <span class="hljs-attribute">-g</span> <span '
             'class="hljs-attribute">-v</span> golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports\n'
             '<span class="hljs-comment">// 3. $GOPATH/bin/</span>\n'
             'go install src/golang<span '
             'class="hljs-built_in">.</span>org/x/tools/cmd/goimports<span '
             'class="hljs-subst">/</span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li></ul>\n'
             '\n'
             '<p>goland$GOPATHgoimports</p>\n'
             '\n'
             '<p>goimportsimportimport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"chao"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li></ul>\n'
             '\n'
             '<p>ctrl+simport</p>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code class="hljs erlang '
             'has-numbering" onclick="mdcp.signin(event)" style="position: '
             'unset;"><span class="hljs-function"><span '
             'class="hljs-title">import</span> <span class="hljs-params">(\n'
             '    <span class="hljs-string">"fmt"</span>\n'
             '    <span class="hljs-string">"learngo/tree"</span>\n'
             ')</span></span><div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Golang: ']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 6 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 15 items (at 5 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 17 items (at 6 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 16 items (at 4 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 4 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 6 items/min)
2019-11-01 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 1 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 15 items (at 4 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 17 items (at 1 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 12 items (at 0 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 6 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 15:10:00 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2019-11-01 15:11:41 [scrapy.core.scraper] ERROR: Error processing {'Atype': 'python',
 'content': ['<article class="baidu_pl">\n'
             '                <div id="article_content" class="article_content '
             'clearfix" style="height: 1166px; overflow: hidden;">\n'
             '                                                <div '
             'class="article-copyright">\n'
             '                <span class="creativecommons">\n'
             '                <a rel="license" '
             'href="http://creativecommons.org/licenses/by-sa/4.0/">\n'
             '                    </a>\n'
             '            <span>\n'
             '                <a '
             'href="http://creativecommons.org/licenses/by-sa/4.0/" '
             'target="_blank" rel="noopener"> CC 4.0 BY-SA '
             '</a>            </span>\n'
             '               <div class="article-source-link2222">\n'
             '                    <a '
             'href="https://blog.csdn.net/Rozol/article/details/71081854">https://blog.csdn.net/Rozol/article/details/71081854</a>\n'
             '                </div>\n'
             '            </span>\n'
             '                    </div>\n'
             '                                                    <link '
             'rel="stylesheet" '
             'href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-3019150162.css">\n'
             '                                        <div id="content_views" '
             'class="markdown_views">\n'
             '                    <!-- flowchart   -->\n'
             '                    <svg xmlns="http://www.w3.org/2000/svg" '
             'style="display: none;">\n'
             '                        <path stroke-linecap="round" d="M5,0 '
             '0,2.5 5,5z" id="raphael-marker-block" '
             'style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>\n'
             '                    </svg>\n'
             '                                            <h1 '
             'id="python3-pythonpickle-shelve"><a name="t0"></a>Python3 '
             'Python(pickle / shelve)</h1>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<p><strong> Luzhuo ,.</strong> <br>\n'
             '<strong>: '
             '<code>http://blog.csdn.net/rozol/article/details/71081854</code></strong>  '
             '</p>\n'
             '\n'
             '<hr>\n'
             '\n'
             '<blockquote>\n'
             '  <p>Python3.6.1 <br>\n'
             '  Less is more!</p>\n'
             '</blockquote>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="pickle"><a name="t1"></a>pickle</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#coding=utf-8</span>\n'
             '<span class="hljs-comment"># pickledemo.py Pickle</span>\n'
             '<span class="hljs-comment"># Python</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> pickle\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">demo</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>)\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    strs = <span class="hljs-string">""</span>\n'
             '    num = <span class="hljs-number">123</span>\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    pickle.dump(lists, f) <span class="hljs-comment"># '
             '</span>\n'
             '    pickle.dump(strs, f)\n'
             '    pickle.dump(num, f)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    f.close()\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"rb+"</span>)\n'
             '\n'
             '    <span class="hljs-comment"># </span>\n'
             '    data = pickle.load(f) <span class="hljs-comment"># '
             '</span>\n'
             '    <span class="hljs-keyword">print</span> (data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '    data = pickle.load(f)\n'
             '    print(data)\n'
             '\n'
             '    f.close()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">pickle_funs</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    lists = [<span class="hljs-number">123</span>, <span '
             'class="hljs-string">""</span>, [<span '
             'class="hljs-number">456</span>]]\n'
             '    f = open(<span class="hljs-string">"pickle.txt"</span>, '
             '<span class="hljs-string">"wb+"</span>) <span '
             'class="hljs-comment"># (:wb+)</span>\n'
             '\n'
             '    num = pickle.HIGHEST_PROTOCOL <span class="hljs-comment"># '
             '(4)</span>\n'
             '    num = pickle.DEFAULT_PROTOCOL <span class="hljs-comment"># '
             '(3) {3:bytes; 4:}</span>\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># dump(obj, file, protocol=None, '
             '*, fix_imports=True) // obj</span>\n'
             '    pickle.dump(lists, f)\n'
             '    <span class="hljs-comment"># dumps(obj, protocol=None, *, '
             'fix_imports=True) // objbytes</span>\n'
             '    bytes = pickle.dumps(lists)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-comment"># load(file, *, fix_imports=True, '
             'encoding="ASCII", errors="strict") // fileobj</span>\n'
             '    lists = pickle.load(f)\n'
             '    <span class="hljs-comment"># loads(bytes_object, *, '
             'fix_imports=True, encoding="ASCII", errors="strict") // '
             'bytesobj</span>\n'
             '    lists = pickle.loads(bytes)\n'
             '\n'
             '    <span class="hljs-comment"># ---  ---</span>\n'
             '    <span class="hljs-keyword">try</span>:\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.PicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> '
             'pickle.UnpicklingError: <span class="hljs-comment"># '
             '</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '    <span class="hljs-keyword">except</span> pickle.PickleError: '
             '<span class="hljs-comment"># pickling</span>\n'
             '        <span class="hljs-keyword">pass</span>\n'
             '\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    demo()\n'
             '    pickle_funs()\n'
             '<div class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li><li style="color: '
             'rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, '
             '153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li '
             'style="color: rgb(153, 153, 153);">50</li><li style="color: '
             'rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, '
             '153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li '
             'style="color: rgb(153, 153, 153);">54</li><li style="color: '
             'rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, '
             '153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li '
             'style="color: rgb(153, 153, 153);">58</li><li style="color: '
             'rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, '
             '153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li '
             'style="color: rgb(153, 153, 153);">62</li><li style="color: '
             'rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, '
             '153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li '
             'style="color: rgb(153, 153, 153);">66</li><li style="color: '
             'rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, '
             '153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li '
             'style="color: rgb(153, 153, 153);">70</li><li style="color: '
             'rgb(153, 153, 153);">71</li></ul>\n'
             '\n'
             '\n'
             '\n'
             '<h2 id="shelve"><a name="t2"></a>shelve</h2>\n'
             '\n'
             '\n'
             '\n'
             '<pre class="prettyprint" name="code"><code '
             'class="language-python hljs  has-numbering" '
             'onclick="mdcp.signin(event)" style="position: unset;"><span '
             'class="hljs-comment">#!/usr/bin/env python</span>\n'
             '<span class="hljs-comment"># coding=utf-8</span>\n'
             '__author__ = <span class="hljs-string">\'Luzhuo\'</span>\n'
             '__date__ = <span class="hljs-string">\'2017/5/26\'</span>\n'
             '<span class="hljs-comment"># shelve_demo.py '
             ':Python</span>\n'
             '<span class="hljs-comment"># , , '
             'picklePython</span>\n'
             '<span class="hljs-comment"># pickle, '
             '</span>\n'
             '\n'
             '<span class="hljs-keyword">import</span> shelve\n'
             '\n'
             '\n'
             '<span class="hljs-class"><span class="hljs-keyword">class</span> '
             '<span class="hljs-title">Person</span><span '
             'class="hljs-params">(object)</span>:</span>\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__init__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        self.name = <span class="hljs-string">"luzhuo"</span>\n'
             '        self.age = <span class="hljs-number">21</span>\n'
             '\n'
             '    <span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">__str__</span><span '
             'class="hljs-params">(self)</span>:</span>\n'
             '        <span class="hljs-keyword">return</span> <span '
             'class="hljs-string">"name: {}, age: {}"</span>.format(self.name, '
             'self.age)\n'
             '\n'
             'path = <span class="hljs-string">"file.txt"</span>\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_write</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> write: <span '
             'class="hljs-comment"># </span>\n'
             '        write[<span class="hljs-string">"nums"</span>] = [<span '
             'class="hljs-number">1</span>, <span '
             'class="hljs-number">2</span>, <span '
             'class="hljs-number">3</span>, <span '
             'class="hljs-number">4</span>, <span '
             'class="hljs-number">5</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        write[<span class="hljs-string">"obj"</span>] = '
             'Person()\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_read</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-string">\'\'\'\n'
             '    \n'
             "    '''</span>\n"
             '\n'
             '    <span class="hljs-keyword">with</span> shelve.open(path) '
             '<span class="hljs-keyword">as</span> read:  <span '
             'class="hljs-comment"># </span>\n'
             '        nums = read.get(<span '
             'class="hljs-string">"nums"</span>)  <span class="hljs-comment"># '
             '</span>\n'
             '        print(nums)\n'
             '        clazz = read[<span class="hljs-string">"obj"</span>]\n'
             '        print(clazz)\n'
             '\n'
             '        <span class="hljs-keyword">del</span> read[<span '
             'class="hljs-string">"obj"</span>]  <span class="hljs-comment"># '
             '</span>\n'
             '        print(<span class="hljs-string">"obj"</span> <span '
             'class="hljs-keyword">in</span> read)\n'
             '\n'
             '        keys = list(read.keys())  <span class="hljs-comment"># '
             'key</span>\n'
             '        print(keys)\n'
             '\n'
             '\n'
             '<span class="hljs-function"><span '
             'class="hljs-keyword">def</span> <span '
             'class="hljs-title">shelve_func</span><span '
             'class="hljs-params">()</span>:</span>\n'
             '    <span class="hljs-comment"># , filename:, '
             'writeback:(True,), Shelf</span>\n'
             '    <span class="hljs-comment"># shelve.open(filename, '
             "flag='c', protocol=None, writeback=False)</span>\n"
             '    d = shelve.open(path)\n'
             '\n'
             '    <span class="hljs-comment"># Shelf</span>\n'
             '    <span class="hljs-comment"># </span>\n'
             '    <span class="hljs-comment"># get(self, key, default=None) // '
             ' == data = shelf["key"]</span>\n'
             '    data = d.get(<span class="hljs-string">"key"</span>)\n'
             '    d.sync()  <span class="hljs-comment"># (,)</span>\n'
             '    d.close()  <span class="hljs-comment"># </span>\n'
             '\n'
             '\n'
             '    <span class="hljs-comment"># class shelve.Shelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8')</span>\n"
             '    <span class="hljs-comment"># class shelve.BsdDbShelf(dict, '
             "protocol=None, writeback=False, keyencoding='utf-8') // "
             'Shelf</span>\n'
             '    <span class="hljs-comment"># class '
             "shelve.DbfilenameShelf(filename, flag='c', protocol=None, "
             'writeback=False) // Shelf</span>\n'
             '\n'
             '\n'
             '<span class="hljs-keyword">if</span> __name__ == <span '
             'class="hljs-string">"__main__"</span>:\n'
             '    shelve_write()\n'
             '    shelve_read()\n'
             '\n'
             '    <span class="hljs-comment"># shelve_func()</span><div '
             'class="hljs-button signin" '
             'data-title=""></div></code></pre><ul class="pre-numbering" '
             'style=""><li style="color: rgb(153, 153, 153);">1</li><li '
             'style="color: rgb(153, 153, 153);">2</li><li style="color: '
             'rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, '
             '153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li '
             'style="color: rgb(153, 153, 153);">6</li><li style="color: '
             'rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, '
             '153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li '
             'style="color: rgb(153, 153, 153);">10</li><li style="color: '
             'rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, '
             '153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li '
             'style="color: rgb(153, 153, 153);">14</li><li style="color: '
             'rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, '
             '153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li '
             'style="color: rgb(153, 153, 153);">18</li><li style="color: '
             'rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, '
             '153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li '
             'style="color: rgb(153, 153, 153);">22</li><li style="color: '
             'rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, '
             '153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li '
             'style="color: rgb(153, 153, 153);">26</li><li style="color: '
             'rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, '
             '153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li '
             'style="color: rgb(153, 153, 153);">30</li><li style="color: '
             'rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, '
             '153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li '
             'style="color: rgb(153, 153, 153);">34</li><li style="color: '
             'rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, '
             '153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li '
             'style="color: rgb(153, 153, 153);">38</li><li style="color: '
             'rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, '
             '153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li '
             'style="color: rgb(153, 153, 153);">42</li><li style="color: '
             'rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, '
             '153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li '
             'style="color: rgb(153, 153, 153);">46</li><li style="color: '
             'rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, '
             '153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li '
             'style="color: rgb(153, 153, 153);">50</li><li style="color: '
             'rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, '
             '153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li '
             'style="color: rgb(153, 153, 153);">54</li><li style="color: '
             'rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, '
             '153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li '
             'style="color: rgb(153, 153, 153);">58</li><li style="color: '
             'rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, '
             '153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li '
             'style="color: rgb(153, 153, 153);">62</li><li style="color: '
             'rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, '
             '153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li '
             'style="color: rgb(153, 153, 153);">66</li><li style="color: '
             'rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, '
             '153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li '
             'style="color: rgb(153, 153, 153);">70</li><li style="color: '
             'rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, '
             '153);">72</li><li style="color: rgb(153, 153, '
             '153);">73</li></ul>                                    </div>\n'
             '                <link '
             'href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-e9f16cbbc2.css" '
             'rel="stylesheet">\n'
             '                    </div>\n'
             '    </article>'],
 'title': ['Python3 Python(pickle / shelve)']}
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 15, in process_item
    path = downloader.create_Folder(article['title'][0]) + '\\'
TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 17 items (at 1 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 3 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 17 items (at 2 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 4 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 1 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 15:13:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 13 items (at 2 items/min)
2019-11-01 15:14:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:14:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 14525900,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 14, 12, 24176),
 'item_scraped_count': 13,
 'log_count/ERROR': 11,
 'log_count/INFO': 109,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 17,
 'scheduler/dequeued': 17,
 'scheduler/dequeued/memory': 17,
 'scheduler/enqueued': 17,
 'scheduler/enqueued/memory': 17,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 340993)}
2019-11-01 15:14:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:15:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:15:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21130572,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 15, 19, 592070),
 'item_scraped_count': 21,
 'log_count/ERROR': 11,
 'log_count/INFO': 172,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 2960)}
2019-11-01 15:15:19 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 3 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 20 items (at 4 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 0 pages/min), scraped 22 items (at 5 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 18 items (at 2 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 5 pages/min), scraped 17 items (at 0 items/min)
2019-11-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:15:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21366316,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 15, 49, 438776),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 202,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 49, 941970)}
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:15:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21895462,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 15, 49, 443778),
 'item_scraped_count': 22,
 'log_count/ERROR': 11,
 'log_count/INFO': 165,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 101968)}
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:15:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21359067,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 15, 49, 447791),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 198,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 49, 973958)}
2019-11-01 15:15:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:16:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:16:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 21404612,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 24,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 16, 25, 544893),
 'item_scraped_count': 20,
 'log_count/ERROR': 11,
 'log_count/INFO': 141,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 24,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 303977)}
2019-11-01 15:16:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:16:25 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 18 items (at 1 items/min)
2019-11-01 15:16:25 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 2 pages/min), scraped 22 items (at 4 items/min)
2019-11-01 15:16:25 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 1 pages/min), scraped 23 items (at 6 items/min)
2019-11-01 15:16:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:16:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 18008254,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 16, 25, 574884),
 'item_scraped_count': 18,
 'log_count/ERROR': 11,
 'log_count/INFO': 187,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 59965)}
2019-11-01 15:16:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:17:40 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 1 pages/min), scraped 24 items (at 2 items/min)
2019-11-01 15:17:40 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 5 pages/min), scraped 23 items (at 0 items/min)
2019-11-01 15:17:51 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 24 items (at 0 items/min)
2019-11-01 15:17:51 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 29 items (at 6 items/min)
2019-11-01 15:18:42 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:18:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 24112413,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 18, 42, 222951),
 'item_scraped_count': 25,
 'log_count/ERROR': 11,
 'log_count/INFO': 174,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 143971)}
2019-11-01 15:18:42 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:19:03 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 6 pages/min), scraped 34 items (at 5 items/min)
2019-11-01 15:20:21 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 6 pages/min), scraped 35 items (at 1 items/min)
2019-11-01 15:21:26 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 5 pages/min), scraped 41 items (at 6 items/min)
2019-11-01 15:21:56 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 1 pages/min), scraped 46 items (at 5 items/min)
2019-11-01 15:22:38 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-01 15:22:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 48952263,
 'downloader/response_count': 55,
 'downloader/response_status_count/200': 55,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 1, 7, 22, 38, 133413),
 'item_scraped_count': 51,
 'log_count/ERROR': 11,
 'log_count/INFO': 171,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 55,
 'scheduler/dequeued': 55,
 'scheduler/dequeued/memory': 55,
 'scheduler/enqueued': 55,
 'scheduler/enqueued/memory': 55,
 'start_time': datetime.datetime(2019, 11, 1, 6, 25, 50, 262988)}
2019-11-01 15:22:38 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-01 15:27:30 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 15:27:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 15:29:02 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 15:29:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 17:09:08 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-01 17:09:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-01 17:09:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:08 [scrapy.extensions.telnet] INFO: Telnet Password: d0135112e9d2feb6
2019-11-01 17:09:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:16 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:16 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:16 [C_spider] INFO: Spider opened: C_spider
2019-11-01 17:09:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-01 17:09:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:16 [scrapy.extensions.telnet] INFO: Telnet Password: 1d9a92e4f1c73c7b
2019-11-01 17:09:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 7ab156ac29a5c71f
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: bed99faf32a1e82f
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 3d11bf192c15f777
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [golang_spider] INFO: Spider opened: golang_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: ea013ad0ca2ca558
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [html_spider] INFO: Spider opened: html_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 59bf8be78fc9dff6
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [java_spider] INFO: Spider opened: java_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: af96e82b5a30e886
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [js_spider] INFO: Spider opened: js_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 2d778764be489504
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [php_spider] INFO: Spider opened: php_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 139536ffb28cc725
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [python_spider] INFO: Spider opened: python_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-01 17:09:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet Password: 14d81317cefbf18e
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-01 17:09:17 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-01 17:09:17 [scrapy.core.engine] INFO: Spider opened
2019-11-01 17:09:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-01 17:09:17 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-01 17:09:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-01 17:10:09 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:09 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-11-01 17:10:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://so.csdn.net/so/search/s.do?p=1&q=%E5%B0%8F%E7%A8%8B%E5%BA%8F&t=&viparticle=&domain=&o=&s=&u=&l=>
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 383, in _make_request
    httplib_response = conn.getresponse()
  File "d:\programdata\anaconda3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "d:\programdata\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "d:\programdata\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "d:\programdata\anaconda3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\middlewares.py", line 101, in process_request
    driver.get(request.url)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "d:\programdata\anaconda3\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 70, in request
    **urlopen_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\request.py", line 148, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\poolmanager.py", line 321, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\util\retry.py", line 357, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\packages\six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "d:\programdata\anaconda3\lib\site-packages\urllib3\connectionpool.py", line 383, in _make_request
    httplib_response = conn.getresponse()
  File "d:\programdata\anaconda3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "d:\programdata\anaconda3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "d:\programdata\anaconda3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "d:\programdata\anaconda3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '', None, 10054, None))
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 137572,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 716392),
 'log_count/ERROR': 1,
 'log_count/INFO': 101,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 60196)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 137770,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 728393),
 'log_count/ERROR': 1,
 'log_count/INFO': 93,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 107198)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 149746,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 796396),
 'log_count/ERROR': 1,
 'log_count/INFO': 35,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 481220)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 127722,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 804396),
 'log_count/ERROR': 1,
 'log_count/INFO': 127,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 16, 952189)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 133533,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 812397),
 'log_count/ERROR': 1,
 'log_count/INFO': 119,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 3192)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 133525,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 818397),
 'log_count/ERROR': 1,
 'log_count/INFO': 91,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 153215)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 148720,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 840399),
 'log_count/ERROR': 1,
 'log_count/INFO': 73,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 333223)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 134395,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 853399),
 'log_count/ERROR': 1,
 'log_count/INFO': 65,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 372213)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/urllib3.exceptions.ProtocolError': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 866401),
 'log_count/ERROR': 1,
 'log_count/INFO': 37,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 531222)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 132570,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 873402),
 'log_count/ERROR': 1,
 'log_count/INFO': 89,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 15,
 'scheduler/enqueued/memory': 15,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 208205)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-01 17:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 126657,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 11, 1, 9, 10, 10, 911404),
 'log_count/ERROR': 1,
 'log_count/INFO': 61,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2019, 11, 1, 9, 9, 17, 427217)}
2019-11-01 17:10:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-11-04 14:15:47 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 14:15:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 14:15:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:47 [scrapy.extensions.telnet] INFO: Telnet Password: ada25f0da5415ed2
2019-11-04 14:15:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [C_spider] INFO: Spider opened: C_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: d78c07b68d0d1c07
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: ced191e4fb952237
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: 025765d1dfbefbf8
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: cfe8504af64b625e
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [golang_spider] INFO: Spider opened: golang_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: 94b83f6ac7a3e99b
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [html_spider] INFO: Spider opened: html_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: 098c85156945cb5a
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [java_spider] INFO: Spider opened: java_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: 34a5f03226124c4c
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [js_spider] INFO: Spider opened: js_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: bef752f9f96ce4da
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:53 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:53 [php_spider] INFO: Spider opened: php_spider
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-04 14:15:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:53 [scrapy.extensions.telnet] INFO: Telnet Password: 025f91f5ca53c067
2019-11-04 14:15:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:54 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:54 [python_spider] INFO: Spider opened: python_spider
2019-11-04 14:15:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-04 14:15:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:15:54 [scrapy.extensions.telnet] INFO: Telnet Password: 9c067df78b26170d
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:15:54 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:15:54 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:15:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:15:54 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-04 14:15:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-04 14:17:35 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-11-04 14:17:38 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000239C536E2B0>: Failed to establish a new connection: [WinError 10061] ',)': /session/9ef9c1e2c2e2426e2ba7dc8f548500fa/element
2019-11-04 14:19:09 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 14:19:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 14:19:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:09 [scrapy.extensions.telnet] INFO: Telnet Password: 74887bb63077d7bb
2019-11-04 14:19:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [C_spider] INFO: Spider opened: C_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 4c766a54126afbf2
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 6d4dd11764365029
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: e9cd52229df8f8a5
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 7e640f37b09448c6
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [golang_spider] INFO: Spider opened: golang_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 5a67d293b3f22299
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [html_spider] INFO: Spider opened: html_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 2b92b2f9be4f39b7
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [java_spider] INFO: Spider opened: java_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 52b755475f536927
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [js_spider] INFO: Spider opened: js_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 829827f62620b05c
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [php_spider] INFO: Spider opened: php_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 30ca3ac09e944d5a
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [python_spider] INFO: Spider opened: python_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-04 14:19:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet Password: 848d0ee9413776f5
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:19:13 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:19:13 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:19:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:19:13 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-04 14:19:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:20:59 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:23:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:27 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 14:30:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 14:30:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:27 [scrapy.extensions.telnet] INFO: Telnet Password: ea08e5636f3936e8
2019-11-04 14:30:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [C_spider] INFO: Spider opened: C_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: 4d9b92eef38899bd
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: e060affaa3e66f7f
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: b8a0db1e4caae01c
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: 57aa476a710db816
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [golang_spider] INFO: Spider opened: golang_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: 18786662c97fcb93
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:31 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:31 [html_spider] INFO: Spider opened: html_spider
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-04 14:30:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:31 [scrapy.extensions.telnet] INFO: Telnet Password: e619d7e78408c634
2019-11-04 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:32 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:32 [java_spider] INFO: Spider opened: java_spider
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-04 14:30:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet Password: 0a72b228da9ee7de
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:32 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:32 [js_spider] INFO: Spider opened: js_spider
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-04 14:30:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet Password: cb6d699f19450649
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:32 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:32 [php_spider] INFO: Spider opened: php_spider
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-04 14:30:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet Password: 0c46eac493695980
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:32 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:32 [python_spider] INFO: Spider opened: python_spider
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-04 14:30:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet Password: 78ec75d200a58108
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:30:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:30:32 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:30:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:30:32 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-04 14:30:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:32:16 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:14 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:22 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 14:40:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 14:40:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:40:22 [scrapy.extensions.telnet] INFO: Telnet Password: f1d1f46705fb1ef9
2019-11-04 14:40:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:40:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:40:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:40:26 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:40:26 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:40:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:40:26 [python_spider] INFO: Spider opened: python_spider
2019-11-04 14:40:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 14:42:26 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 14:42:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 14:42:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 14:42:26 [scrapy.extensions.telnet] INFO: Telnet Password: 065e962efabb8835
2019-11-04 14:42:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 14:42:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 14:42:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 14:42:27 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 14:42:27 [scrapy.core.engine] INFO: Spider opened
2019-11-04 14:42:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:42:27 [python_spider] INFO: Spider opened: python_spider
2019-11-04 14:42:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 14:44:38 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 14:44:57 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-04 14:46:18 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 5 pages/min), scraped 5 items (at 5 items/min)
2019-11-04 14:46:48 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 14:48:37 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 11 items (at 6 items/min)
2019-11-04 14:50:43 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 6 pages/min), scraped 17 items (at 6 items/min)
2019-11-04 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 6 pages/min), scraped 23 items (at 6 items/min)
2019-11-04 14:54:27 [scrapy.extensions.logstats] INFO: Crawled 40 pages (at 6 pages/min), scraped 29 items (at 6 items/min)
2019-11-04 14:57:23 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 6 pages/min), scraped 35 items (at 6 items/min)
2019-11-04 14:57:33 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 0 pages/min), scraped 40 items (at 5 items/min)
2019-11-04 14:59:34 [scrapy.extensions.logstats] INFO: Crawled 52 pages (at 6 pages/min), scraped 41 items (at 1 items/min)
2019-11-04 15:01:30 [scrapy.extensions.logstats] INFO: Crawled 58 pages (at 6 pages/min), scraped 47 items (at 6 items/min)
2019-11-04 15:03:36 [scrapy.extensions.logstats] INFO: Crawled 64 pages (at 6 pages/min), scraped 53 items (at 6 items/min)
2019-11-04 15:04:55 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 5 pages/min), scraped 59 items (at 6 items/min)
2019-11-04 15:05:56 [scrapy.extensions.logstats] INFO: Crawled 73 pages (at 4 pages/min), scraped 59 items (at 0 items/min)
2019-11-04 15:07:24 [scrapy.extensions.logstats] INFO: Crawled 78 pages (at 5 pages/min), scraped 64 items (at 5 items/min)
2019-11-04 15:07:43 [scrapy.extensions.logstats] INFO: Crawled 79 pages (at 1 pages/min), scraped 65 items (at 1 items/min)
2019-11-04 15:09:37 [scrapy.extensions.logstats] INFO: Crawled 85 pages (at 6 pages/min), scraped 70 items (at 5 items/min)
2019-11-04 15:11:38 [scrapy.extensions.logstats] INFO: Crawled 91 pages (at 6 pages/min), scraped 76 items (at 6 items/min)
2019-11-04 15:13:50 [scrapy.extensions.logstats] INFO: Crawled 97 pages (at 6 pages/min), scraped 82 items (at 6 items/min)
2019-11-04 15:19:49 [scrapy.extensions.logstats] INFO: Crawled 103 pages (at 6 pages/min), scraped 88 items (at 6 items/min)
2019-11-04 15:21:38 [scrapy.extensions.logstats] INFO: Crawled 108 pages (at 5 pages/min), scraped 94 items (at 6 items/min)
2019-11-04 15:23:54 [scrapy.extensions.logstats] INFO: Crawled 115 pages (at 7 pages/min), scraped 100 items (at 6 items/min)
2019-11-04 15:24:45 [scrapy.extensions.logstats] INFO: Crawled 117 pages (at 2 pages/min), scraped 106 items (at 6 items/min)
2019-11-04 15:26:29 [scrapy.extensions.logstats] INFO: Crawled 123 pages (at 6 pages/min), scraped 107 items (at 1 items/min)
2019-11-04 15:27:48 [scrapy.extensions.logstats] INFO: Crawled 127 pages (at 4 pages/min), scraped 113 items (at 6 items/min)
2019-11-04 15:27:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-04 15:27:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 112910946,
 'downloader/response_count': 127,
 'downloader/response_status_count/200': 127,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 4, 7, 27, 56, 735127),
 'item_scraped_count': 117,
 'log_count/INFO': 35,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 127,
 'scheduler/dequeued': 127,
 'scheduler/dequeued/memory': 127,
 'scheduler/enqueued': 127,
 'scheduler/enqueued/memory': 127,
 'start_time': datetime.datetime(2019, 11, 4, 6, 42, 27, 352915)}
2019-11-04 15:27:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-04 15:37:42 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-04 15:37:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-04 15:37:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:42 [scrapy.extensions.telnet] INFO: Telnet Password: 35366b7edda3e864
2019-11-04 15:37:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [C_spider] INFO: Spider opened: C_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: 0837071c30820293
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: 9ed452ef86a91b66
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: bd9a68750003e696
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: 578acf66d01905e4
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [golang_spider] INFO: Spider opened: golang_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: d1fae6910a615768
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [html_spider] INFO: Spider opened: html_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-04 15:37:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet Password: af811f41ef619389
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:45 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:45 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:45 [java_spider] INFO: Spider opened: java_spider
2019-11-04 15:37:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-04 15:37:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet Password: d4f823abe6b70c8c
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:46 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:46 [js_spider] INFO: Spider opened: js_spider
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-04 15:37:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet Password: 4349c00b3f484a12
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:46 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:46 [php_spider] INFO: Spider opened: php_spider
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-04 15:37:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet Password: 874bbea2bd582b0d
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:46 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:46 [python_spider] INFO: Spider opened: python_spider
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-04 15:37:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet Password: 26d20d5f70a3553e
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-04 15:37:46 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-04 15:37:46 [scrapy.core.engine] INFO: Spider opened
2019-11-04 15:37:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:37:46 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-04 15:37:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:44 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:40:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:43:17 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:44:27 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:44:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:44:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:44:27 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:47:38 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:49:54 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:49:54 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:49:54 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:49:54 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 15:58:01 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:04:35 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:04:35 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:04:35 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:04:35 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:04:52 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:05:00 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-04 16:05:28 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:28 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:28 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:05:28 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 5 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 5 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 5 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 4 items (at 3 items/min)
2019-11-04 16:12:37 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 5 items (at 4 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 3 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 5 pages/min), scraped 5 items (at 1 items/min)
2019-11-04 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 10 items (at 4 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 6 items (at 1 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 7 items (at 2 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 7 items (at 2 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 7 items (at 2 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 6 items (at 1 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 6 items (at 1 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 1 pages/min), scraped 7 items (at 2 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 6 items (at 1 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 5 items (at 0 items/min)
2019-11-04 16:28:49 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 2 pages/min), scraped 7 items (at 2 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 12 items (at 2 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 5 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 4 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 4 pages/min), scraped 11 items (at 4 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 4 pages/min), scraped 11 items (at 4 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 5 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 5 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 4 pages/min), scraped 10 items (at 3 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 5 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 10 items (at 5 items/min)
2019-11-04 16:38:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 0 pages/min), scraped 9 items (at 2 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 12 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 10 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 11 items (at 1 items/min)
2019-11-04 16:48:38 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 11 items (at 2 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 1 pages/min), scraped 12 items (at 0 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 14 items (at 3 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 14 items (at 3 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 15 items (at 4 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 15 items (at 4 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 14 items (at 3 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 14 items (at 3 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 4 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 14 items (at 3 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:51:06 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 11 items (at 0 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 0 pages/min), scraped 17 items (at 5 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 3 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 3 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 2 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 2 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 3 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 3 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 2 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 2 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 1 pages/min), scraped 16 items (at 5 items/min)
2019-11-04 16:52:38 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 17 items (at 6 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 5 pages/min), scraped 18 items (at 1 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 16 items (at 0 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 4 pages/min), scraped 17 items (at 1 items/min)
2019-11-04 17:06:26 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 1 pages/min), scraped 18 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 16 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 2 pages/min), scraped 16 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 2 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 3 pages/min), scraped 17 items (at 0 items/min)
2019-11-04 17:16:50 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 23 items (at 5 items/min)
2019-11-04 17:16:50 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 21 items (at 4 items/min)
2019-11-04 17:16:52 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 20 items (at 3 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 23 items (at 6 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 21 items (at 4 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 22 items (at 5 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 3 pages/min), scraped 20 items (at 3 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 2 pages/min), scraped 20 items (at 4 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 0 pages/min), scraped 20 items (at 4 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 0 pages/min), scraped 21 items (at 4 items/min)
2019-11-04 17:16:59 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 0 pages/min), scraped 20 items (at 3 items/min)
2019-11-06 16:00:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:00:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:00:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:00:05 [scrapy.extensions.telnet] INFO: Telnet Password: 10f27a41d7ea9bbc
2019-11-06 16:00:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:00:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:00:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:00:12 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:00:12 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:00:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:00:13 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:00:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:01:34 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:02:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:02:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:02:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:02:05 [scrapy.extensions.telnet] INFO: Telnet Password: f0e52e8a190f736a
2019-11-06 16:02:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:02:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:02:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:02:09 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:02:09 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:02:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:02:10 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:02:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:02:54 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:02:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1070478,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 2, 54, 607327),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 2, 10, 8457)}
2019-11-06 16:02:54 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:03:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:03:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:03:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:03:23 [scrapy.extensions.telnet] INFO: Telnet Password: 5ff30b6c580f85c3
2019-11-06 16:03:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:03:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:03:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:03:28 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:03:28 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:03:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:03:28 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:03:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:04:14 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:04:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1070484,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 4, 14, 638466),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 3, 28, 158935)}
2019-11-06 16:04:14 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:05:05 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:05:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:05:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:05:05 [scrapy.extensions.telnet] INFO: Telnet Password: 5674dd79898a62cf
2019-11-06 16:05:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:05:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:05:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:05:10 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:05:10 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:05:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:05:10 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:05:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:06:13 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-06 16:06:13 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:06:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1051739,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 6, 13, 459608),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 5, 10, 942955)}
2019-11-06 16:06:13 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:07:29 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:07:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:07:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:07:29 [scrapy.extensions.telnet] INFO: Telnet Password: b8bbbdc146aa7683
2019-11-06 16:07:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:07:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:07:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:07:34 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:07:34 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:07:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:07:34 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:07:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:08:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:08:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1050345,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 8, 17, 537980),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 7, 34, 361464)}
2019-11-06 16:08:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:10:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:10:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:10:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:10:53 [scrapy.extensions.telnet] INFO: Telnet Password: 6779de2694add53c
2019-11-06 16:10:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:10:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:10:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:10:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:10:58 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:10:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:10:58 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:10:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:11:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:11:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1052636,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 11, 30, 917810),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 10, 58, 310047)}
2019-11-06 16:11:30 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:13:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:13:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:13:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:13:52 [scrapy.extensions.telnet] INFO: Telnet Password: a92f0fceb67955f2
2019-11-06 16:13:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:13:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:13:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:13:57 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:13:57 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:13:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:13:57 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:13:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:14:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:14:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1070462,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 14, 29, 691843),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 13, 57, 803004)}
2019-11-06 16:14:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:15:39 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:15:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:15:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:15:39 [scrapy.extensions.telnet] INFO: Telnet Password: 5de7456fea8b33d4
2019-11-06 16:15:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:15:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:15:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:15:44 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:15:44 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:15:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:15:44 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:15:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:16:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:16:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1071324,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 16, 17, 289619),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 15, 44, 890237)}
2019-11-06 16:16:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:17:07 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:17:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:17:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:17:07 [scrapy.extensions.telnet] INFO: Telnet Password: 35af673f81d514d2
2019-11-06 16:17:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:17:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:17:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:17:14 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:17:14 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:17:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:17:14 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:17:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:17:47 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:17:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1071834,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 17, 47, 234571),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 17, 14, 68616)}
2019-11-06 16:17:47 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:17:56 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:17:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:17:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:17:56 [scrapy.extensions.telnet] INFO: Telnet Password: eac894b6f39302fb
2019-11-06 16:17:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:17:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:17:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:18:01 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:18:01 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:18:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:18:01 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:18:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:18:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:18:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1052862,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 18, 34, 279888),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 18, 1, 345743)}
2019-11-06 16:18:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:19:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:19:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:19:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:19:46 [scrapy.extensions.telnet] INFO: Telnet Password: fd34295677bc7840
2019-11-06 16:19:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:19:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:19:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:19:51 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:19:51 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:19:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:19:51 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:19:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:20:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:20:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1117804,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 20, 25, 761386),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 19, 51, 661982)}
2019-11-06 16:20:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:21:54 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:21:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:21:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:21:54 [scrapy.extensions.telnet] INFO: Telnet Password: a11ca92f05fdfdd9
2019-11-06 16:21:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:21:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:21:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:21:58 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:21:58 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:21:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:21:58 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:21:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:22:33 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:22:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1136388,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 22, 33, 527684),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 21, 58, 956001)}
2019-11-06 16:22:33 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:24:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:24:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:24:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:24:17 [scrapy.extensions.telnet] INFO: Telnet Password: b48363ee848ee943
2019-11-06 16:24:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:24:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:24:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:24:22 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:24:22 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:24:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:24:22 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:24:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:24:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:24:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1117424,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 24, 57, 404501),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 24, 22, 281047)}
2019-11-06 16:24:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:26:17 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:26:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:26:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:26:17 [scrapy.extensions.telnet] INFO: Telnet Password: 5e388194b1aacdca
2019-11-06 16:26:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:26:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:26:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:26:23 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:26:23 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:26:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:26:23 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:26:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:26:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:26:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1042136,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 26, 55, 572815),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 26, 23, 184548)}
2019-11-06 16:26:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:28:48 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:28:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:28:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:28:48 [scrapy.extensions.telnet] INFO: Telnet Password: 14b2d513772c68f1
2019-11-06 16:28:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:28:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:28:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:28:53 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:28:53 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:28:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:28:53 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:28:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:29:31 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:29:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1059866,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 29, 31, 492598),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 28, 53, 644674)}
2019-11-06 16:29:31 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:37:54 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:37:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:37:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:37:54 [scrapy.extensions.telnet] INFO: Telnet Password: e1fe548bd5ddd655
2019-11-06 16:37:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:37:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:37:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:37:59 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:37:59 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:37:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:37:59 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:37:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:38:40 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-06 16:38:41 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:38:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1060291,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 38, 41, 130643),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 37, 59, 950465)}
2019-11-06 16:38:41 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:41:19 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:41:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:41:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:41:19 [scrapy.extensions.telnet] INFO: Telnet Password: b0bc62f936613f3b
2019-11-06 16:41:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:41:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:41:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:41:31 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:41:31 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:41:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:41:31 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:41:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:43:10 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:43:11 [py.warnings] WARNING: d:\programdata\anaconda3\lib\site-packages\pymysql\cursors.py:170: Warning: (3719, "'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.")
  result = self._query(query)

2019-11-06 16:43:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:43:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1075526,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 43, 12, 131681),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 41, 31, 380781)}
2019-11-06 16:43:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:44:52 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:44:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:44:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:44:52 [scrapy.extensions.telnet] INFO: Telnet Password: 69e112096dc783cb
2019-11-06 16:44:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:44:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:44:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:45:05 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:45:05 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:45:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:45:05 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:45:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:47:05 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:47:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:47:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1061849,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 47, 16, 47525),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 45, 5, 137663)}
2019-11-06 16:47:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:51:34 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:51:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:51:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:51:35 [scrapy.extensions.telnet] INFO: Telnet Password: 29740a0a935583dc
2019-11-06 16:51:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:51:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:51:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:51:47 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:51:47 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:51:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:51:47 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:51:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:53:41 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:53:45 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:53:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1058589,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 53, 45, 755216),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 51, 47, 934372)}
2019-11-06 16:53:45 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 16:57:02 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 16:57:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 16:57:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 16:57:02 [scrapy.extensions.telnet] INFO: Telnet Password: ac0893aca10f53a4
2019-11-06 16:57:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 16:57:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 16:57:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 16:57:20 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 16:57:20 [scrapy.core.engine] INFO: Spider opened
2019-11-06 16:57:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:57:20 [java_spider] INFO: Spider opened: java_spider
2019-11-06 16:57:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 16:58:56 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 16:58:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 16:58:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1061314,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 8, 58, 57, 303648),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 8, 57, 20, 81954)}
2019-11-06 16:58:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 17:10:19 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:10:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:10:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:10:20 [scrapy.extensions.telnet] INFO: Telnet Password: 17c789fdb112665c
2019-11-06 17:10:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:10:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:10:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:10:32 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 17:10:32 [scrapy.core.engine] INFO: Spider opened
2019-11-06 17:10:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:10:32 [java_spider] INFO: Spider opened: java_spider
2019-11-06 17:10:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 17:12:21 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:12:34 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-06 17:12:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 17:12:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1041356,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 9, 12, 34, 289559),
 'item_scraped_count': 1,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 9, 10, 32, 932313)}
2019-11-06 17:12:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 17:14:55 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:14:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:14:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:14:55 [scrapy.extensions.telnet] INFO: Telnet Password: 9a057b47d1bd37c4
2019-11-06 17:14:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:14:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:14:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:15:05 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 17:15:05 [scrapy.core.engine] INFO: Spider opened
2019-11-06 17:15:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:15:05 [java_spider] INFO: Spider opened: java_spider
2019-11-06 17:15:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 17:17:01 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:17:10 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-06 17:17:10 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 17:17:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1061128,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 9, 17, 10, 774016),
 'item_scraped_count': 1,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 9, 15, 5, 304461)}
2019-11-06 17:17:10 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 17:18:02 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:18:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:18:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:18:03 [scrapy.extensions.telnet] INFO: Telnet Password: ae3b2d864a432b79
2019-11-06 17:18:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:18:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:18:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:18:05 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-06 17:18:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "d:\programdata\anaconda3\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 53
    ArticleContent.Aid = articlecontent.Aid,
    ^
SyntaxError: keyword can't be an expression
2019-11-06 17:18:40 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:18:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:18:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:18:40 [scrapy.extensions.telnet] INFO: Telnet Password: ce18f4f3685e527d
2019-11-06 17:18:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:18:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:18:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:18:42 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-06 17:18:42 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "d:\programdata\anaconda3\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 53
    ArticleContent.Aid = articlecontent.Aid,
    ^
SyntaxError: keyword can't be an expression
2019-11-06 17:18:59 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:18:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:18:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:18:59 [scrapy.extensions.telnet] INFO: Telnet Password: 18a93c1782db4da2
2019-11-06 17:18:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:19:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:19:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:19:01 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-06 17:19:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "d:\programdata\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "d:\programdata\anaconda3\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "d:\programdata\anaconda3\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "D:\webCrawler_bishe\csdn_crawler\csdn_crawler\pipelines.py", line 53
    ArticleWord.Aid = articlecontent.Aid,
    ^
SyntaxError: keyword can't be an expression
2019-11-06 17:19:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:19:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:19:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:19:52 [scrapy.extensions.telnet] INFO: Telnet Password: 2b2844938be1501a
2019-11-06 17:19:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:19:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:19:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:20:01 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 17:20:01 [scrapy.core.engine] INFO: Spider opened
2019-11-06 17:20:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:20:02 [java_spider] INFO: Spider opened: java_spider
2019-11-06 17:20:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 17:22:03 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:22:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 17:22:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1042445,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 9, 22, 12, 227164),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 9, 20, 2, 18047)}
2019-11-06 17:22:12 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-06 17:22:50 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:22:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:22:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:22:50 [scrapy.extensions.telnet] INFO: Telnet Password: 24769dc25ea2c80f
2019-11-06 17:22:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:22:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:22:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:23:00 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 17:23:00 [scrapy.core.engine] INFO: Spider opened
2019-11-06 17:23:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:23:00 [java_spider] INFO: Spider opened: java_spider
2019-11-06 17:23:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 17:24:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:28:26 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-06 17:28:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-06 17:28:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-06 17:28:26 [scrapy.extensions.telnet] INFO: Telnet Password: 2b5822ff3b386173
2019-11-06 17:28:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-06 17:28:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-06 17:28:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-06 17:28:33 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-06 17:28:33 [scrapy.core.engine] INFO: Spider opened
2019-11-06 17:28:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-06 17:28:33 [java_spider] INFO: Spider opened: java_spider
2019-11-06 17:28:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-06 17:29:33 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-06 17:29:33 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-06 17:29:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1060063,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 6, 9, 29, 33, 572704),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 6, 9, 28, 33, 160186)}
2019-11-06 17:29:33 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-07 09:13:46 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 09:13:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 09:13:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 09:13:46 [scrapy.extensions.telnet] INFO: Telnet Password: a4f3d0030a90f986
2019-11-07 09:13:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 09:13:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 09:13:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 09:13:52 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 09:13:52 [scrapy.core.engine] INFO: Spider opened
2019-11-07 09:13:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 09:13:52 [java_spider] INFO: Spider opened: java_spider
2019-11-07 09:13:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 09:14:55 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 09:14:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-07 09:14:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1079709,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 7, 1, 14, 55, 949623),
 'item_scraped_count': 1,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 7, 1, 13, 52, 640052)}
2019-11-07 09:14:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-07 09:24:31 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 09:24:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 09:24:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 09:24:31 [scrapy.extensions.telnet] INFO: Telnet Password: 1a9d570c186649c6
2019-11-07 09:24:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 09:24:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 09:24:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 09:24:36 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 09:24:36 [scrapy.core.engine] INFO: Spider opened
2019-11-07 09:24:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 09:24:36 [java_spider] INFO: Spider opened: java_spider
2019-11-07 09:24:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 09:25:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-07 09:25:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1099368,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 7, 1, 25, 15, 552173),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 7, 1, 24, 36, 49025)}
2019-11-07 09:25:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-07 09:31:33 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 09:31:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 09:31:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 09:31:33 [scrapy.extensions.telnet] INFO: Telnet Password: 90966cb7ef538110
2019-11-07 09:31:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 09:31:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 09:31:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 09:31:39 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 09:31:39 [scrapy.core.engine] INFO: Spider opened
2019-11-07 09:31:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 09:31:39 [java_spider] INFO: Spider opened: java_spider
2019-11-07 09:31:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 09:32:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-07 09:32:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1050910,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 7, 1, 32, 17, 274995),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 7, 1, 31, 39, 161095)}
2019-11-07 09:32:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-07 11:28:29 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 11:28:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 11:28:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 11:28:29 [scrapy.extensions.telnet] INFO: Telnet Password: b73e6a510cf68b22
2019-11-07 11:28:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 11:28:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 11:28:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 11:28:34 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 11:28:34 [scrapy.core.engine] INFO: Spider opened
2019-11-07 11:28:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 11:28:34 [java_spider] INFO: Spider opened: java_spider
2019-11-07 11:28:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 11:29:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-07 11:29:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1081011,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 7, 3, 29, 25, 73629),
 'item_scraped_count': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2019, 11, 7, 3, 28, 34, 482780)}
2019-11-07 11:29:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-07 13:31:02 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 13:31:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 13:31:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:02 [scrapy.extensions.telnet] INFO: Telnet Password: 6c7892371a9db94d
2019-11-07 13:31:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [C_spider] INFO: Spider opened: C_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: a972f30b79500156
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: c3dca1d0a688de01
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 728d9786db1ce9f0
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 38fa68f3c28f89c3
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [golang_spider] INFO: Spider opened: golang_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 2a4e193f13fc128e
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [html_spider] INFO: Spider opened: html_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 1e5e72ff23dcf758
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [java_spider] INFO: Spider opened: java_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: ce8b793c33a12f55
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [js_spider] INFO: Spider opened: js_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 16badda18588cfea
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [php_spider] INFO: Spider opened: php_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: b60b91a7ec02cd5e
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [python_spider] INFO: Spider opened: python_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-07 13:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet Password: 6135b7b4851c962b
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 13:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 13:31:07 [scrapy.core.engine] INFO: Spider opened
2019-11-07 13:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:31:07 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-07 13:31:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:34:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:37:22 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 13:47:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:02 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:04:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:25 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: csdn_crawler)
2019-11-07 14:13:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.16299-SP0
2019-11-07 14:13:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:25 [scrapy.extensions.telnet] INFO: Telnet Password: 7541fb795121bd98
2019-11-07 14:13:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:29 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:29 [C_spider] INFO: Spider opened: C_spider
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-07 14:13:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet Password: 70733b9665c6fe54
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:29 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:29 [Ctoplus_spider] INFO: Spider opened: Ctoplus_spider
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2019-11-07 14:13:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet Password: 8a01ee6500f3ac42
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:29 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:29 [daonet_spider] INFO: Spider opened: daonet_spider
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2019-11-07 14:13:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet Password: 731b9d06deed92d9
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:29 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:29 [erlang_spider] INFO: Spider opened: erlang_spider
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026
2019-11-07 14:13:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet Password: 88e41135186ae8fb
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:29 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:29 [golang_spider] INFO: Spider opened: golang_spider
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027
2019-11-07 14:13:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:29 [scrapy.extensions.telnet] INFO: Telnet Password: af977dc927e32aa6
2019-11-07 14:13:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [html_spider] INFO: Spider opened: html_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028
2019-11-07 14:13:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: 7a0b31c338c5fb1e
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [java_spider] INFO: Spider opened: java_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029
2019-11-07 14:13:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: e33e54144956109d
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [js_spider] INFO: Spider opened: js_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030
2019-11-07 14:13:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: daa5df58b0a8bf19
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [php_spider] INFO: Spider opened: php_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031
2019-11-07 14:13:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: 1b2f76351c09fb54
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [python_spider] INFO: Spider opened: python_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032
2019-11-07 14:13:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'csdn_crawler', 'COMMANDS_MODULE': 'csdn_crawler.commands', 'COOKIES_ENABLED': False, 'LOG_FILE': './log.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'csdn_crawler.spiders', 'SPIDER_MODULES': ['csdn_crawler.spiders']}
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: 71916f3316c9ab76
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'csdn_crawler.middlewares.CsdnCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-07 14:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['csdn_crawler.pipelines.CsdnCrawlerPipeline',
 'csdn_crawler.pipelines.MysqlPipeline',
 'csdn_crawler.pipelines.HtmlSqlPipeline']
2019-11-07 14:13:30 [scrapy.core.engine] INFO: Spider opened
2019-11-07 14:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:13:30 [smallapp_spider] INFO: Spider opened: smallapp_spider
2019-11-07 14:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:16:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:19:36 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:25:41 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:40:31 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-11-07 14:50:01 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 6 items (at 5 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 4 items (at 3 items/min)
2019-11-07 15:24:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 4 items (at 4 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 4 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 5 pages/min), scraped 5 items (at 1 items/min)
2019-11-07 15:42:36 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 4 pages/min), scraped 6 items (at 2 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 10 items (at 4 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 7 items (at 1 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 5 items (at 0 items/min)
2019-11-07 15:55:00 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 6 items (at 0 items/min)
